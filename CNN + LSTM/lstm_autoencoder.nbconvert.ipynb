{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from resnet_feature_extracter import Img2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 6\n",
    "input_size = 2048\n",
    "hidden_size = 32#64#1024\n",
    "num_layers = 1#2\n",
    "num_classes = 10\n",
    "batch_size = 36\n",
    "num_epoches = 500#250\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vector extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Img2Vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoencoder definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # initialize weights\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return out[:, -1, :].unsqueeze(1)\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(hidden_size, output_size, num_layers, batch_first=True)\n",
    "\n",
    "        # initialize weights\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.output_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.output_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class AutoEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(AutoEncoderRNN, self).__init__()\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size, num_layers)\n",
    "        self.decoder = DecoderRNN(hidden_size, input_size, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded_x = self.encoder(x).expand(-1, sequence_length, -1)\n",
    "        decoded_x = self.decoder(encoded_x)\n",
    "\n",
    "        return decoded_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './pregnant'\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform=data_transforms) for x in ['train', 'val']}\n",
    "data_loaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    losses = {'train': [], 'val': []}\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "\n",
    "    for epoch in range(num_epoches):\n",
    "        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                # scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for inputs, _ in data_loaders[phase]:\n",
    "                inputs = extractor.get_vec(inputs)\n",
    "                \n",
    "                inputs = inputs.reshape(-1, sequence_length, input_size).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
    "                    loss = criterion(outputs, inputs[:, inv_idx, :])\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 25\n",
      "----------\n",
      "train Loss: 0.043862\n",
      "val Loss: 0.068216\n",
      "\n",
      "Epoch 2 / 25\n",
      "----------\n",
      "train Loss: 0.043842\n",
      "val Loss: 0.068190\n",
      "\n",
      "Epoch 3 / 25\n",
      "----------\n",
      "train Loss: 0.043822\n",
      "val Loss: 0.068163\n",
      "\n",
      "Epoch 4 / 25\n",
      "----------\n",
      "train Loss: 0.043802\n",
      "val Loss: 0.068137\n",
      "\n",
      "Epoch 5 / 25\n",
      "----------\n",
      "train Loss: 0.043782\n",
      "val Loss: 0.068111\n",
      "\n",
      "Epoch 6 / 25\n",
      "----------\n",
      "train Loss: 0.043762\n",
      "val Loss: 0.068085\n",
      "\n",
      "Epoch 7 / 25\n",
      "----------\n",
      "train Loss: 0.043742\n",
      "val Loss: 0.068059\n",
      "\n",
      "Epoch 8 / 25\n",
      "----------\n",
      "train Loss: 0.043722\n",
      "val Loss: 0.068033\n",
      "\n",
      "Epoch 9 / 25\n",
      "----------\n",
      "train Loss: 0.043703\n",
      "val Loss: 0.068007\n",
      "\n",
      "Epoch 10 / 25\n",
      "----------\n",
      "train Loss: 0.043683\n",
      "val Loss: 0.067981\n",
      "\n",
      "Epoch 11 / 25\n",
      "----------\n",
      "train Loss: 0.043663\n",
      "val Loss: 0.067955\n",
      "\n",
      "Epoch 12 / 25\n",
      "----------\n",
      "train Loss: 0.043644\n",
      "val Loss: 0.067929\n",
      "\n",
      "Epoch 13 / 25\n",
      "----------\n",
      "train Loss: 0.043624\n",
      "val Loss: 0.067904\n",
      "\n",
      "Epoch 14 / 25\n",
      "----------\n",
      "train Loss: 0.043605\n",
      "val Loss: 0.067878\n",
      "\n",
      "Epoch 15 / 25\n",
      "----------\n",
      "train Loss: 0.043585\n",
      "val Loss: 0.067852\n",
      "\n",
      "Epoch 16 / 25\n",
      "----------\n",
      "train Loss: 0.043566\n",
      "val Loss: 0.067826\n",
      "\n",
      "Epoch 17 / 25\n",
      "----------\n",
      "train Loss: 0.043546\n",
      "val Loss: 0.067800\n",
      "\n",
      "Epoch 18 / 25\n",
      "----------\n",
      "train Loss: 0.043526\n",
      "val Loss: 0.067774\n",
      "\n",
      "Epoch 19 / 25\n",
      "----------\n",
      "train Loss: 0.043507\n",
      "val Loss: 0.067748\n",
      "\n",
      "Epoch 20 / 25\n",
      "----------\n",
      "train Loss: 0.043487\n",
      "val Loss: 0.067722\n",
      "\n",
      "Epoch 21 / 25\n",
      "----------\n",
      "train Loss: 0.043467\n",
      "val Loss: 0.067695\n",
      "\n",
      "Epoch 22 / 25\n",
      "----------\n",
      "train Loss: 0.043447\n",
      "val Loss: 0.067669\n",
      "\n",
      "Epoch 23 / 25\n",
      "----------\n",
      "train Loss: 0.043427\n",
      "val Loss: 0.067642\n",
      "\n",
      "Epoch 24 / 25\n",
      "----------\n",
      "train Loss: 0.043407\n",
      "val Loss: 0.067616\n",
      "\n",
      "Epoch 25 / 25\n",
      "----------\n",
      "train Loss: 0.043387\n",
      "val Loss: 0.067589\n",
      "\n",
      "Epoch 26 / 25\n",
      "----------\n",
      "train Loss: 0.043366\n",
      "val Loss: 0.067562\n",
      "\n",
      "Epoch 27 / 25\n",
      "----------\n",
      "train Loss: 0.043346\n",
      "val Loss: 0.067535\n",
      "\n",
      "Epoch 28 / 25\n",
      "----------\n",
      "train Loss: 0.043325\n",
      "val Loss: 0.067507\n",
      "\n",
      "Epoch 29 / 25\n",
      "----------\n",
      "train Loss: 0.043305\n",
      "val Loss: 0.067480\n",
      "\n",
      "Epoch 30 / 25\n",
      "----------\n",
      "train Loss: 0.043284\n",
      "val Loss: 0.067452\n",
      "\n",
      "Epoch 31 / 25\n",
      "----------\n",
      "train Loss: 0.043263\n",
      "val Loss: 0.067424\n",
      "\n",
      "Epoch 32 / 25\n",
      "----------\n",
      "train Loss: 0.043242\n",
      "val Loss: 0.067396\n",
      "\n",
      "Epoch 33 / 25\n",
      "----------\n",
      "train Loss: 0.043221\n",
      "val Loss: 0.067368\n",
      "\n",
      "Epoch 34 / 25\n",
      "----------\n",
      "train Loss: 0.043199\n",
      "val Loss: 0.067339\n",
      "\n",
      "Epoch 35 / 25\n",
      "----------\n",
      "train Loss: 0.043177\n",
      "val Loss: 0.067310\n",
      "\n",
      "Epoch 36 / 25\n",
      "----------\n",
      "train Loss: 0.043156\n",
      "val Loss: 0.067281\n",
      "\n",
      "Epoch 37 / 25\n",
      "----------\n",
      "train Loss: 0.043134\n",
      "val Loss: 0.067252\n",
      "\n",
      "Epoch 38 / 25\n",
      "----------\n",
      "train Loss: 0.043112\n",
      "val Loss: 0.067222\n",
      "\n",
      "Epoch 39 / 25\n",
      "----------\n",
      "train Loss: 0.043089\n",
      "val Loss: 0.067192\n",
      "\n",
      "Epoch 40 / 25\n",
      "----------\n",
      "train Loss: 0.043067\n",
      "val Loss: 0.067162\n",
      "\n",
      "Epoch 41 / 25\n",
      "----------\n",
      "train Loss: 0.043044\n",
      "val Loss: 0.067132\n",
      "\n",
      "Epoch 42 / 25\n",
      "----------\n",
      "train Loss: 0.043021\n",
      "val Loss: 0.067101\n",
      "\n",
      "Epoch 43 / 25\n",
      "----------\n",
      "train Loss: 0.042998\n",
      "val Loss: 0.067070\n",
      "\n",
      "Epoch 44 / 25\n",
      "----------\n",
      "train Loss: 0.042974\n",
      "val Loss: 0.067039\n",
      "\n",
      "Epoch 45 / 25\n",
      "----------\n",
      "train Loss: 0.042951\n",
      "val Loss: 0.067007\n",
      "\n",
      "Epoch 46 / 25\n",
      "----------\n",
      "train Loss: 0.042927\n",
      "val Loss: 0.066975\n",
      "\n",
      "Epoch 47 / 25\n",
      "----------\n",
      "train Loss: 0.042902\n",
      "val Loss: 0.066943\n",
      "\n",
      "Epoch 48 / 25\n",
      "----------\n",
      "train Loss: 0.042878\n",
      "val Loss: 0.066910\n",
      "\n",
      "Epoch 49 / 25\n",
      "----------\n",
      "train Loss: 0.042853\n",
      "val Loss: 0.066877\n",
      "\n",
      "Epoch 50 / 25\n",
      "----------\n",
      "train Loss: 0.042828\n",
      "val Loss: 0.066843\n",
      "\n",
      "Epoch 51 / 25\n",
      "----------\n",
      "train Loss: 0.042803\n",
      "val Loss: 0.066810\n",
      "\n",
      "Epoch 52 / 25\n",
      "----------\n",
      "train Loss: 0.042777\n",
      "val Loss: 0.066775\n",
      "\n",
      "Epoch 53 / 25\n",
      "----------\n",
      "train Loss: 0.042752\n",
      "val Loss: 0.066741\n",
      "\n",
      "Epoch 54 / 25\n",
      "----------\n",
      "train Loss: 0.042725\n",
      "val Loss: 0.066706\n",
      "\n",
      "Epoch 55 / 25\n",
      "----------\n",
      "train Loss: 0.042699\n",
      "val Loss: 0.066670\n",
      "\n",
      "Epoch 56 / 25\n",
      "----------\n",
      "train Loss: 0.042672\n",
      "val Loss: 0.066634\n",
      "\n",
      "Epoch 57 / 25\n",
      "----------\n",
      "train Loss: 0.042645\n",
      "val Loss: 0.066598\n",
      "\n",
      "Epoch 58 / 25\n",
      "----------\n",
      "train Loss: 0.042618\n",
      "val Loss: 0.066561\n",
      "\n",
      "Epoch 59 / 25\n",
      "----------\n",
      "train Loss: 0.042590\n",
      "val Loss: 0.066523\n",
      "\n",
      "Epoch 60 / 25\n",
      "----------\n",
      "train Loss: 0.042562\n",
      "val Loss: 0.066485\n",
      "\n",
      "Epoch 61 / 25\n",
      "----------\n",
      "train Loss: 0.042533\n",
      "val Loss: 0.066447\n",
      "\n",
      "Epoch 62 / 25\n",
      "----------\n",
      "train Loss: 0.042504\n",
      "val Loss: 0.066408\n",
      "\n",
      "Epoch 63 / 25\n",
      "----------\n",
      "train Loss: 0.042475\n",
      "val Loss: 0.066369\n",
      "\n",
      "Epoch 64 / 25\n",
      "----------\n",
      "train Loss: 0.042445\n",
      "val Loss: 0.066329\n",
      "\n",
      "Epoch 65 / 25\n",
      "----------\n",
      "train Loss: 0.042415\n",
      "val Loss: 0.066289\n",
      "\n",
      "Epoch 66 / 25\n",
      "----------\n",
      "train Loss: 0.042385\n",
      "val Loss: 0.066248\n",
      "\n",
      "Epoch 67 / 25\n",
      "----------\n",
      "train Loss: 0.042354\n",
      "val Loss: 0.066207\n",
      "\n",
      "Epoch 68 / 25\n",
      "----------\n",
      "train Loss: 0.042323\n",
      "val Loss: 0.066165\n",
      "\n",
      "Epoch 69 / 25\n",
      "----------\n",
      "train Loss: 0.042292\n",
      "val Loss: 0.066122\n",
      "\n",
      "Epoch 70 / 25\n",
      "----------\n",
      "train Loss: 0.042260\n",
      "val Loss: 0.066079\n",
      "\n",
      "Epoch 71 / 25\n",
      "----------\n",
      "train Loss: 0.042227\n",
      "val Loss: 0.066036\n",
      "\n",
      "Epoch 72 / 25\n",
      "----------\n",
      "train Loss: 0.042194\n",
      "val Loss: 0.065992\n",
      "\n",
      "Epoch 73 / 25\n",
      "----------\n",
      "train Loss: 0.042161\n",
      "val Loss: 0.065947\n",
      "\n",
      "Epoch 74 / 25\n",
      "----------\n",
      "train Loss: 0.042127\n",
      "val Loss: 0.065902\n",
      "\n",
      "Epoch 75 / 25\n",
      "----------\n",
      "train Loss: 0.042093\n",
      "val Loss: 0.065856\n",
      "\n",
      "Epoch 76 / 25\n",
      "----------\n",
      "train Loss: 0.042059\n",
      "val Loss: 0.065809\n",
      "\n",
      "Epoch 77 / 25\n",
      "----------\n",
      "train Loss: 0.042024\n",
      "val Loss: 0.065762\n",
      "\n",
      "Epoch 78 / 25\n",
      "----------\n",
      "train Loss: 0.041988\n",
      "val Loss: 0.065715\n",
      "\n",
      "Epoch 79 / 25\n",
      "----------\n",
      "train Loss: 0.041952\n",
      "val Loss: 0.065667\n",
      "\n",
      "Epoch 80 / 25\n",
      "----------\n",
      "train Loss: 0.041916\n",
      "val Loss: 0.065618\n",
      "\n",
      "Epoch 81 / 25\n",
      "----------\n",
      "train Loss: 0.041879\n",
      "val Loss: 0.065568\n",
      "\n",
      "Epoch 82 / 25\n",
      "----------\n",
      "train Loss: 0.041842\n",
      "val Loss: 0.065518\n",
      "\n",
      "Epoch 83 / 25\n",
      "----------\n",
      "train Loss: 0.041804\n",
      "val Loss: 0.065468\n",
      "\n",
      "Epoch 84 / 25\n",
      "----------\n",
      "train Loss: 0.041766\n",
      "val Loss: 0.065417\n",
      "\n",
      "Epoch 85 / 25\n",
      "----------\n",
      "train Loss: 0.041727\n",
      "val Loss: 0.065365\n",
      "\n",
      "Epoch 86 / 25\n",
      "----------\n",
      "train Loss: 0.041688\n",
      "val Loss: 0.065312\n",
      "\n",
      "Epoch 87 / 25\n",
      "----------\n",
      "train Loss: 0.041648\n",
      "val Loss: 0.065259\n",
      "\n",
      "Epoch 88 / 25\n",
      "----------\n",
      "train Loss: 0.041608\n",
      "val Loss: 0.065206\n",
      "\n",
      "Epoch 89 / 25\n",
      "----------\n",
      "train Loss: 0.041567\n",
      "val Loss: 0.065151\n",
      "\n",
      "Epoch 90 / 25\n",
      "----------\n",
      "train Loss: 0.041526\n",
      "val Loss: 0.065097\n",
      "\n",
      "Epoch 91 / 25\n",
      "----------\n",
      "train Loss: 0.041485\n",
      "val Loss: 0.065041\n",
      "\n",
      "Epoch 92 / 25\n",
      "----------\n",
      "train Loss: 0.041442\n",
      "val Loss: 0.064985\n",
      "\n",
      "Epoch 93 / 25\n",
      "----------\n",
      "train Loss: 0.041400\n",
      "val Loss: 0.064928\n",
      "\n",
      "Epoch 94 / 25\n",
      "----------\n",
      "train Loss: 0.041357\n",
      "val Loss: 0.064871\n",
      "\n",
      "Epoch 95 / 25\n",
      "----------\n",
      "train Loss: 0.041314\n",
      "val Loss: 0.064813\n",
      "\n",
      "Epoch 96 / 25\n",
      "----------\n",
      "train Loss: 0.041270\n",
      "val Loss: 0.064754\n",
      "\n",
      "Epoch 97 / 25\n",
      "----------\n",
      "train Loss: 0.041225\n",
      "val Loss: 0.064695\n",
      "\n",
      "Epoch 98 / 25\n",
      "----------\n",
      "train Loss: 0.041180\n",
      "val Loss: 0.064635\n",
      "\n",
      "Epoch 99 / 25\n",
      "----------\n",
      "train Loss: 0.041135\n",
      "val Loss: 0.064575\n",
      "\n",
      "Epoch 100 / 25\n",
      "----------\n",
      "train Loss: 0.041089\n",
      "val Loss: 0.064514\n",
      "\n",
      "Epoch 101 / 25\n",
      "----------\n",
      "train Loss: 0.041043\n",
      "val Loss: 0.064453\n",
      "\n",
      "Epoch 102 / 25\n",
      "----------\n",
      "train Loss: 0.040996\n",
      "val Loss: 0.064390\n",
      "\n",
      "Epoch 103 / 25\n",
      "----------\n",
      "train Loss: 0.040949\n",
      "val Loss: 0.064328\n",
      "\n",
      "Epoch 104 / 25\n",
      "----------\n",
      "train Loss: 0.040901\n",
      "val Loss: 0.064264\n",
      "\n",
      "Epoch 105 / 25\n",
      "----------\n",
      "train Loss: 0.040853\n",
      "val Loss: 0.064200\n",
      "\n",
      "Epoch 106 / 25\n",
      "----------\n",
      "train Loss: 0.040805\n",
      "val Loss: 0.064136\n",
      "\n",
      "Epoch 107 / 25\n",
      "----------\n",
      "train Loss: 0.040756\n",
      "val Loss: 0.064071\n",
      "\n",
      "Epoch 108 / 25\n",
      "----------\n",
      "train Loss: 0.040706\n",
      "val Loss: 0.064005\n",
      "\n",
      "Epoch 109 / 25\n",
      "----------\n",
      "train Loss: 0.040656\n",
      "val Loss: 0.063939\n",
      "\n",
      "Epoch 110 / 25\n",
      "----------\n",
      "train Loss: 0.040606\n",
      "val Loss: 0.063872\n",
      "\n",
      "Epoch 111 / 25\n",
      "----------\n",
      "train Loss: 0.040555\n",
      "val Loss: 0.063805\n",
      "\n",
      "Epoch 112 / 25\n",
      "----------\n",
      "train Loss: 0.040504\n",
      "val Loss: 0.063737\n",
      "\n",
      "Epoch 113 / 25\n",
      "----------\n",
      "train Loss: 0.040453\n",
      "val Loss: 0.063669\n",
      "\n",
      "Epoch 114 / 25\n",
      "----------\n",
      "train Loss: 0.040401\n",
      "val Loss: 0.063600\n",
      "\n",
      "Epoch 115 / 25\n",
      "----------\n",
      "train Loss: 0.040348\n",
      "val Loss: 0.063531\n",
      "\n",
      "Epoch 116 / 25\n",
      "----------\n",
      "train Loss: 0.040295\n",
      "val Loss: 0.063461\n",
      "\n",
      "Epoch 117 / 25\n",
      "----------\n",
      "train Loss: 0.040242\n",
      "val Loss: 0.063391\n",
      "\n",
      "Epoch 118 / 25\n",
      "----------\n",
      "train Loss: 0.040189\n",
      "val Loss: 0.063320\n",
      "\n",
      "Epoch 119 / 25\n",
      "----------\n",
      "train Loss: 0.040135\n",
      "val Loss: 0.063248\n",
      "\n",
      "Epoch 120 / 25\n",
      "----------\n",
      "train Loss: 0.040080\n",
      "val Loss: 0.063177\n",
      "\n",
      "Epoch 121 / 25\n",
      "----------\n",
      "train Loss: 0.040026\n",
      "val Loss: 0.063104\n",
      "\n",
      "Epoch 122 / 25\n",
      "----------\n",
      "train Loss: 0.039971\n",
      "val Loss: 0.063032\n",
      "\n",
      "Epoch 123 / 25\n",
      "----------\n",
      "train Loss: 0.039915\n",
      "val Loss: 0.062958\n",
      "\n",
      "Epoch 124 / 25\n",
      "----------\n",
      "train Loss: 0.039860\n",
      "val Loss: 0.062885\n",
      "\n",
      "Epoch 125 / 25\n",
      "----------\n",
      "train Loss: 0.039803\n",
      "val Loss: 0.062811\n",
      "\n",
      "Epoch 126 / 25\n",
      "----------\n",
      "train Loss: 0.039747\n",
      "val Loss: 0.062736\n",
      "\n",
      "Epoch 127 / 25\n",
      "----------\n",
      "train Loss: 0.039690\n",
      "val Loss: 0.062661\n",
      "\n",
      "Epoch 128 / 25\n",
      "----------\n",
      "train Loss: 0.039633\n",
      "val Loss: 0.062586\n",
      "\n",
      "Epoch 129 / 25\n",
      "----------\n",
      "train Loss: 0.039576\n",
      "val Loss: 0.062510\n",
      "\n",
      "Epoch 130 / 25\n",
      "----------\n",
      "train Loss: 0.039518\n",
      "val Loss: 0.062434\n",
      "\n",
      "Epoch 131 / 25\n",
      "----------\n",
      "train Loss: 0.039460\n",
      "val Loss: 0.062358\n",
      "\n",
      "Epoch 132 / 25\n",
      "----------\n",
      "train Loss: 0.039401\n",
      "val Loss: 0.062281\n",
      "\n",
      "Epoch 133 / 25\n",
      "----------\n",
      "train Loss: 0.039343\n",
      "val Loss: 0.062203\n",
      "\n",
      "Epoch 134 / 25\n",
      "----------\n",
      "train Loss: 0.039284\n",
      "val Loss: 0.062126\n",
      "\n",
      "Epoch 135 / 25\n",
      "----------\n",
      "train Loss: 0.039224\n",
      "val Loss: 0.062048\n",
      "\n",
      "Epoch 136 / 25\n",
      "----------\n",
      "train Loss: 0.039165\n",
      "val Loss: 0.061969\n",
      "\n",
      "Epoch 137 / 25\n",
      "----------\n",
      "train Loss: 0.039105\n",
      "val Loss: 0.061891\n",
      "\n",
      "Epoch 138 / 25\n",
      "----------\n",
      "train Loss: 0.039045\n",
      "val Loss: 0.061811\n",
      "\n",
      "Epoch 139 / 25\n",
      "----------\n",
      "train Loss: 0.038984\n",
      "val Loss: 0.061732\n",
      "\n",
      "Epoch 140 / 25\n",
      "----------\n",
      "train Loss: 0.038924\n",
      "val Loss: 0.061652\n",
      "\n",
      "Epoch 141 / 25\n",
      "----------\n",
      "train Loss: 0.038863\n",
      "val Loss: 0.061572\n",
      "\n",
      "Epoch 142 / 25\n",
      "----------\n",
      "train Loss: 0.038802\n",
      "val Loss: 0.061492\n",
      "\n",
      "Epoch 143 / 25\n",
      "----------\n",
      "train Loss: 0.038740\n",
      "val Loss: 0.061411\n",
      "\n",
      "Epoch 144 / 25\n",
      "----------\n",
      "train Loss: 0.038679\n",
      "val Loss: 0.061330\n",
      "\n",
      "Epoch 145 / 25\n",
      "----------\n",
      "train Loss: 0.038617\n",
      "val Loss: 0.061249\n",
      "\n",
      "Epoch 146 / 25\n",
      "----------\n",
      "train Loss: 0.038555\n",
      "val Loss: 0.061167\n",
      "\n",
      "Epoch 147 / 25\n",
      "----------\n",
      "train Loss: 0.038492\n",
      "val Loss: 0.061086\n",
      "\n",
      "Epoch 148 / 25\n",
      "----------\n",
      "train Loss: 0.038430\n",
      "val Loss: 0.061003\n",
      "\n",
      "Epoch 149 / 25\n",
      "----------\n",
      "train Loss: 0.038367\n",
      "val Loss: 0.060921\n",
      "\n",
      "Epoch 150 / 25\n",
      "----------\n",
      "train Loss: 0.038304\n",
      "val Loss: 0.060838\n",
      "\n",
      "Epoch 151 / 25\n",
      "----------\n",
      "train Loss: 0.038241\n",
      "val Loss: 0.060755\n",
      "\n",
      "Epoch 152 / 25\n",
      "----------\n",
      "train Loss: 0.038177\n",
      "val Loss: 0.060672\n",
      "\n",
      "Epoch 153 / 25\n",
      "----------\n",
      "train Loss: 0.038114\n",
      "val Loss: 0.060589\n",
      "\n",
      "Epoch 154 / 25\n",
      "----------\n",
      "train Loss: 0.038050\n",
      "val Loss: 0.060505\n",
      "\n",
      "Epoch 155 / 25\n",
      "----------\n",
      "train Loss: 0.037986\n",
      "val Loss: 0.060421\n",
      "\n",
      "Epoch 156 / 25\n",
      "----------\n",
      "train Loss: 0.037922\n",
      "val Loss: 0.060337\n",
      "\n",
      "Epoch 157 / 25\n",
      "----------\n",
      "train Loss: 0.037857\n",
      "val Loss: 0.060252\n",
      "\n",
      "Epoch 158 / 25\n",
      "----------\n",
      "train Loss: 0.037793\n",
      "val Loss: 0.060168\n",
      "\n",
      "Epoch 159 / 25\n",
      "----------\n",
      "train Loss: 0.037728\n",
      "val Loss: 0.060083\n",
      "\n",
      "Epoch 160 / 25\n",
      "----------\n",
      "train Loss: 0.037663\n",
      "val Loss: 0.059998\n",
      "\n",
      "Epoch 161 / 25\n",
      "----------\n",
      "train Loss: 0.037598\n",
      "val Loss: 0.059912\n",
      "\n",
      "Epoch 162 / 25\n",
      "----------\n",
      "train Loss: 0.037533\n",
      "val Loss: 0.059827\n",
      "\n",
      "Epoch 163 / 25\n",
      "----------\n",
      "train Loss: 0.037468\n",
      "val Loss: 0.059741\n",
      "\n",
      "Epoch 164 / 25\n",
      "----------\n",
      "train Loss: 0.037402\n",
      "val Loss: 0.059655\n",
      "\n",
      "Epoch 165 / 25\n",
      "----------\n",
      "train Loss: 0.037337\n",
      "val Loss: 0.059569\n",
      "\n",
      "Epoch 166 / 25\n",
      "----------\n",
      "train Loss: 0.037271\n",
      "val Loss: 0.059483\n",
      "\n",
      "Epoch 167 / 25\n",
      "----------\n",
      "train Loss: 0.037205\n",
      "val Loss: 0.059396\n",
      "\n",
      "Epoch 168 / 25\n",
      "----------\n",
      "train Loss: 0.037139\n",
      "val Loss: 0.059310\n",
      "\n",
      "Epoch 169 / 25\n",
      "----------\n",
      "train Loss: 0.037073\n",
      "val Loss: 0.059223\n",
      "\n",
      "Epoch 170 / 25\n",
      "----------\n",
      "train Loss: 0.037007\n",
      "val Loss: 0.059136\n",
      "\n",
      "Epoch 171 / 25\n",
      "----------\n",
      "train Loss: 0.036940\n",
      "val Loss: 0.059048\n",
      "\n",
      "Epoch 172 / 25\n",
      "----------\n",
      "train Loss: 0.036874\n",
      "val Loss: 0.058961\n",
      "\n",
      "Epoch 173 / 25\n",
      "----------\n",
      "train Loss: 0.036807\n",
      "val Loss: 0.058873\n",
      "\n",
      "Epoch 174 / 25\n",
      "----------\n",
      "train Loss: 0.036740\n",
      "val Loss: 0.058786\n",
      "\n",
      "Epoch 175 / 25\n",
      "----------\n",
      "train Loss: 0.036673\n",
      "val Loss: 0.058698\n",
      "\n",
      "Epoch 176 / 25\n",
      "----------\n",
      "train Loss: 0.036606\n",
      "val Loss: 0.058610\n",
      "\n",
      "Epoch 177 / 25\n",
      "----------\n",
      "train Loss: 0.036539\n",
      "val Loss: 0.058522\n",
      "\n",
      "Epoch 178 / 25\n",
      "----------\n",
      "train Loss: 0.036472\n",
      "val Loss: 0.058433\n",
      "\n",
      "Epoch 179 / 25\n",
      "----------\n",
      "train Loss: 0.036405\n",
      "val Loss: 0.058345\n",
      "\n",
      "Epoch 180 / 25\n",
      "----------\n",
      "train Loss: 0.036337\n",
      "val Loss: 0.058256\n",
      "\n",
      "Epoch 181 / 25\n",
      "----------\n",
      "train Loss: 0.036270\n",
      "val Loss: 0.058168\n",
      "\n",
      "Epoch 182 / 25\n",
      "----------\n",
      "train Loss: 0.036202\n",
      "val Loss: 0.058079\n",
      "\n",
      "Epoch 183 / 25\n",
      "----------\n",
      "train Loss: 0.036135\n",
      "val Loss: 0.057990\n",
      "\n",
      "Epoch 184 / 25\n",
      "----------\n",
      "train Loss: 0.036067\n",
      "val Loss: 0.057901\n",
      "\n",
      "Epoch 185 / 25\n",
      "----------\n",
      "train Loss: 0.035999\n",
      "val Loss: 0.057811\n",
      "\n",
      "Epoch 186 / 25\n",
      "----------\n",
      "train Loss: 0.035931\n",
      "val Loss: 0.057722\n",
      "\n",
      "Epoch 187 / 25\n",
      "----------\n",
      "train Loss: 0.035863\n",
      "val Loss: 0.057632\n",
      "\n",
      "Epoch 188 / 25\n",
      "----------\n",
      "train Loss: 0.035795\n",
      "val Loss: 0.057543\n",
      "\n",
      "Epoch 189 / 25\n",
      "----------\n",
      "train Loss: 0.035727\n",
      "val Loss: 0.057453\n",
      "\n",
      "Epoch 190 / 25\n",
      "----------\n",
      "train Loss: 0.035659\n",
      "val Loss: 0.057363\n",
      "\n",
      "Epoch 191 / 25\n",
      "----------\n",
      "train Loss: 0.035591\n",
      "val Loss: 0.057273\n",
      "\n",
      "Epoch 192 / 25\n",
      "----------\n",
      "train Loss: 0.035522\n",
      "val Loss: 0.057183\n",
      "\n",
      "Epoch 193 / 25\n",
      "----------\n",
      "train Loss: 0.035454\n",
      "val Loss: 0.057093\n",
      "\n",
      "Epoch 194 / 25\n",
      "----------\n",
      "train Loss: 0.035385\n",
      "val Loss: 0.057003\n",
      "\n",
      "Epoch 195 / 25\n",
      "----------\n",
      "train Loss: 0.035317\n",
      "val Loss: 0.056912\n",
      "\n",
      "Epoch 196 / 25\n",
      "----------\n",
      "train Loss: 0.035248\n",
      "val Loss: 0.056822\n",
      "\n",
      "Epoch 197 / 25\n",
      "----------\n",
      "train Loss: 0.035180\n",
      "val Loss: 0.056731\n",
      "\n",
      "Epoch 198 / 25\n",
      "----------\n",
      "train Loss: 0.035111\n",
      "val Loss: 0.056641\n",
      "\n",
      "Epoch 199 / 25\n",
      "----------\n",
      "train Loss: 0.035043\n",
      "val Loss: 0.056550\n",
      "\n",
      "Epoch 200 / 25\n",
      "----------\n",
      "train Loss: 0.034974\n",
      "val Loss: 0.056459\n",
      "\n",
      "Epoch 201 / 25\n",
      "----------\n",
      "train Loss: 0.034905\n",
      "val Loss: 0.056368\n",
      "\n",
      "Epoch 202 / 25\n",
      "----------\n",
      "train Loss: 0.034836\n",
      "val Loss: 0.056278\n",
      "\n",
      "Epoch 203 / 25\n",
      "----------\n",
      "train Loss: 0.034768\n",
      "val Loss: 0.056187\n",
      "\n",
      "Epoch 204 / 25\n",
      "----------\n",
      "train Loss: 0.034699\n",
      "val Loss: 0.056095\n",
      "\n",
      "Epoch 205 / 25\n",
      "----------\n",
      "train Loss: 0.034630\n",
      "val Loss: 0.056004\n",
      "\n",
      "Epoch 206 / 25\n",
      "----------\n",
      "train Loss: 0.034561\n",
      "val Loss: 0.055913\n",
      "\n",
      "Epoch 207 / 25\n",
      "----------\n",
      "train Loss: 0.034492\n",
      "val Loss: 0.055822\n",
      "\n",
      "Epoch 208 / 25\n",
      "----------\n",
      "train Loss: 0.034423\n",
      "val Loss: 0.055731\n",
      "\n",
      "Epoch 209 / 25\n",
      "----------\n",
      "train Loss: 0.034354\n",
      "val Loss: 0.055639\n",
      "\n",
      "Epoch 210 / 25\n",
      "----------\n",
      "train Loss: 0.034285\n",
      "val Loss: 0.055548\n",
      "\n",
      "Epoch 211 / 25\n",
      "----------\n",
      "train Loss: 0.034216\n",
      "val Loss: 0.055456\n",
      "\n",
      "Epoch 212 / 25\n",
      "----------\n",
      "train Loss: 0.034147\n",
      "val Loss: 0.055365\n",
      "\n",
      "Epoch 213 / 25\n",
      "----------\n",
      "train Loss: 0.034078\n",
      "val Loss: 0.055273\n",
      "\n",
      "Epoch 214 / 25\n",
      "----------\n",
      "train Loss: 0.034009\n",
      "val Loss: 0.055182\n",
      "\n",
      "Epoch 215 / 25\n",
      "----------\n",
      "train Loss: 0.033940\n",
      "val Loss: 0.055090\n",
      "\n",
      "Epoch 216 / 25\n",
      "----------\n",
      "train Loss: 0.033871\n",
      "val Loss: 0.054999\n",
      "\n",
      "Epoch 217 / 25\n",
      "----------\n",
      "train Loss: 0.033802\n",
      "val Loss: 0.054907\n",
      "\n",
      "Epoch 218 / 25\n",
      "----------\n",
      "train Loss: 0.033733\n",
      "val Loss: 0.054815\n",
      "\n",
      "Epoch 219 / 25\n",
      "----------\n",
      "train Loss: 0.033664\n",
      "val Loss: 0.054724\n",
      "\n",
      "Epoch 220 / 25\n",
      "----------\n",
      "train Loss: 0.033595\n",
      "val Loss: 0.054632\n",
      "\n",
      "Epoch 221 / 25\n",
      "----------\n",
      "train Loss: 0.033526\n",
      "val Loss: 0.054540\n",
      "\n",
      "Epoch 222 / 25\n",
      "----------\n",
      "train Loss: 0.033457\n",
      "val Loss: 0.054448\n",
      "\n",
      "Epoch 223 / 25\n",
      "----------\n",
      "train Loss: 0.033388\n",
      "val Loss: 0.054357\n",
      "\n",
      "Epoch 224 / 25\n",
      "----------\n",
      "train Loss: 0.033319\n",
      "val Loss: 0.054265\n",
      "\n",
      "Epoch 225 / 25\n",
      "----------\n",
      "train Loss: 0.033250\n",
      "val Loss: 0.054173\n",
      "\n",
      "Epoch 226 / 25\n",
      "----------\n",
      "train Loss: 0.033181\n",
      "val Loss: 0.054081\n",
      "\n",
      "Epoch 227 / 25\n",
      "----------\n",
      "train Loss: 0.033113\n",
      "val Loss: 0.053989\n",
      "\n",
      "Epoch 228 / 25\n",
      "----------\n",
      "train Loss: 0.033044\n",
      "val Loss: 0.053898\n",
      "\n",
      "Epoch 229 / 25\n",
      "----------\n",
      "train Loss: 0.032975\n",
      "val Loss: 0.053806\n",
      "\n",
      "Epoch 230 / 25\n",
      "----------\n",
      "train Loss: 0.032906\n",
      "val Loss: 0.053714\n",
      "\n",
      "Epoch 231 / 25\n",
      "----------\n",
      "train Loss: 0.032837\n",
      "val Loss: 0.053622\n",
      "\n",
      "Epoch 232 / 25\n",
      "----------\n",
      "train Loss: 0.032768\n",
      "val Loss: 0.053530\n",
      "\n",
      "Epoch 233 / 25\n",
      "----------\n",
      "train Loss: 0.032700\n",
      "val Loss: 0.053439\n",
      "\n",
      "Epoch 234 / 25\n",
      "----------\n",
      "train Loss: 0.032631\n",
      "val Loss: 0.053347\n",
      "\n",
      "Epoch 235 / 25\n",
      "----------\n",
      "train Loss: 0.032562\n",
      "val Loss: 0.053255\n",
      "\n",
      "Epoch 236 / 25\n",
      "----------\n",
      "train Loss: 0.032494\n",
      "val Loss: 0.053164\n",
      "\n",
      "Epoch 237 / 25\n",
      "----------\n",
      "train Loss: 0.032425\n",
      "val Loss: 0.053072\n",
      "\n",
      "Epoch 238 / 25\n",
      "----------\n",
      "train Loss: 0.032356\n",
      "val Loss: 0.052980\n",
      "\n",
      "Epoch 239 / 25\n",
      "----------\n",
      "train Loss: 0.032288\n",
      "val Loss: 0.052889\n",
      "\n",
      "Epoch 240 / 25\n",
      "----------\n",
      "train Loss: 0.032219\n",
      "val Loss: 0.052797\n",
      "\n",
      "Epoch 241 / 25\n",
      "----------\n",
      "train Loss: 0.032151\n",
      "val Loss: 0.052705\n",
      "\n",
      "Epoch 242 / 25\n",
      "----------\n",
      "train Loss: 0.032083\n",
      "val Loss: 0.052614\n",
      "\n",
      "Epoch 243 / 25\n",
      "----------\n",
      "train Loss: 0.032014\n",
      "val Loss: 0.052522\n",
      "\n",
      "Epoch 244 / 25\n",
      "----------\n",
      "train Loss: 0.031946\n",
      "val Loss: 0.052431\n",
      "\n",
      "Epoch 245 / 25\n",
      "----------\n",
      "train Loss: 0.031878\n",
      "val Loss: 0.052339\n",
      "\n",
      "Epoch 246 / 25\n",
      "----------\n",
      "train Loss: 0.031810\n",
      "val Loss: 0.052248\n",
      "\n",
      "Epoch 247 / 25\n",
      "----------\n",
      "train Loss: 0.031742\n",
      "val Loss: 0.052157\n",
      "\n",
      "Epoch 248 / 25\n",
      "----------\n",
      "train Loss: 0.031674\n",
      "val Loss: 0.052065\n",
      "\n",
      "Epoch 249 / 25\n",
      "----------\n",
      "train Loss: 0.031606\n",
      "val Loss: 0.051974\n",
      "\n",
      "Epoch 250 / 25\n",
      "----------\n",
      "train Loss: 0.031538\n",
      "val Loss: 0.051883\n",
      "\n",
      "Epoch 251 / 25\n",
      "----------\n",
      "train Loss: 0.031470\n",
      "val Loss: 0.051792\n",
      "\n",
      "Epoch 252 / 25\n",
      "----------\n",
      "train Loss: 0.031402\n",
      "val Loss: 0.051700\n",
      "\n",
      "Epoch 253 / 25\n",
      "----------\n",
      "train Loss: 0.031334\n",
      "val Loss: 0.051609\n",
      "\n",
      "Epoch 254 / 25\n",
      "----------\n",
      "train Loss: 0.031267\n",
      "val Loss: 0.051518\n",
      "\n",
      "Epoch 255 / 25\n",
      "----------\n",
      "train Loss: 0.031199\n",
      "val Loss: 0.051428\n",
      "\n",
      "Epoch 256 / 25\n",
      "----------\n",
      "train Loss: 0.031132\n",
      "val Loss: 0.051337\n",
      "\n",
      "Epoch 257 / 25\n",
      "----------\n",
      "train Loss: 0.031064\n",
      "val Loss: 0.051246\n",
      "\n",
      "Epoch 258 / 25\n",
      "----------\n",
      "train Loss: 0.030997\n",
      "val Loss: 0.051155\n",
      "\n",
      "Epoch 259 / 25\n",
      "----------\n",
      "train Loss: 0.030930\n",
      "val Loss: 0.051065\n",
      "\n",
      "Epoch 260 / 25\n",
      "----------\n",
      "train Loss: 0.030863\n",
      "val Loss: 0.050974\n",
      "\n",
      "Epoch 261 / 25\n",
      "----------\n",
      "train Loss: 0.030796\n",
      "val Loss: 0.050884\n",
      "\n",
      "Epoch 262 / 25\n",
      "----------\n",
      "train Loss: 0.030729\n",
      "val Loss: 0.050793\n",
      "\n",
      "Epoch 263 / 25\n",
      "----------\n",
      "train Loss: 0.030662\n",
      "val Loss: 0.050703\n",
      "\n",
      "Epoch 264 / 25\n",
      "----------\n",
      "train Loss: 0.030595\n",
      "val Loss: 0.050613\n",
      "\n",
      "Epoch 265 / 25\n",
      "----------\n",
      "train Loss: 0.030529\n",
      "val Loss: 0.050523\n",
      "\n",
      "Epoch 266 / 25\n",
      "----------\n",
      "train Loss: 0.030462\n",
      "val Loss: 0.050433\n",
      "\n",
      "Epoch 267 / 25\n",
      "----------\n",
      "train Loss: 0.030396\n",
      "val Loss: 0.050343\n",
      "\n",
      "Epoch 268 / 25\n",
      "----------\n",
      "train Loss: 0.030329\n",
      "val Loss: 0.050253\n",
      "\n",
      "Epoch 269 / 25\n",
      "----------\n",
      "train Loss: 0.030263\n",
      "val Loss: 0.050163\n",
      "\n",
      "Epoch 270 / 25\n",
      "----------\n",
      "train Loss: 0.030197\n",
      "val Loss: 0.050074\n",
      "\n",
      "Epoch 271 / 25\n",
      "----------\n",
      "train Loss: 0.030131\n",
      "val Loss: 0.049984\n",
      "\n",
      "Epoch 272 / 25\n",
      "----------\n",
      "train Loss: 0.030065\n",
      "val Loss: 0.049895\n",
      "\n",
      "Epoch 273 / 25\n",
      "----------\n",
      "train Loss: 0.030000\n",
      "val Loss: 0.049806\n",
      "\n",
      "Epoch 274 / 25\n",
      "----------\n",
      "train Loss: 0.029934\n",
      "val Loss: 0.049717\n",
      "\n",
      "Epoch 275 / 25\n",
      "----------\n",
      "train Loss: 0.029868\n",
      "val Loss: 0.049628\n",
      "\n",
      "Epoch 276 / 25\n",
      "----------\n",
      "train Loss: 0.029803\n",
      "val Loss: 0.049539\n",
      "\n",
      "Epoch 277 / 25\n",
      "----------\n",
      "train Loss: 0.029738\n",
      "val Loss: 0.049450\n",
      "\n",
      "Epoch 278 / 25\n",
      "----------\n",
      "train Loss: 0.029673\n",
      "val Loss: 0.049362\n",
      "\n",
      "Epoch 279 / 25\n",
      "----------\n",
      "train Loss: 0.029608\n",
      "val Loss: 0.049274\n",
      "\n",
      "Epoch 280 / 25\n",
      "----------\n",
      "train Loss: 0.029543\n",
      "val Loss: 0.049185\n",
      "\n",
      "Epoch 281 / 25\n",
      "----------\n",
      "train Loss: 0.029478\n",
      "val Loss: 0.049097\n",
      "\n",
      "Epoch 282 / 25\n",
      "----------\n",
      "train Loss: 0.029414\n",
      "val Loss: 0.049009\n",
      "\n",
      "Epoch 283 / 25\n",
      "----------\n",
      "train Loss: 0.029350\n",
      "val Loss: 0.048922\n",
      "\n",
      "Epoch 284 / 25\n",
      "----------\n",
      "train Loss: 0.029285\n",
      "val Loss: 0.048834\n",
      "\n",
      "Epoch 285 / 25\n",
      "----------\n",
      "train Loss: 0.029221\n",
      "val Loss: 0.048747\n",
      "\n",
      "Epoch 286 / 25\n",
      "----------\n",
      "train Loss: 0.029157\n",
      "val Loss: 0.048660\n",
      "\n",
      "Epoch 287 / 25\n",
      "----------\n",
      "train Loss: 0.029094\n",
      "val Loss: 0.048572\n",
      "\n",
      "Epoch 288 / 25\n",
      "----------\n",
      "train Loss: 0.029030\n",
      "val Loss: 0.048486\n",
      "\n",
      "Epoch 289 / 25\n",
      "----------\n",
      "train Loss: 0.028967\n",
      "val Loss: 0.048399\n",
      "\n",
      "Epoch 290 / 25\n",
      "----------\n",
      "train Loss: 0.028903\n",
      "val Loss: 0.048312\n",
      "\n",
      "Epoch 291 / 25\n",
      "----------\n",
      "train Loss: 0.028840\n",
      "val Loss: 0.048226\n",
      "\n",
      "Epoch 292 / 25\n",
      "----------\n",
      "train Loss: 0.028777\n",
      "val Loss: 0.048140\n",
      "\n",
      "Epoch 293 / 25\n",
      "----------\n",
      "train Loss: 0.028715\n",
      "val Loss: 0.048054\n",
      "\n",
      "Epoch 294 / 25\n",
      "----------\n",
      "train Loss: 0.028652\n",
      "val Loss: 0.047968\n",
      "\n",
      "Epoch 295 / 25\n",
      "----------\n",
      "train Loss: 0.028589\n",
      "val Loss: 0.047882\n",
      "\n",
      "Epoch 296 / 25\n",
      "----------\n",
      "train Loss: 0.028527\n",
      "val Loss: 0.047797\n",
      "\n",
      "Epoch 297 / 25\n",
      "----------\n",
      "train Loss: 0.028465\n",
      "val Loss: 0.047711\n",
      "\n",
      "Epoch 298 / 25\n",
      "----------\n",
      "train Loss: 0.028403\n",
      "val Loss: 0.047626\n",
      "\n",
      "Epoch 299 / 25\n",
      "----------\n",
      "train Loss: 0.028341\n",
      "val Loss: 0.047541\n",
      "\n",
      "Epoch 300 / 25\n",
      "----------\n",
      "train Loss: 0.028280\n",
      "val Loss: 0.047456\n",
      "\n",
      "Epoch 301 / 25\n",
      "----------\n",
      "train Loss: 0.028218\n",
      "val Loss: 0.047372\n",
      "\n",
      "Epoch 302 / 25\n",
      "----------\n",
      "train Loss: 0.028157\n",
      "val Loss: 0.047287\n",
      "\n",
      "Epoch 303 / 25\n",
      "----------\n",
      "train Loss: 0.028096\n",
      "val Loss: 0.047203\n",
      "\n",
      "Epoch 304 / 25\n",
      "----------\n",
      "train Loss: 0.028035\n",
      "val Loss: 0.047119\n",
      "\n",
      "Epoch 305 / 25\n",
      "----------\n",
      "train Loss: 0.027974\n",
      "val Loss: 0.047035\n",
      "\n",
      "Epoch 306 / 25\n",
      "----------\n",
      "train Loss: 0.027914\n",
      "val Loss: 0.046952\n",
      "\n",
      "Epoch 307 / 25\n",
      "----------\n",
      "train Loss: 0.027854\n",
      "val Loss: 0.046868\n",
      "\n",
      "Epoch 308 / 25\n",
      "----------\n",
      "train Loss: 0.027793\n",
      "val Loss: 0.046785\n",
      "\n",
      "Epoch 309 / 25\n",
      "----------\n",
      "train Loss: 0.027733\n",
      "val Loss: 0.046702\n",
      "\n",
      "Epoch 310 / 25\n",
      "----------\n",
      "train Loss: 0.027674\n",
      "val Loss: 0.046619\n",
      "\n",
      "Epoch 311 / 25\n",
      "----------\n",
      "train Loss: 0.027614\n",
      "val Loss: 0.046536\n",
      "\n",
      "Epoch 312 / 25\n",
      "----------\n",
      "train Loss: 0.027554\n",
      "val Loss: 0.046453\n",
      "\n",
      "Epoch 313 / 25\n",
      "----------\n",
      "train Loss: 0.027495\n",
      "val Loss: 0.046371\n",
      "\n",
      "Epoch 314 / 25\n",
      "----------\n",
      "train Loss: 0.027436\n",
      "val Loss: 0.046289\n",
      "\n",
      "Epoch 315 / 25\n",
      "----------\n",
      "train Loss: 0.027377\n",
      "val Loss: 0.046207\n",
      "\n",
      "Epoch 316 / 25\n",
      "----------\n",
      "train Loss: 0.027318\n",
      "val Loss: 0.046125\n",
      "\n",
      "Epoch 317 / 25\n",
      "----------\n",
      "train Loss: 0.027260\n",
      "val Loss: 0.046043\n",
      "\n",
      "Epoch 318 / 25\n",
      "----------\n",
      "train Loss: 0.027201\n",
      "val Loss: 0.045962\n",
      "\n",
      "Epoch 319 / 25\n",
      "----------\n",
      "train Loss: 0.027143\n",
      "val Loss: 0.045881\n",
      "\n",
      "Epoch 320 / 25\n",
      "----------\n",
      "train Loss: 0.027085\n",
      "val Loss: 0.045800\n",
      "\n",
      "Epoch 321 / 25\n",
      "----------\n",
      "train Loss: 0.027027\n",
      "val Loss: 0.045719\n",
      "\n",
      "Epoch 322 / 25\n",
      "----------\n",
      "train Loss: 0.026970\n",
      "val Loss: 0.045638\n",
      "\n",
      "Epoch 323 / 25\n",
      "----------\n",
      "train Loss: 0.026912\n",
      "val Loss: 0.045558\n",
      "\n",
      "Epoch 324 / 25\n",
      "----------\n",
      "train Loss: 0.026855\n",
      "val Loss: 0.045477\n",
      "\n",
      "Epoch 325 / 25\n",
      "----------\n",
      "train Loss: 0.026798\n",
      "val Loss: 0.045397\n",
      "\n",
      "Epoch 326 / 25\n",
      "----------\n",
      "train Loss: 0.026741\n",
      "val Loss: 0.045317\n",
      "\n",
      "Epoch 327 / 25\n",
      "----------\n",
      "train Loss: 0.026684\n",
      "val Loss: 0.045238\n",
      "\n",
      "Epoch 328 / 25\n",
      "----------\n",
      "train Loss: 0.026628\n",
      "val Loss: 0.045158\n",
      "\n",
      "Epoch 329 / 25\n",
      "----------\n",
      "train Loss: 0.026571\n",
      "val Loss: 0.045079\n",
      "\n",
      "Epoch 330 / 25\n",
      "----------\n",
      "train Loss: 0.026515\n",
      "val Loss: 0.045000\n",
      "\n",
      "Epoch 331 / 25\n",
      "----------\n",
      "train Loss: 0.026459\n",
      "val Loss: 0.044921\n",
      "\n",
      "Epoch 332 / 25\n",
      "----------\n",
      "train Loss: 0.026404\n",
      "val Loss: 0.044842\n",
      "\n",
      "Epoch 333 / 25\n",
      "----------\n",
      "train Loss: 0.026348\n",
      "val Loss: 0.044764\n",
      "\n",
      "Epoch 334 / 25\n",
      "----------\n",
      "train Loss: 0.026293\n",
      "val Loss: 0.044686\n",
      "\n",
      "Epoch 335 / 25\n",
      "----------\n",
      "train Loss: 0.026237\n",
      "val Loss: 0.044608\n",
      "\n",
      "Epoch 336 / 25\n",
      "----------\n",
      "train Loss: 0.026182\n",
      "val Loss: 0.044530\n",
      "\n",
      "Epoch 337 / 25\n",
      "----------\n",
      "train Loss: 0.026128\n",
      "val Loss: 0.044452\n",
      "\n",
      "Epoch 338 / 25\n",
      "----------\n",
      "train Loss: 0.026073\n",
      "val Loss: 0.044374\n",
      "\n",
      "Epoch 339 / 25\n",
      "----------\n",
      "train Loss: 0.026018\n",
      "val Loss: 0.044297\n",
      "\n",
      "Epoch 340 / 25\n",
      "----------\n",
      "train Loss: 0.025964\n",
      "val Loss: 0.044220\n",
      "\n",
      "Epoch 341 / 25\n",
      "----------\n",
      "train Loss: 0.025910\n",
      "val Loss: 0.044143\n",
      "\n",
      "Epoch 342 / 25\n",
      "----------\n",
      "train Loss: 0.025856\n",
      "val Loss: 0.044067\n",
      "\n",
      "Epoch 343 / 25\n",
      "----------\n",
      "train Loss: 0.025803\n",
      "val Loss: 0.043990\n",
      "\n",
      "Epoch 344 / 25\n",
      "----------\n",
      "train Loss: 0.025749\n",
      "val Loss: 0.043914\n",
      "\n",
      "Epoch 345 / 25\n",
      "----------\n",
      "train Loss: 0.025696\n",
      "val Loss: 0.043838\n",
      "\n",
      "Epoch 346 / 25\n",
      "----------\n",
      "train Loss: 0.025643\n",
      "val Loss: 0.043762\n",
      "\n",
      "Epoch 347 / 25\n",
      "----------\n",
      "train Loss: 0.025590\n",
      "val Loss: 0.043687\n",
      "\n",
      "Epoch 348 / 25\n",
      "----------\n",
      "train Loss: 0.025537\n",
      "val Loss: 0.043611\n",
      "\n",
      "Epoch 349 / 25\n",
      "----------\n",
      "train Loss: 0.025485\n",
      "val Loss: 0.043536\n",
      "\n",
      "Epoch 350 / 25\n",
      "----------\n",
      "train Loss: 0.025432\n",
      "val Loss: 0.043461\n",
      "\n",
      "Epoch 351 / 25\n",
      "----------\n",
      "train Loss: 0.025380\n",
      "val Loss: 0.043386\n",
      "\n",
      "Epoch 352 / 25\n",
      "----------\n",
      "train Loss: 0.025328\n",
      "val Loss: 0.043312\n",
      "\n",
      "Epoch 353 / 25\n",
      "----------\n",
      "train Loss: 0.025276\n",
      "val Loss: 0.043237\n",
      "\n",
      "Epoch 354 / 25\n",
      "----------\n",
      "train Loss: 0.025225\n",
      "val Loss: 0.043163\n",
      "\n",
      "Epoch 355 / 25\n",
      "----------\n",
      "train Loss: 0.025173\n",
      "val Loss: 0.043089\n",
      "\n",
      "Epoch 356 / 25\n",
      "----------\n",
      "train Loss: 0.025122\n",
      "val Loss: 0.043015\n",
      "\n",
      "Epoch 357 / 25\n",
      "----------\n",
      "train Loss: 0.025071\n",
      "val Loss: 0.042942\n",
      "\n",
      "Epoch 358 / 25\n",
      "----------\n",
      "train Loss: 0.025021\n",
      "val Loss: 0.042869\n",
      "\n",
      "Epoch 359 / 25\n",
      "----------\n",
      "train Loss: 0.024970\n",
      "val Loss: 0.042796\n",
      "\n",
      "Epoch 360 / 25\n",
      "----------\n",
      "train Loss: 0.024920\n",
      "val Loss: 0.042723\n",
      "\n",
      "Epoch 361 / 25\n",
      "----------\n",
      "train Loss: 0.024869\n",
      "val Loss: 0.042650\n",
      "\n",
      "Epoch 362 / 25\n",
      "----------\n",
      "train Loss: 0.024819\n",
      "val Loss: 0.042578\n",
      "\n",
      "Epoch 363 / 25\n",
      "----------\n",
      "train Loss: 0.024770\n",
      "val Loss: 0.042506\n",
      "\n",
      "Epoch 364 / 25\n",
      "----------\n",
      "train Loss: 0.024720\n",
      "val Loss: 0.042434\n",
      "\n",
      "Epoch 365 / 25\n",
      "----------\n",
      "train Loss: 0.024671\n",
      "val Loss: 0.042362\n",
      "\n",
      "Epoch 366 / 25\n",
      "----------\n",
      "train Loss: 0.024621\n",
      "val Loss: 0.042290\n",
      "\n",
      "Epoch 367 / 25\n",
      "----------\n",
      "train Loss: 0.024572\n",
      "val Loss: 0.042219\n",
      "\n",
      "Epoch 368 / 25\n",
      "----------\n",
      "train Loss: 0.024523\n",
      "val Loss: 0.042148\n",
      "\n",
      "Epoch 369 / 25\n",
      "----------\n",
      "train Loss: 0.024475\n",
      "val Loss: 0.042077\n",
      "\n",
      "Epoch 370 / 25\n",
      "----------\n",
      "train Loss: 0.024426\n",
      "val Loss: 0.042006\n",
      "\n",
      "Epoch 371 / 25\n",
      "----------\n",
      "train Loss: 0.024378\n",
      "val Loss: 0.041936\n",
      "\n",
      "Epoch 372 / 25\n",
      "----------\n",
      "train Loss: 0.024330\n",
      "val Loss: 0.041866\n",
      "\n",
      "Epoch 373 / 25\n",
      "----------\n",
      "train Loss: 0.024282\n",
      "val Loss: 0.041796\n",
      "\n",
      "Epoch 374 / 25\n",
      "----------\n",
      "train Loss: 0.024235\n",
      "val Loss: 0.041726\n",
      "\n",
      "Epoch 375 / 25\n",
      "----------\n",
      "train Loss: 0.024187\n",
      "val Loss: 0.041656\n",
      "\n",
      "Epoch 376 / 25\n",
      "----------\n",
      "train Loss: 0.024140\n",
      "val Loss: 0.041587\n",
      "\n",
      "Epoch 377 / 25\n",
      "----------\n",
      "train Loss: 0.024093\n",
      "val Loss: 0.041518\n",
      "\n",
      "Epoch 378 / 25\n",
      "----------\n",
      "train Loss: 0.024046\n",
      "val Loss: 0.041449\n",
      "\n",
      "Epoch 379 / 25\n",
      "----------\n",
      "train Loss: 0.023999\n",
      "val Loss: 0.041380\n",
      "\n",
      "Epoch 380 / 25\n",
      "----------\n",
      "train Loss: 0.023953\n",
      "val Loss: 0.041312\n",
      "\n",
      "Epoch 381 / 25\n",
      "----------\n",
      "train Loss: 0.023906\n",
      "val Loss: 0.041244\n",
      "\n",
      "Epoch 382 / 25\n",
      "----------\n",
      "train Loss: 0.023860\n",
      "val Loss: 0.041176\n",
      "\n",
      "Epoch 383 / 25\n",
      "----------\n",
      "train Loss: 0.023814\n",
      "val Loss: 0.041108\n",
      "\n",
      "Epoch 384 / 25\n",
      "----------\n",
      "train Loss: 0.023769\n",
      "val Loss: 0.041041\n",
      "\n",
      "Epoch 385 / 25\n",
      "----------\n",
      "train Loss: 0.023723\n",
      "val Loss: 0.040973\n",
      "\n",
      "Epoch 386 / 25\n",
      "----------\n",
      "train Loss: 0.023678\n",
      "val Loss: 0.040906\n",
      "\n",
      "Epoch 387 / 25\n",
      "----------\n",
      "train Loss: 0.023633\n",
      "val Loss: 0.040839\n",
      "\n",
      "Epoch 388 / 25\n",
      "----------\n",
      "train Loss: 0.023588\n",
      "val Loss: 0.040773\n",
      "\n",
      "Epoch 389 / 25\n",
      "----------\n",
      "train Loss: 0.023543\n",
      "val Loss: 0.040706\n",
      "\n",
      "Epoch 390 / 25\n",
      "----------\n",
      "train Loss: 0.023499\n",
      "val Loss: 0.040640\n",
      "\n",
      "Epoch 391 / 25\n",
      "----------\n",
      "train Loss: 0.023454\n",
      "val Loss: 0.040574\n",
      "\n",
      "Epoch 392 / 25\n",
      "----------\n",
      "train Loss: 0.023410\n",
      "val Loss: 0.040509\n",
      "\n",
      "Epoch 393 / 25\n",
      "----------\n",
      "train Loss: 0.023366\n",
      "val Loss: 0.040443\n",
      "\n",
      "Epoch 394 / 25\n",
      "----------\n",
      "train Loss: 0.023323\n",
      "val Loss: 0.040378\n",
      "\n",
      "Epoch 395 / 25\n",
      "----------\n",
      "train Loss: 0.023279\n",
      "val Loss: 0.040313\n",
      "\n",
      "Epoch 396 / 25\n",
      "----------\n",
      "train Loss: 0.023236\n",
      "val Loss: 0.040248\n",
      "\n",
      "Epoch 397 / 25\n",
      "----------\n",
      "train Loss: 0.023192\n",
      "val Loss: 0.040184\n",
      "\n",
      "Epoch 398 / 25\n",
      "----------\n",
      "train Loss: 0.023149\n",
      "val Loss: 0.040119\n",
      "\n",
      "Epoch 399 / 25\n",
      "----------\n",
      "train Loss: 0.023107\n",
      "val Loss: 0.040055\n",
      "\n",
      "Epoch 400 / 25\n",
      "----------\n",
      "train Loss: 0.023064\n",
      "val Loss: 0.039992\n",
      "\n",
      "Epoch 401 / 25\n",
      "----------\n",
      "train Loss: 0.023022\n",
      "val Loss: 0.039928\n",
      "\n",
      "Epoch 402 / 25\n",
      "----------\n",
      "train Loss: 0.022980\n",
      "val Loss: 0.039865\n",
      "\n",
      "Epoch 403 / 25\n",
      "----------\n",
      "train Loss: 0.022938\n",
      "val Loss: 0.039801\n",
      "\n",
      "Epoch 404 / 25\n",
      "----------\n",
      "train Loss: 0.022896\n",
      "val Loss: 0.039739\n",
      "\n",
      "Epoch 405 / 25\n",
      "----------\n",
      "train Loss: 0.022854\n",
      "val Loss: 0.039676\n",
      "\n",
      "Epoch 406 / 25\n",
      "----------\n",
      "train Loss: 0.022813\n",
      "val Loss: 0.039613\n",
      "\n",
      "Epoch 407 / 25\n",
      "----------\n",
      "train Loss: 0.022772\n",
      "val Loss: 0.039551\n",
      "\n",
      "Epoch 408 / 25\n",
      "----------\n",
      "train Loss: 0.022730\n",
      "val Loss: 0.039489\n",
      "\n",
      "Epoch 409 / 25\n",
      "----------\n",
      "train Loss: 0.022690\n",
      "val Loss: 0.039427\n",
      "\n",
      "Epoch 410 / 25\n",
      "----------\n",
      "train Loss: 0.022649\n",
      "val Loss: 0.039366\n",
      "\n",
      "Epoch 411 / 25\n",
      "----------\n",
      "train Loss: 0.022609\n",
      "val Loss: 0.039305\n",
      "\n",
      "Epoch 412 / 25\n",
      "----------\n",
      "train Loss: 0.022568\n",
      "val Loss: 0.039244\n",
      "\n",
      "Epoch 413 / 25\n",
      "----------\n",
      "train Loss: 0.022528\n",
      "val Loss: 0.039183\n",
      "\n",
      "Epoch 414 / 25\n",
      "----------\n",
      "train Loss: 0.022488\n",
      "val Loss: 0.039122\n",
      "\n",
      "Epoch 415 / 25\n",
      "----------\n",
      "train Loss: 0.022449\n",
      "val Loss: 0.039062\n",
      "\n",
      "Epoch 416 / 25\n",
      "----------\n",
      "train Loss: 0.022409\n",
      "val Loss: 0.039002\n",
      "\n",
      "Epoch 417 / 25\n",
      "----------\n",
      "train Loss: 0.022370\n",
      "val Loss: 0.038942\n",
      "\n",
      "Epoch 418 / 25\n",
      "----------\n",
      "train Loss: 0.022331\n",
      "val Loss: 0.038882\n",
      "\n",
      "Epoch 419 / 25\n",
      "----------\n",
      "train Loss: 0.022292\n",
      "val Loss: 0.038823\n",
      "\n",
      "Epoch 420 / 25\n",
      "----------\n",
      "train Loss: 0.022253\n",
      "val Loss: 0.038764\n",
      "\n",
      "Epoch 421 / 25\n",
      "----------\n",
      "train Loss: 0.022214\n",
      "val Loss: 0.038705\n",
      "\n",
      "Epoch 422 / 25\n",
      "----------\n",
      "train Loss: 0.022176\n",
      "val Loss: 0.038646\n",
      "\n",
      "Epoch 423 / 25\n",
      "----------\n",
      "train Loss: 0.022138\n",
      "val Loss: 0.038587\n",
      "\n",
      "Epoch 424 / 25\n",
      "----------\n",
      "train Loss: 0.022100\n",
      "val Loss: 0.038529\n",
      "\n",
      "Epoch 425 / 25\n",
      "----------\n",
      "train Loss: 0.022062\n",
      "val Loss: 0.038471\n",
      "\n",
      "Epoch 426 / 25\n",
      "----------\n",
      "train Loss: 0.022024\n",
      "val Loss: 0.038413\n",
      "\n",
      "Epoch 427 / 25\n",
      "----------\n",
      "train Loss: 0.021987\n",
      "val Loss: 0.038355\n",
      "\n",
      "Epoch 428 / 25\n",
      "----------\n",
      "train Loss: 0.021950\n",
      "val Loss: 0.038298\n",
      "\n",
      "Epoch 429 / 25\n",
      "----------\n",
      "train Loss: 0.021913\n",
      "val Loss: 0.038241\n",
      "\n",
      "Epoch 430 / 25\n",
      "----------\n",
      "train Loss: 0.021876\n",
      "val Loss: 0.038184\n",
      "\n",
      "Epoch 431 / 25\n",
      "----------\n",
      "train Loss: 0.021839\n",
      "val Loss: 0.038127\n",
      "\n",
      "Epoch 432 / 25\n",
      "----------\n",
      "train Loss: 0.021802\n",
      "val Loss: 0.038071\n",
      "\n",
      "Epoch 433 / 25\n",
      "----------\n",
      "train Loss: 0.021766\n",
      "val Loss: 0.038015\n",
      "\n",
      "Epoch 434 / 25\n",
      "----------\n",
      "train Loss: 0.021730\n",
      "val Loss: 0.037959\n",
      "\n",
      "Epoch 435 / 25\n",
      "----------\n",
      "train Loss: 0.021694\n",
      "val Loss: 0.037903\n",
      "\n",
      "Epoch 436 / 25\n",
      "----------\n",
      "train Loss: 0.021658\n",
      "val Loss: 0.037847\n",
      "\n",
      "Epoch 437 / 25\n",
      "----------\n",
      "train Loss: 0.021623\n",
      "val Loss: 0.037792\n",
      "\n",
      "Epoch 438 / 25\n",
      "----------\n",
      "train Loss: 0.021587\n",
      "val Loss: 0.037737\n",
      "\n",
      "Epoch 439 / 25\n",
      "----------\n",
      "train Loss: 0.021552\n",
      "val Loss: 0.037682\n",
      "\n",
      "Epoch 440 / 25\n",
      "----------\n",
      "train Loss: 0.021517\n",
      "val Loss: 0.037627\n",
      "\n",
      "Epoch 441 / 25\n",
      "----------\n",
      "train Loss: 0.021482\n",
      "val Loss: 0.037573\n",
      "\n",
      "Epoch 442 / 25\n",
      "----------\n",
      "train Loss: 0.021447\n",
      "val Loss: 0.037519\n",
      "\n",
      "Epoch 443 / 25\n",
      "----------\n",
      "train Loss: 0.021413\n",
      "val Loss: 0.037465\n",
      "\n",
      "Epoch 444 / 25\n",
      "----------\n",
      "train Loss: 0.021378\n",
      "val Loss: 0.037411\n",
      "\n",
      "Epoch 445 / 25\n",
      "----------\n",
      "train Loss: 0.021344\n",
      "val Loss: 0.037357\n",
      "\n",
      "Epoch 446 / 25\n",
      "----------\n",
      "train Loss: 0.021310\n",
      "val Loss: 0.037304\n",
      "\n",
      "Epoch 447 / 25\n",
      "----------\n",
      "train Loss: 0.021276\n",
      "val Loss: 0.037251\n",
      "\n",
      "Epoch 448 / 25\n",
      "----------\n",
      "train Loss: 0.021243\n",
      "val Loss: 0.037198\n",
      "\n",
      "Epoch 449 / 25\n",
      "----------\n",
      "train Loss: 0.021209\n",
      "val Loss: 0.037146\n",
      "\n",
      "Epoch 450 / 25\n",
      "----------\n",
      "train Loss: 0.021176\n",
      "val Loss: 0.037093\n",
      "\n",
      "Epoch 451 / 25\n",
      "----------\n",
      "train Loss: 0.021143\n",
      "val Loss: 0.037041\n",
      "\n",
      "Epoch 452 / 25\n",
      "----------\n",
      "train Loss: 0.021110\n",
      "val Loss: 0.036989\n",
      "\n",
      "Epoch 453 / 25\n",
      "----------\n",
      "train Loss: 0.021077\n",
      "val Loss: 0.036937\n",
      "\n",
      "Epoch 454 / 25\n",
      "----------\n",
      "train Loss: 0.021044\n",
      "val Loss: 0.036886\n",
      "\n",
      "Epoch 455 / 25\n",
      "----------\n",
      "train Loss: 0.021012\n",
      "val Loss: 0.036834\n",
      "\n",
      "Epoch 456 / 25\n",
      "----------\n",
      "train Loss: 0.020980\n",
      "val Loss: 0.036783\n",
      "\n",
      "Epoch 457 / 25\n",
      "----------\n",
      "train Loss: 0.020947\n",
      "val Loss: 0.036732\n",
      "\n",
      "Epoch 458 / 25\n",
      "----------\n",
      "train Loss: 0.020916\n",
      "val Loss: 0.036682\n",
      "\n",
      "Epoch 459 / 25\n",
      "----------\n",
      "train Loss: 0.020884\n",
      "val Loss: 0.036631\n",
      "\n",
      "Epoch 460 / 25\n",
      "----------\n",
      "train Loss: 0.020852\n",
      "val Loss: 0.036581\n",
      "\n",
      "Epoch 461 / 25\n",
      "----------\n",
      "train Loss: 0.020821\n",
      "val Loss: 0.036531\n",
      "\n",
      "Epoch 462 / 25\n",
      "----------\n",
      "train Loss: 0.020789\n",
      "val Loss: 0.036481\n",
      "\n",
      "Epoch 463 / 25\n",
      "----------\n",
      "train Loss: 0.020758\n",
      "val Loss: 0.036431\n",
      "\n",
      "Epoch 464 / 25\n",
      "----------\n",
      "train Loss: 0.020727\n",
      "val Loss: 0.036382\n",
      "\n",
      "Epoch 465 / 25\n",
      "----------\n",
      "train Loss: 0.020697\n",
      "val Loss: 0.036333\n",
      "\n",
      "Epoch 466 / 25\n",
      "----------\n",
      "train Loss: 0.020666\n",
      "val Loss: 0.036284\n",
      "\n",
      "Epoch 467 / 25\n",
      "----------\n",
      "train Loss: 0.020636\n",
      "val Loss: 0.036235\n",
      "\n",
      "Epoch 468 / 25\n",
      "----------\n",
      "train Loss: 0.020605\n",
      "val Loss: 0.036186\n",
      "\n",
      "Epoch 469 / 25\n",
      "----------\n",
      "train Loss: 0.020575\n",
      "val Loss: 0.036138\n",
      "\n",
      "Epoch 470 / 25\n",
      "----------\n",
      "train Loss: 0.020545\n",
      "val Loss: 0.036090\n",
      "\n",
      "Epoch 471 / 25\n",
      "----------\n",
      "train Loss: 0.020516\n",
      "val Loss: 0.036042\n",
      "\n",
      "Epoch 472 / 25\n",
      "----------\n",
      "train Loss: 0.020486\n",
      "val Loss: 0.035994\n",
      "\n",
      "Epoch 473 / 25\n",
      "----------\n",
      "train Loss: 0.020456\n",
      "val Loss: 0.035947\n",
      "\n",
      "Epoch 474 / 25\n",
      "----------\n",
      "train Loss: 0.020427\n",
      "val Loss: 0.035900\n",
      "\n",
      "Epoch 475 / 25\n",
      "----------\n",
      "train Loss: 0.020398\n",
      "val Loss: 0.035852\n",
      "\n",
      "Epoch 476 / 25\n",
      "----------\n",
      "train Loss: 0.020369\n",
      "val Loss: 0.035806\n",
      "\n",
      "Epoch 477 / 25\n",
      "----------\n",
      "train Loss: 0.020340\n",
      "val Loss: 0.035759\n",
      "\n",
      "Epoch 478 / 25\n",
      "----------\n",
      "train Loss: 0.020312\n",
      "val Loss: 0.035712\n",
      "\n",
      "Epoch 479 / 25\n",
      "----------\n",
      "train Loss: 0.020283\n",
      "val Loss: 0.035666\n",
      "\n",
      "Epoch 480 / 25\n",
      "----------\n",
      "train Loss: 0.020255\n",
      "val Loss: 0.035620\n",
      "\n",
      "Epoch 481 / 25\n",
      "----------\n",
      "train Loss: 0.020226\n",
      "val Loss: 0.035574\n",
      "\n",
      "Epoch 482 / 25\n",
      "----------\n",
      "train Loss: 0.020198\n",
      "val Loss: 0.035529\n",
      "\n",
      "Epoch 483 / 25\n",
      "----------\n",
      "train Loss: 0.020170\n",
      "val Loss: 0.035483\n",
      "\n",
      "Epoch 484 / 25\n",
      "----------\n",
      "train Loss: 0.020143\n",
      "val Loss: 0.035438\n",
      "\n",
      "Epoch 485 / 25\n",
      "----------\n",
      "train Loss: 0.020115\n",
      "val Loss: 0.035393\n",
      "\n",
      "Epoch 486 / 25\n",
      "----------\n",
      "train Loss: 0.020088\n",
      "val Loss: 0.035348\n",
      "\n",
      "Epoch 487 / 25\n",
      "----------\n",
      "train Loss: 0.020060\n",
      "val Loss: 0.035303\n",
      "\n",
      "Epoch 488 / 25\n",
      "----------\n",
      "train Loss: 0.020033\n",
      "val Loss: 0.035259\n",
      "\n",
      "Epoch 489 / 25\n",
      "----------\n",
      "train Loss: 0.020006\n",
      "val Loss: 0.035215\n",
      "\n",
      "Epoch 490 / 25\n",
      "----------\n",
      "train Loss: 0.019979\n",
      "val Loss: 0.035171\n",
      "\n",
      "Epoch 491 / 25\n",
      "----------\n",
      "train Loss: 0.019953\n",
      "val Loss: 0.035127\n",
      "\n",
      "Epoch 492 / 25\n",
      "----------\n",
      "train Loss: 0.019926\n",
      "val Loss: 0.035083\n",
      "\n",
      "Epoch 493 / 25\n",
      "----------\n",
      "train Loss: 0.019900\n",
      "val Loss: 0.035040\n",
      "\n",
      "Epoch 494 / 25\n",
      "----------\n",
      "train Loss: 0.019874\n",
      "val Loss: 0.034996\n",
      "\n",
      "Epoch 495 / 25\n",
      "----------\n",
      "train Loss: 0.019847\n",
      "val Loss: 0.034953\n",
      "\n",
      "Epoch 496 / 25\n",
      "----------\n",
      "train Loss: 0.019822\n",
      "val Loss: 0.034910\n",
      "\n",
      "Epoch 497 / 25\n",
      "----------\n",
      "train Loss: 0.019796\n",
      "val Loss: 0.034868\n",
      "\n",
      "Epoch 498 / 25\n",
      "----------\n",
      "train Loss: 0.019770\n",
      "val Loss: 0.034825\n",
      "\n",
      "Epoch 499 / 25\n",
      "----------\n",
      "train Loss: 0.019745\n",
      "val Loss: 0.034783\n",
      "\n",
      "Epoch 500 / 25\n",
      "----------\n",
      "train Loss: 0.019719\n",
      "val Loss: 0.034741\n",
      "\n",
      "Training complete in 41m 54.403625s\n",
      "Best val loss: 0.034741\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoderRNN(input_size, hidden_size, num_layers)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model, losses = train_model(model, criterion, optimizer)\n",
    "torch.save(model.state_dict(), './lstm_autoencoder_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training/val curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for phase in ['train', 'val']:\n",
    "    plt.plot(losses[phase], label='{} loss'.format(phase))\n",
    " \n",
    "plt.legend()\n",
    "\n",
    "plt.title('train/val losses')\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
