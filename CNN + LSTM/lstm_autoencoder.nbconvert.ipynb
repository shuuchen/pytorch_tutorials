{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from resnet_feature_extracter import Img2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 6\n",
    "input_size = 2048\n",
    "hidden_size = 32#64#1024\n",
    "num_layers = 1#2\n",
    "num_classes = 10\n",
    "batch_size = 36\n",
    "num_epoches = 500#250\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vector extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Img2Vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoencoder definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, \n",
    "                            dropout=0.2, bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # initialize weights\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return out[:, -1, :].unsqueeze(1)\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(hidden_size, output_size, num_layers, batch_first=True,\n",
    "                            dropout=0.2, bidirectional=False)\n",
    "\n",
    "        # initialize weights\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.output_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.output_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class AutoEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(AutoEncoderRNN, self).__init__()\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size, num_layers)\n",
    "        self.decoder = DecoderRNN(hidden_size, input_size, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded_x = self.encoder(x).expand(-1, sequence_length, -1)\n",
    "        decoded_x = self.decoder(encoded_x)\n",
    "\n",
    "        return decoded_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './pregnant'\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform=data_transforms) for x in ['train', 'val']}\n",
    "data_loaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    losses = {'train': [], 'val': []}\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "\n",
    "    for epoch in range(num_epoches):\n",
    "        print('Epoch {} / {}'.format(epoch + 1, num_epoches))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                # scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for inputs, _ in data_loaders[phase]:\n",
    "                inputs = extractor.get_vec(inputs)\n",
    "                \n",
    "                inputs = inputs.reshape(-1, sequence_length, input_size).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
    "                    loss = criterion(outputs, inputs[:, inv_idx, :])\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuchen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 500\n",
      "----------\n",
      "train Loss: 0.043730\n",
      "val Loss: 0.068081\n",
      "\n",
      "Epoch 2 / 500\n",
      "----------\n",
      "train Loss: 0.043717\n",
      "val Loss: 0.068063\n",
      "\n",
      "Epoch 3 / 500\n",
      "----------\n",
      "train Loss: 0.043703\n",
      "val Loss: 0.068045\n",
      "\n",
      "Epoch 4 / 500\n",
      "----------\n",
      "train Loss: 0.043690\n",
      "val Loss: 0.068028\n",
      "\n",
      "Epoch 5 / 500\n",
      "----------\n",
      "train Loss: 0.043677\n",
      "val Loss: 0.068010\n",
      "\n",
      "Epoch 6 / 500\n",
      "----------\n",
      "train Loss: 0.043664\n",
      "val Loss: 0.067993\n",
      "\n",
      "Epoch 7 / 500\n",
      "----------\n",
      "train Loss: 0.043650\n",
      "val Loss: 0.067975\n",
      "\n",
      "Epoch 8 / 500\n",
      "----------\n",
      "train Loss: 0.043637\n",
      "val Loss: 0.067957\n",
      "\n",
      "Epoch 9 / 500\n",
      "----------\n",
      "train Loss: 0.043623\n",
      "val Loss: 0.067940\n",
      "\n",
      "Epoch 10 / 500\n",
      "----------\n",
      "train Loss: 0.043610\n",
      "val Loss: 0.067922\n",
      "\n",
      "Epoch 11 / 500\n",
      "----------\n",
      "train Loss: 0.043597\n",
      "val Loss: 0.067904\n",
      "\n",
      "Epoch 12 / 500\n",
      "----------\n",
      "train Loss: 0.043583\n",
      "val Loss: 0.067886\n",
      "\n",
      "Epoch 13 / 500\n",
      "----------\n",
      "train Loss: 0.043570\n",
      "val Loss: 0.067868\n",
      "\n",
      "Epoch 14 / 500\n",
      "----------\n",
      "train Loss: 0.043556\n",
      "val Loss: 0.067850\n",
      "\n",
      "Epoch 15 / 500\n",
      "----------\n",
      "train Loss: 0.043542\n",
      "val Loss: 0.067832\n",
      "\n",
      "Epoch 16 / 500\n",
      "----------\n",
      "train Loss: 0.043529\n",
      "val Loss: 0.067814\n",
      "\n",
      "Epoch 17 / 500\n",
      "----------\n",
      "train Loss: 0.043515\n",
      "val Loss: 0.067795\n",
      "\n",
      "Epoch 18 / 500\n",
      "----------\n",
      "train Loss: 0.043501\n",
      "val Loss: 0.067777\n",
      "\n",
      "Epoch 19 / 500\n",
      "----------\n",
      "train Loss: 0.043487\n",
      "val Loss: 0.067758\n",
      "\n",
      "Epoch 20 / 500\n",
      "----------\n",
      "train Loss: 0.043473\n",
      "val Loss: 0.067739\n",
      "\n",
      "Epoch 21 / 500\n",
      "----------\n",
      "train Loss: 0.043459\n",
      "val Loss: 0.067721\n",
      "\n",
      "Epoch 22 / 500\n",
      "----------\n",
      "train Loss: 0.043444\n",
      "val Loss: 0.067701\n",
      "\n",
      "Epoch 23 / 500\n",
      "----------\n",
      "train Loss: 0.043430\n",
      "val Loss: 0.067682\n",
      "\n",
      "Epoch 24 / 500\n",
      "----------\n",
      "train Loss: 0.043416\n",
      "val Loss: 0.067663\n",
      "\n",
      "Epoch 25 / 500\n",
      "----------\n",
      "train Loss: 0.043401\n",
      "val Loss: 0.067643\n",
      "\n",
      "Epoch 26 / 500\n",
      "----------\n",
      "train Loss: 0.043386\n",
      "val Loss: 0.067623\n",
      "\n",
      "Epoch 27 / 500\n",
      "----------\n",
      "train Loss: 0.043371\n",
      "val Loss: 0.067604\n",
      "\n",
      "Epoch 28 / 500\n",
      "----------\n",
      "train Loss: 0.043356\n",
      "val Loss: 0.067583\n",
      "\n",
      "Epoch 29 / 500\n",
      "----------\n",
      "train Loss: 0.043341\n",
      "val Loss: 0.067563\n",
      "\n",
      "Epoch 30 / 500\n",
      "----------\n",
      "train Loss: 0.043326\n",
      "val Loss: 0.067542\n",
      "\n",
      "Epoch 31 / 500\n",
      "----------\n",
      "train Loss: 0.043310\n",
      "val Loss: 0.067522\n",
      "\n",
      "Epoch 32 / 500\n",
      "----------\n",
      "train Loss: 0.043294\n",
      "val Loss: 0.067501\n",
      "\n",
      "Epoch 33 / 500\n",
      "----------\n",
      "train Loss: 0.043279\n",
      "val Loss: 0.067479\n",
      "\n",
      "Epoch 34 / 500\n",
      "----------\n",
      "train Loss: 0.043263\n",
      "val Loss: 0.067458\n",
      "\n",
      "Epoch 35 / 500\n",
      "----------\n",
      "train Loss: 0.043246\n",
      "val Loss: 0.067436\n",
      "\n",
      "Epoch 36 / 500\n",
      "----------\n",
      "train Loss: 0.043230\n",
      "val Loss: 0.067414\n",
      "\n",
      "Epoch 37 / 500\n",
      "----------\n",
      "train Loss: 0.043213\n",
      "val Loss: 0.067392\n",
      "\n",
      "Epoch 38 / 500\n",
      "----------\n",
      "train Loss: 0.043197\n",
      "val Loss: 0.067369\n",
      "\n",
      "Epoch 39 / 500\n",
      "----------\n",
      "train Loss: 0.043180\n",
      "val Loss: 0.067346\n",
      "\n",
      "Epoch 40 / 500\n",
      "----------\n",
      "train Loss: 0.043162\n",
      "val Loss: 0.067323\n",
      "\n",
      "Epoch 41 / 500\n",
      "----------\n",
      "train Loss: 0.043145\n",
      "val Loss: 0.067300\n",
      "\n",
      "Epoch 42 / 500\n",
      "----------\n",
      "train Loss: 0.043127\n",
      "val Loss: 0.067276\n",
      "\n",
      "Epoch 43 / 500\n",
      "----------\n",
      "train Loss: 0.043110\n",
      "val Loss: 0.067252\n",
      "\n",
      "Epoch 44 / 500\n",
      "----------\n",
      "train Loss: 0.043091\n",
      "val Loss: 0.067228\n",
      "\n",
      "Epoch 45 / 500\n",
      "----------\n",
      "train Loss: 0.043073\n",
      "val Loss: 0.067203\n",
      "\n",
      "Epoch 46 / 500\n",
      "----------\n",
      "train Loss: 0.043055\n",
      "val Loss: 0.067178\n",
      "\n",
      "Epoch 47 / 500\n",
      "----------\n",
      "train Loss: 0.043036\n",
      "val Loss: 0.067153\n",
      "\n",
      "Epoch 48 / 500\n",
      "----------\n",
      "train Loss: 0.043017\n",
      "val Loss: 0.067127\n",
      "\n",
      "Epoch 49 / 500\n",
      "----------\n",
      "train Loss: 0.042998\n",
      "val Loss: 0.067101\n",
      "\n",
      "Epoch 50 / 500\n",
      "----------\n",
      "train Loss: 0.042978\n",
      "val Loss: 0.067074\n",
      "\n",
      "Epoch 51 / 500\n",
      "----------\n",
      "train Loss: 0.042958\n",
      "val Loss: 0.067048\n",
      "\n",
      "Epoch 52 / 500\n",
      "----------\n",
      "train Loss: 0.042938\n",
      "val Loss: 0.067021\n",
      "\n",
      "Epoch 53 / 500\n",
      "----------\n",
      "train Loss: 0.042918\n",
      "val Loss: 0.066993\n",
      "\n",
      "Epoch 54 / 500\n",
      "----------\n",
      "train Loss: 0.042897\n",
      "val Loss: 0.066965\n",
      "\n",
      "Epoch 55 / 500\n",
      "----------\n",
      "train Loss: 0.042876\n",
      "val Loss: 0.066937\n",
      "\n",
      "Epoch 56 / 500\n",
      "----------\n",
      "train Loss: 0.042855\n",
      "val Loss: 0.066908\n",
      "\n",
      "Epoch 57 / 500\n",
      "----------\n",
      "train Loss: 0.042834\n",
      "val Loss: 0.066879\n",
      "\n",
      "Epoch 58 / 500\n",
      "----------\n",
      "train Loss: 0.042812\n",
      "val Loss: 0.066849\n",
      "\n",
      "Epoch 59 / 500\n",
      "----------\n",
      "train Loss: 0.042790\n",
      "val Loss: 0.066819\n",
      "\n",
      "Epoch 60 / 500\n",
      "----------\n",
      "train Loss: 0.042767\n",
      "val Loss: 0.066789\n",
      "\n",
      "Epoch 61 / 500\n",
      "----------\n",
      "train Loss: 0.042745\n",
      "val Loss: 0.066758\n",
      "\n",
      "Epoch 62 / 500\n",
      "----------\n",
      "train Loss: 0.042722\n",
      "val Loss: 0.066727\n",
      "\n",
      "Epoch 63 / 500\n",
      "----------\n",
      "train Loss: 0.042698\n",
      "val Loss: 0.066695\n",
      "\n",
      "Epoch 64 / 500\n",
      "----------\n",
      "train Loss: 0.042675\n",
      "val Loss: 0.066663\n",
      "\n",
      "Epoch 65 / 500\n",
      "----------\n",
      "train Loss: 0.042650\n",
      "val Loss: 0.066630\n",
      "\n",
      "Epoch 66 / 500\n",
      "----------\n",
      "train Loss: 0.042626\n",
      "val Loss: 0.066597\n",
      "\n",
      "Epoch 67 / 500\n",
      "----------\n",
      "train Loss: 0.042601\n",
      "val Loss: 0.066563\n",
      "\n",
      "Epoch 68 / 500\n",
      "----------\n",
      "train Loss: 0.042576\n",
      "val Loss: 0.066529\n",
      "\n",
      "Epoch 69 / 500\n",
      "----------\n",
      "train Loss: 0.042551\n",
      "val Loss: 0.066494\n",
      "\n",
      "Epoch 70 / 500\n",
      "----------\n",
      "train Loss: 0.042525\n",
      "val Loss: 0.066459\n",
      "\n",
      "Epoch 71 / 500\n",
      "----------\n",
      "train Loss: 0.042499\n",
      "val Loss: 0.066423\n",
      "\n",
      "Epoch 72 / 500\n",
      "----------\n",
      "train Loss: 0.042472\n",
      "val Loss: 0.066387\n",
      "\n",
      "Epoch 73 / 500\n",
      "----------\n",
      "train Loss: 0.042445\n",
      "val Loss: 0.066350\n",
      "\n",
      "Epoch 74 / 500\n",
      "----------\n",
      "train Loss: 0.042418\n",
      "val Loss: 0.066312\n",
      "\n",
      "Epoch 75 / 500\n",
      "----------\n",
      "train Loss: 0.042390\n",
      "val Loss: 0.066274\n",
      "\n",
      "Epoch 76 / 500\n",
      "----------\n",
      "train Loss: 0.042362\n",
      "val Loss: 0.066236\n",
      "\n",
      "Epoch 77 / 500\n",
      "----------\n",
      "train Loss: 0.042334\n",
      "val Loss: 0.066197\n",
      "\n",
      "Epoch 78 / 500\n",
      "----------\n",
      "train Loss: 0.042305\n",
      "val Loss: 0.066157\n",
      "\n",
      "Epoch 79 / 500\n",
      "----------\n",
      "train Loss: 0.042276\n",
      "val Loss: 0.066117\n",
      "\n",
      "Epoch 80 / 500\n",
      "----------\n",
      "train Loss: 0.042246\n",
      "val Loss: 0.066076\n",
      "\n",
      "Epoch 81 / 500\n",
      "----------\n",
      "train Loss: 0.042216\n",
      "val Loss: 0.066035\n",
      "\n",
      "Epoch 82 / 500\n",
      "----------\n",
      "train Loss: 0.042185\n",
      "val Loss: 0.065993\n",
      "\n",
      "Epoch 83 / 500\n",
      "----------\n",
      "train Loss: 0.042154\n",
      "val Loss: 0.065951\n",
      "\n",
      "Epoch 84 / 500\n",
      "----------\n",
      "train Loss: 0.042123\n",
      "val Loss: 0.065908\n",
      "\n",
      "Epoch 85 / 500\n",
      "----------\n",
      "train Loss: 0.042091\n",
      "val Loss: 0.065864\n",
      "\n",
      "Epoch 86 / 500\n",
      "----------\n",
      "train Loss: 0.042058\n",
      "val Loss: 0.065820\n",
      "\n",
      "Epoch 87 / 500\n",
      "----------\n",
      "train Loss: 0.042026\n",
      "val Loss: 0.065775\n",
      "\n",
      "Epoch 88 / 500\n",
      "----------\n",
      "train Loss: 0.041993\n",
      "val Loss: 0.065729\n",
      "\n",
      "Epoch 89 / 500\n",
      "----------\n",
      "train Loss: 0.041959\n",
      "val Loss: 0.065683\n",
      "\n",
      "Epoch 90 / 500\n",
      "----------\n",
      "train Loss: 0.041925\n",
      "val Loss: 0.065636\n",
      "\n",
      "Epoch 91 / 500\n",
      "----------\n",
      "train Loss: 0.041890\n",
      "val Loss: 0.065589\n",
      "\n",
      "Epoch 92 / 500\n",
      "----------\n",
      "train Loss: 0.041855\n",
      "val Loss: 0.065540\n",
      "\n",
      "Epoch 93 / 500\n",
      "----------\n",
      "train Loss: 0.041820\n",
      "val Loss: 0.065492\n",
      "\n",
      "Epoch 94 / 500\n",
      "----------\n",
      "train Loss: 0.041784\n",
      "val Loss: 0.065442\n",
      "\n",
      "Epoch 95 / 500\n",
      "----------\n",
      "train Loss: 0.041747\n",
      "val Loss: 0.065392\n",
      "\n",
      "Epoch 96 / 500\n",
      "----------\n",
      "train Loss: 0.041710\n",
      "val Loss: 0.065342\n",
      "\n",
      "Epoch 97 / 500\n",
      "----------\n",
      "train Loss: 0.041673\n",
      "val Loss: 0.065290\n",
      "\n",
      "Epoch 98 / 500\n",
      "----------\n",
      "train Loss: 0.041635\n",
      "val Loss: 0.065238\n",
      "\n",
      "Epoch 99 / 500\n",
      "----------\n",
      "train Loss: 0.041596\n",
      "val Loss: 0.065186\n",
      "\n",
      "Epoch 100 / 500\n",
      "----------\n",
      "train Loss: 0.041557\n",
      "val Loss: 0.065132\n",
      "\n",
      "Epoch 101 / 500\n",
      "----------\n",
      "train Loss: 0.041518\n",
      "val Loss: 0.065078\n",
      "\n",
      "Epoch 102 / 500\n",
      "----------\n",
      "train Loss: 0.041478\n",
      "val Loss: 0.065023\n",
      "\n",
      "Epoch 103 / 500\n",
      "----------\n",
      "train Loss: 0.041438\n",
      "val Loss: 0.064968\n",
      "\n",
      "Epoch 104 / 500\n",
      "----------\n",
      "train Loss: 0.041397\n",
      "val Loss: 0.064912\n",
      "\n",
      "Epoch 105 / 500\n",
      "----------\n",
      "train Loss: 0.041355\n",
      "val Loss: 0.064855\n",
      "\n",
      "Epoch 106 / 500\n",
      "----------\n",
      "train Loss: 0.041313\n",
      "val Loss: 0.064798\n",
      "\n",
      "Epoch 107 / 500\n",
      "----------\n",
      "train Loss: 0.041271\n",
      "val Loss: 0.064740\n",
      "\n",
      "Epoch 108 / 500\n",
      "----------\n",
      "train Loss: 0.041228\n",
      "val Loss: 0.064681\n",
      "\n",
      "Epoch 109 / 500\n",
      "----------\n",
      "train Loss: 0.041184\n",
      "val Loss: 0.064621\n",
      "\n",
      "Epoch 110 / 500\n",
      "----------\n",
      "train Loss: 0.041140\n",
      "val Loss: 0.064561\n",
      "\n",
      "Epoch 111 / 500\n",
      "----------\n",
      "train Loss: 0.041096\n",
      "val Loss: 0.064500\n",
      "\n",
      "Epoch 112 / 500\n",
      "----------\n",
      "train Loss: 0.041051\n",
      "val Loss: 0.064439\n",
      "\n",
      "Epoch 113 / 500\n",
      "----------\n",
      "train Loss: 0.041005\n",
      "val Loss: 0.064377\n",
      "\n",
      "Epoch 114 / 500\n",
      "----------\n",
      "train Loss: 0.040959\n",
      "val Loss: 0.064314\n",
      "\n",
      "Epoch 115 / 500\n",
      "----------\n",
      "train Loss: 0.040913\n",
      "val Loss: 0.064250\n",
      "\n",
      "Epoch 116 / 500\n",
      "----------\n",
      "train Loss: 0.040866\n",
      "val Loss: 0.064186\n",
      "\n",
      "Epoch 117 / 500\n",
      "----------\n",
      "train Loss: 0.040818\n",
      "val Loss: 0.064121\n",
      "\n",
      "Epoch 118 / 500\n",
      "----------\n",
      "train Loss: 0.040770\n",
      "val Loss: 0.064055\n",
      "\n",
      "Epoch 119 / 500\n",
      "----------\n",
      "train Loss: 0.040721\n",
      "val Loss: 0.063989\n",
      "\n",
      "Epoch 120 / 500\n",
      "----------\n",
      "train Loss: 0.040672\n",
      "val Loss: 0.063922\n",
      "\n",
      "Epoch 121 / 500\n",
      "----------\n",
      "train Loss: 0.040622\n",
      "val Loss: 0.063854\n",
      "\n",
      "Epoch 122 / 500\n",
      "----------\n",
      "train Loss: 0.040572\n",
      "val Loss: 0.063786\n",
      "\n",
      "Epoch 123 / 500\n",
      "----------\n",
      "train Loss: 0.040521\n",
      "val Loss: 0.063717\n",
      "\n",
      "Epoch 124 / 500\n",
      "----------\n",
      "train Loss: 0.040470\n",
      "val Loss: 0.063647\n",
      "\n",
      "Epoch 125 / 500\n",
      "----------\n",
      "train Loss: 0.040418\n",
      "val Loss: 0.063577\n",
      "\n",
      "Epoch 126 / 500\n",
      "----------\n",
      "train Loss: 0.040366\n",
      "val Loss: 0.063506\n",
      "\n",
      "Epoch 127 / 500\n",
      "----------\n",
      "train Loss: 0.040313\n",
      "val Loss: 0.063434\n",
      "\n",
      "Epoch 128 / 500\n",
      "----------\n",
      "train Loss: 0.040260\n",
      "val Loss: 0.063362\n",
      "\n",
      "Epoch 129 / 500\n",
      "----------\n",
      "train Loss: 0.040206\n",
      "val Loss: 0.063289\n",
      "\n",
      "Epoch 130 / 500\n",
      "----------\n",
      "train Loss: 0.040152\n",
      "val Loss: 0.063215\n",
      "\n",
      "Epoch 131 / 500\n",
      "----------\n",
      "train Loss: 0.040097\n",
      "val Loss: 0.063141\n",
      "\n",
      "Epoch 132 / 500\n",
      "----------\n",
      "train Loss: 0.040042\n",
      "val Loss: 0.063066\n",
      "\n",
      "Epoch 133 / 500\n",
      "----------\n",
      "train Loss: 0.039986\n",
      "val Loss: 0.062991\n",
      "\n",
      "Epoch 134 / 500\n",
      "----------\n",
      "train Loss: 0.039930\n",
      "val Loss: 0.062915\n",
      "\n",
      "Epoch 135 / 500\n",
      "----------\n",
      "train Loss: 0.039873\n",
      "val Loss: 0.062838\n",
      "\n",
      "Epoch 136 / 500\n",
      "----------\n",
      "train Loss: 0.039816\n",
      "val Loss: 0.062761\n",
      "\n",
      "Epoch 137 / 500\n",
      "----------\n",
      "train Loss: 0.039758\n",
      "val Loss: 0.062683\n",
      "\n",
      "Epoch 138 / 500\n",
      "----------\n",
      "train Loss: 0.039700\n",
      "val Loss: 0.062605\n",
      "\n",
      "Epoch 139 / 500\n",
      "----------\n",
      "train Loss: 0.039641\n",
      "val Loss: 0.062526\n",
      "\n",
      "Epoch 140 / 500\n",
      "----------\n",
      "train Loss: 0.039582\n",
      "val Loss: 0.062446\n",
      "\n",
      "Epoch 141 / 500\n",
      "----------\n",
      "train Loss: 0.039523\n",
      "val Loss: 0.062366\n",
      "\n",
      "Epoch 142 / 500\n",
      "----------\n",
      "train Loss: 0.039463\n",
      "val Loss: 0.062285\n",
      "\n",
      "Epoch 143 / 500\n",
      "----------\n",
      "train Loss: 0.039402\n",
      "val Loss: 0.062204\n",
      "\n",
      "Epoch 144 / 500\n",
      "----------\n",
      "train Loss: 0.039341\n",
      "val Loss: 0.062122\n",
      "\n",
      "Epoch 145 / 500\n",
      "----------\n",
      "train Loss: 0.039280\n",
      "val Loss: 0.062040\n",
      "\n",
      "Epoch 146 / 500\n",
      "----------\n",
      "train Loss: 0.039218\n",
      "val Loss: 0.061957\n",
      "\n",
      "Epoch 147 / 500\n",
      "----------\n",
      "train Loss: 0.039156\n",
      "val Loss: 0.061873\n",
      "\n",
      "Epoch 148 / 500\n",
      "----------\n",
      "train Loss: 0.039093\n",
      "val Loss: 0.061790\n",
      "\n",
      "Epoch 149 / 500\n",
      "----------\n",
      "train Loss: 0.039030\n",
      "val Loss: 0.061705\n",
      "\n",
      "Epoch 150 / 500\n",
      "----------\n",
      "train Loss: 0.038967\n",
      "val Loss: 0.061620\n",
      "\n",
      "Epoch 151 / 500\n",
      "----------\n",
      "train Loss: 0.038903\n",
      "val Loss: 0.061535\n",
      "\n",
      "Epoch 152 / 500\n",
      "----------\n",
      "train Loss: 0.038839\n",
      "val Loss: 0.061449\n",
      "\n",
      "Epoch 153 / 500\n",
      "----------\n",
      "train Loss: 0.038774\n",
      "val Loss: 0.061362\n",
      "\n",
      "Epoch 154 / 500\n",
      "----------\n",
      "train Loss: 0.038709\n",
      "val Loss: 0.061275\n",
      "\n",
      "Epoch 155 / 500\n",
      "----------\n",
      "train Loss: 0.038644\n",
      "val Loss: 0.061188\n",
      "\n",
      "Epoch 156 / 500\n",
      "----------\n",
      "train Loss: 0.038578\n",
      "val Loss: 0.061100\n",
      "\n",
      "Epoch 157 / 500\n",
      "----------\n",
      "train Loss: 0.038512\n",
      "val Loss: 0.061012\n",
      "\n",
      "Epoch 158 / 500\n",
      "----------\n",
      "train Loss: 0.038445\n",
      "val Loss: 0.060923\n",
      "\n",
      "Epoch 159 / 500\n",
      "----------\n",
      "train Loss: 0.038378\n",
      "val Loss: 0.060834\n",
      "\n",
      "Epoch 160 / 500\n",
      "----------\n",
      "train Loss: 0.038311\n",
      "val Loss: 0.060744\n",
      "\n",
      "Epoch 161 / 500\n",
      "----------\n",
      "train Loss: 0.038244\n",
      "val Loss: 0.060654\n",
      "\n",
      "Epoch 162 / 500\n",
      "----------\n",
      "train Loss: 0.038176\n",
      "val Loss: 0.060563\n",
      "\n",
      "Epoch 163 / 500\n",
      "----------\n",
      "train Loss: 0.038107\n",
      "val Loss: 0.060472\n",
      "\n",
      "Epoch 164 / 500\n",
      "----------\n",
      "train Loss: 0.038039\n",
      "val Loss: 0.060381\n",
      "\n",
      "Epoch 165 / 500\n",
      "----------\n",
      "train Loss: 0.037970\n",
      "val Loss: 0.060289\n",
      "\n",
      "Epoch 166 / 500\n",
      "----------\n",
      "train Loss: 0.037901\n",
      "val Loss: 0.060197\n",
      "\n",
      "Epoch 167 / 500\n",
      "----------\n",
      "train Loss: 0.037831\n",
      "val Loss: 0.060104\n",
      "\n",
      "Epoch 168 / 500\n",
      "----------\n",
      "train Loss: 0.037761\n",
      "val Loss: 0.060011\n",
      "\n",
      "Epoch 169 / 500\n",
      "----------\n",
      "train Loss: 0.037691\n",
      "val Loss: 0.059918\n",
      "\n",
      "Epoch 170 / 500\n",
      "----------\n",
      "train Loss: 0.037620\n",
      "val Loss: 0.059824\n",
      "\n",
      "Epoch 171 / 500\n",
      "----------\n",
      "train Loss: 0.037550\n",
      "val Loss: 0.059730\n",
      "\n",
      "Epoch 172 / 500\n",
      "----------\n",
      "train Loss: 0.037479\n",
      "val Loss: 0.059636\n",
      "\n",
      "Epoch 173 / 500\n",
      "----------\n",
      "train Loss: 0.037407\n",
      "val Loss: 0.059541\n",
      "\n",
      "Epoch 174 / 500\n",
      "----------\n",
      "train Loss: 0.037336\n",
      "val Loss: 0.059446\n",
      "\n",
      "Epoch 175 / 500\n",
      "----------\n",
      "train Loss: 0.037264\n",
      "val Loss: 0.059350\n",
      "\n",
      "Epoch 176 / 500\n",
      "----------\n",
      "train Loss: 0.037192\n",
      "val Loss: 0.059254\n",
      "\n",
      "Epoch 177 / 500\n",
      "----------\n",
      "train Loss: 0.037119\n",
      "val Loss: 0.059158\n",
      "\n",
      "Epoch 178 / 500\n",
      "----------\n",
      "train Loss: 0.037047\n",
      "val Loss: 0.059062\n",
      "\n",
      "Epoch 179 / 500\n",
      "----------\n",
      "train Loss: 0.036974\n",
      "val Loss: 0.058965\n",
      "\n",
      "Epoch 180 / 500\n",
      "----------\n",
      "train Loss: 0.036901\n",
      "val Loss: 0.058868\n",
      "\n",
      "Epoch 181 / 500\n",
      "----------\n",
      "train Loss: 0.036827\n",
      "val Loss: 0.058770\n",
      "\n",
      "Epoch 182 / 500\n",
      "----------\n",
      "train Loss: 0.036754\n",
      "val Loss: 0.058673\n",
      "\n",
      "Epoch 183 / 500\n",
      "----------\n",
      "train Loss: 0.036680\n",
      "val Loss: 0.058575\n",
      "\n",
      "Epoch 184 / 500\n",
      "----------\n",
      "train Loss: 0.036606\n",
      "val Loss: 0.058477\n",
      "\n",
      "Epoch 185 / 500\n",
      "----------\n",
      "train Loss: 0.036532\n",
      "val Loss: 0.058378\n",
      "\n",
      "Epoch 186 / 500\n",
      "----------\n",
      "train Loss: 0.036457\n",
      "val Loss: 0.058279\n",
      "\n",
      "Epoch 187 / 500\n",
      "----------\n",
      "train Loss: 0.036383\n",
      "val Loss: 0.058180\n",
      "\n",
      "Epoch 188 / 500\n",
      "----------\n",
      "train Loss: 0.036308\n",
      "val Loss: 0.058081\n",
      "\n",
      "Epoch 189 / 500\n",
      "----------\n",
      "train Loss: 0.036233\n",
      "val Loss: 0.057981\n",
      "\n",
      "Epoch 190 / 500\n",
      "----------\n",
      "train Loss: 0.036158\n",
      "val Loss: 0.057882\n",
      "\n",
      "Epoch 191 / 500\n",
      "----------\n",
      "train Loss: 0.036082\n",
      "val Loss: 0.057782\n",
      "\n",
      "Epoch 192 / 500\n",
      "----------\n",
      "train Loss: 0.036007\n",
      "val Loss: 0.057681\n",
      "\n",
      "Epoch 193 / 500\n",
      "----------\n",
      "train Loss: 0.035931\n",
      "val Loss: 0.057581\n",
      "\n",
      "Epoch 194 / 500\n",
      "----------\n",
      "train Loss: 0.035855\n",
      "val Loss: 0.057480\n",
      "\n",
      "Epoch 195 / 500\n",
      "----------\n",
      "train Loss: 0.035779\n",
      "val Loss: 0.057380\n",
      "\n",
      "Epoch 196 / 500\n",
      "----------\n",
      "train Loss: 0.035703\n",
      "val Loss: 0.057279\n",
      "\n",
      "Epoch 197 / 500\n",
      "----------\n",
      "train Loss: 0.035627\n",
      "val Loss: 0.057177\n",
      "\n",
      "Epoch 198 / 500\n",
      "----------\n",
      "train Loss: 0.035550\n",
      "val Loss: 0.057076\n",
      "\n",
      "Epoch 199 / 500\n",
      "----------\n",
      "train Loss: 0.035474\n",
      "val Loss: 0.056975\n",
      "\n",
      "Epoch 200 / 500\n",
      "----------\n",
      "train Loss: 0.035397\n",
      "val Loss: 0.056873\n",
      "\n",
      "Epoch 201 / 500\n",
      "----------\n",
      "train Loss: 0.035320\n",
      "val Loss: 0.056771\n",
      "\n",
      "Epoch 202 / 500\n",
      "----------\n",
      "train Loss: 0.035243\n",
      "val Loss: 0.056669\n",
      "\n",
      "Epoch 203 / 500\n",
      "----------\n",
      "train Loss: 0.035166\n",
      "val Loss: 0.056567\n",
      "\n",
      "Epoch 204 / 500\n",
      "----------\n",
      "train Loss: 0.035089\n",
      "val Loss: 0.056465\n",
      "\n",
      "Epoch 205 / 500\n",
      "----------\n",
      "train Loss: 0.035012\n",
      "val Loss: 0.056362\n",
      "\n",
      "Epoch 206 / 500\n",
      "----------\n",
      "train Loss: 0.034935\n",
      "val Loss: 0.056260\n",
      "\n",
      "Epoch 207 / 500\n",
      "----------\n",
      "train Loss: 0.034857\n",
      "val Loss: 0.056157\n",
      "\n",
      "Epoch 208 / 500\n",
      "----------\n",
      "train Loss: 0.034780\n",
      "val Loss: 0.056054\n",
      "\n",
      "Epoch 209 / 500\n",
      "----------\n",
      "train Loss: 0.034702\n",
      "val Loss: 0.055951\n",
      "\n",
      "Epoch 210 / 500\n",
      "----------\n",
      "train Loss: 0.034625\n",
      "val Loss: 0.055848\n",
      "\n",
      "Epoch 211 / 500\n",
      "----------\n",
      "train Loss: 0.034547\n",
      "val Loss: 0.055745\n",
      "\n",
      "Epoch 212 / 500\n",
      "----------\n",
      "train Loss: 0.034469\n",
      "val Loss: 0.055642\n",
      "\n",
      "Epoch 213 / 500\n",
      "----------\n",
      "train Loss: 0.034391\n",
      "val Loss: 0.055539\n",
      "\n",
      "Epoch 214 / 500\n",
      "----------\n",
      "train Loss: 0.034314\n",
      "val Loss: 0.055436\n",
      "\n",
      "Epoch 215 / 500\n",
      "----------\n",
      "train Loss: 0.034236\n",
      "val Loss: 0.055332\n",
      "\n",
      "Epoch 216 / 500\n",
      "----------\n",
      "train Loss: 0.034158\n",
      "val Loss: 0.055229\n",
      "\n",
      "Epoch 217 / 500\n",
      "----------\n",
      "train Loss: 0.034080\n",
      "val Loss: 0.055125\n",
      "\n",
      "Epoch 218 / 500\n",
      "----------\n",
      "train Loss: 0.034002\n",
      "val Loss: 0.055022\n",
      "\n",
      "Epoch 219 / 500\n",
      "----------\n",
      "train Loss: 0.033924\n",
      "val Loss: 0.054918\n",
      "\n",
      "Epoch 220 / 500\n",
      "----------\n",
      "train Loss: 0.033846\n",
      "val Loss: 0.054814\n",
      "\n",
      "Epoch 221 / 500\n",
      "----------\n",
      "train Loss: 0.033768\n",
      "val Loss: 0.054711\n",
      "\n",
      "Epoch 222 / 500\n",
      "----------\n",
      "train Loss: 0.033690\n",
      "val Loss: 0.054607\n",
      "\n",
      "Epoch 223 / 500\n",
      "----------\n",
      "train Loss: 0.033612\n",
      "val Loss: 0.054503\n",
      "\n",
      "Epoch 224 / 500\n",
      "----------\n",
      "train Loss: 0.033534\n",
      "val Loss: 0.054400\n",
      "\n",
      "Epoch 225 / 500\n",
      "----------\n",
      "train Loss: 0.033456\n",
      "val Loss: 0.054296\n",
      "\n",
      "Epoch 226 / 500\n",
      "----------\n",
      "train Loss: 0.033378\n",
      "val Loss: 0.054192\n",
      "\n",
      "Epoch 227 / 500\n",
      "----------\n",
      "train Loss: 0.033300\n",
      "val Loss: 0.054088\n",
      "\n",
      "Epoch 228 / 500\n",
      "----------\n",
      "train Loss: 0.033222\n",
      "val Loss: 0.053985\n",
      "\n",
      "Epoch 229 / 500\n",
      "----------\n",
      "train Loss: 0.033144\n",
      "val Loss: 0.053881\n",
      "\n",
      "Epoch 230 / 500\n",
      "----------\n",
      "train Loss: 0.033066\n",
      "val Loss: 0.053777\n",
      "\n",
      "Epoch 231 / 500\n",
      "----------\n",
      "train Loss: 0.032988\n",
      "val Loss: 0.053673\n",
      "\n",
      "Epoch 232 / 500\n",
      "----------\n",
      "train Loss: 0.032910\n",
      "val Loss: 0.053570\n",
      "\n",
      "Epoch 233 / 500\n",
      "----------\n",
      "train Loss: 0.032832\n",
      "val Loss: 0.053466\n",
      "\n",
      "Epoch 234 / 500\n",
      "----------\n",
      "train Loss: 0.032754\n",
      "val Loss: 0.053362\n",
      "\n",
      "Epoch 235 / 500\n",
      "----------\n",
      "train Loss: 0.032677\n",
      "val Loss: 0.053259\n",
      "\n",
      "Epoch 236 / 500\n",
      "----------\n",
      "train Loss: 0.032599\n",
      "val Loss: 0.053155\n",
      "\n",
      "Epoch 237 / 500\n",
      "----------\n",
      "train Loss: 0.032521\n",
      "val Loss: 0.053051\n",
      "\n",
      "Epoch 238 / 500\n",
      "----------\n",
      "train Loss: 0.032444\n",
      "val Loss: 0.052948\n",
      "\n",
      "Epoch 239 / 500\n",
      "----------\n",
      "train Loss: 0.032366\n",
      "val Loss: 0.052845\n",
      "\n",
      "Epoch 240 / 500\n",
      "----------\n",
      "train Loss: 0.032289\n",
      "val Loss: 0.052741\n",
      "\n",
      "Epoch 241 / 500\n",
      "----------\n",
      "train Loss: 0.032211\n",
      "val Loss: 0.052638\n",
      "\n",
      "Epoch 242 / 500\n",
      "----------\n",
      "train Loss: 0.032134\n",
      "val Loss: 0.052535\n",
      "\n",
      "Epoch 243 / 500\n",
      "----------\n",
      "train Loss: 0.032057\n",
      "val Loss: 0.052432\n",
      "\n",
      "Epoch 244 / 500\n",
      "----------\n",
      "train Loss: 0.031980\n",
      "val Loss: 0.052328\n",
      "\n",
      "Epoch 245 / 500\n",
      "----------\n",
      "train Loss: 0.031903\n",
      "val Loss: 0.052225\n",
      "\n",
      "Epoch 246 / 500\n",
      "----------\n",
      "train Loss: 0.031826\n",
      "val Loss: 0.052123\n",
      "\n",
      "Epoch 247 / 500\n",
      "----------\n",
      "train Loss: 0.031749\n",
      "val Loss: 0.052020\n",
      "\n",
      "Epoch 248 / 500\n",
      "----------\n",
      "train Loss: 0.031672\n",
      "val Loss: 0.051917\n",
      "\n",
      "Epoch 249 / 500\n",
      "----------\n",
      "train Loss: 0.031596\n",
      "val Loss: 0.051814\n",
      "\n",
      "Epoch 250 / 500\n",
      "----------\n",
      "train Loss: 0.031519\n",
      "val Loss: 0.051712\n",
      "\n",
      "Epoch 251 / 500\n",
      "----------\n",
      "train Loss: 0.031443\n",
      "val Loss: 0.051609\n",
      "\n",
      "Epoch 252 / 500\n",
      "----------\n",
      "train Loss: 0.031366\n",
      "val Loss: 0.051507\n",
      "\n",
      "Epoch 253 / 500\n",
      "----------\n",
      "train Loss: 0.031290\n",
      "val Loss: 0.051405\n",
      "\n",
      "Epoch 254 / 500\n",
      "----------\n",
      "train Loss: 0.031214\n",
      "val Loss: 0.051303\n",
      "\n",
      "Epoch 255 / 500\n",
      "----------\n",
      "train Loss: 0.031138\n",
      "val Loss: 0.051201\n",
      "\n",
      "Epoch 256 / 500\n",
      "----------\n",
      "train Loss: 0.031062\n",
      "val Loss: 0.051099\n",
      "\n",
      "Epoch 257 / 500\n",
      "----------\n",
      "train Loss: 0.030987\n",
      "val Loss: 0.050997\n",
      "\n",
      "Epoch 258 / 500\n",
      "----------\n",
      "train Loss: 0.030911\n",
      "val Loss: 0.050896\n",
      "\n",
      "Epoch 259 / 500\n",
      "----------\n",
      "train Loss: 0.030836\n",
      "val Loss: 0.050795\n",
      "\n",
      "Epoch 260 / 500\n",
      "----------\n",
      "train Loss: 0.030760\n",
      "val Loss: 0.050693\n",
      "\n",
      "Epoch 261 / 500\n",
      "----------\n",
      "train Loss: 0.030685\n",
      "val Loss: 0.050592\n",
      "\n",
      "Epoch 262 / 500\n",
      "----------\n",
      "train Loss: 0.030610\n",
      "val Loss: 0.050491\n",
      "\n",
      "Epoch 263 / 500\n",
      "----------\n",
      "train Loss: 0.030535\n",
      "val Loss: 0.050390\n",
      "\n",
      "Epoch 264 / 500\n",
      "----------\n",
      "train Loss: 0.030461\n",
      "val Loss: 0.050290\n",
      "\n",
      "Epoch 265 / 500\n",
      "----------\n",
      "train Loss: 0.030386\n",
      "val Loss: 0.050189\n",
      "\n",
      "Epoch 266 / 500\n",
      "----------\n",
      "train Loss: 0.030312\n",
      "val Loss: 0.050089\n",
      "\n",
      "Epoch 267 / 500\n",
      "----------\n",
      "train Loss: 0.030237\n",
      "val Loss: 0.049989\n",
      "\n",
      "Epoch 268 / 500\n",
      "----------\n",
      "train Loss: 0.030163\n",
      "val Loss: 0.049889\n",
      "\n",
      "Epoch 269 / 500\n",
      "----------\n",
      "train Loss: 0.030089\n",
      "val Loss: 0.049789\n",
      "\n",
      "Epoch 270 / 500\n",
      "----------\n",
      "train Loss: 0.030016\n",
      "val Loss: 0.049689\n",
      "\n",
      "Epoch 271 / 500\n",
      "----------\n",
      "train Loss: 0.029942\n",
      "val Loss: 0.049590\n",
      "\n",
      "Epoch 272 / 500\n",
      "----------\n",
      "train Loss: 0.029869\n",
      "val Loss: 0.049490\n",
      "\n",
      "Epoch 273 / 500\n",
      "----------\n",
      "train Loss: 0.029795\n",
      "val Loss: 0.049391\n",
      "\n",
      "Epoch 274 / 500\n",
      "----------\n",
      "train Loss: 0.029722\n",
      "val Loss: 0.049292\n",
      "\n",
      "Epoch 275 / 500\n",
      "----------\n",
      "train Loss: 0.029649\n",
      "val Loss: 0.049194\n",
      "\n",
      "Epoch 276 / 500\n",
      "----------\n",
      "train Loss: 0.029577\n",
      "val Loss: 0.049095\n",
      "\n",
      "Epoch 277 / 500\n",
      "----------\n",
      "train Loss: 0.029504\n",
      "val Loss: 0.048997\n",
      "\n",
      "Epoch 278 / 500\n",
      "----------\n",
      "train Loss: 0.029432\n",
      "val Loss: 0.048899\n",
      "\n",
      "Epoch 279 / 500\n",
      "----------\n",
      "train Loss: 0.029360\n",
      "val Loss: 0.048801\n",
      "\n",
      "Epoch 280 / 500\n",
      "----------\n",
      "train Loss: 0.029288\n",
      "val Loss: 0.048703\n",
      "\n",
      "Epoch 281 / 500\n",
      "----------\n",
      "train Loss: 0.029216\n",
      "val Loss: 0.048605\n",
      "\n",
      "Epoch 282 / 500\n",
      "----------\n",
      "train Loss: 0.029144\n",
      "val Loss: 0.048508\n",
      "\n",
      "Epoch 283 / 500\n",
      "----------\n",
      "train Loss: 0.029073\n",
      "val Loss: 0.048411\n",
      "\n",
      "Epoch 284 / 500\n",
      "----------\n",
      "train Loss: 0.029002\n",
      "val Loss: 0.048314\n",
      "\n",
      "Epoch 285 / 500\n",
      "----------\n",
      "train Loss: 0.028931\n",
      "val Loss: 0.048217\n",
      "\n",
      "Epoch 286 / 500\n",
      "----------\n",
      "train Loss: 0.028860\n",
      "val Loss: 0.048121\n",
      "\n",
      "Epoch 287 / 500\n",
      "----------\n",
      "train Loss: 0.028789\n",
      "val Loss: 0.048025\n",
      "\n",
      "Epoch 288 / 500\n",
      "----------\n",
      "train Loss: 0.028719\n",
      "val Loss: 0.047929\n",
      "\n",
      "Epoch 289 / 500\n",
      "----------\n",
      "train Loss: 0.028649\n",
      "val Loss: 0.047833\n",
      "\n",
      "Epoch 290 / 500\n",
      "----------\n",
      "train Loss: 0.028579\n",
      "val Loss: 0.047737\n",
      "\n",
      "Epoch 291 / 500\n",
      "----------\n",
      "train Loss: 0.028509\n",
      "val Loss: 0.047642\n",
      "\n",
      "Epoch 292 / 500\n",
      "----------\n",
      "train Loss: 0.028439\n",
      "val Loss: 0.047547\n",
      "\n",
      "Epoch 293 / 500\n",
      "----------\n",
      "train Loss: 0.028370\n",
      "val Loss: 0.047452\n",
      "\n",
      "Epoch 294 / 500\n",
      "----------\n",
      "train Loss: 0.028301\n",
      "val Loss: 0.047358\n",
      "\n",
      "Epoch 295 / 500\n",
      "----------\n",
      "train Loss: 0.028232\n",
      "val Loss: 0.047263\n",
      "\n",
      "Epoch 296 / 500\n",
      "----------\n",
      "train Loss: 0.028163\n",
      "val Loss: 0.047169\n",
      "\n",
      "Epoch 297 / 500\n",
      "----------\n",
      "train Loss: 0.028095\n",
      "val Loss: 0.047075\n",
      "\n",
      "Epoch 298 / 500\n",
      "----------\n",
      "train Loss: 0.028027\n",
      "val Loss: 0.046981\n",
      "\n",
      "Epoch 299 / 500\n",
      "----------\n",
      "train Loss: 0.027959\n",
      "val Loss: 0.046888\n",
      "\n",
      "Epoch 300 / 500\n",
      "----------\n",
      "train Loss: 0.027891\n",
      "val Loss: 0.046795\n",
      "\n",
      "Epoch 301 / 500\n",
      "----------\n",
      "train Loss: 0.027823\n",
      "val Loss: 0.046702\n",
      "\n",
      "Epoch 302 / 500\n",
      "----------\n",
      "train Loss: 0.027756\n",
      "val Loss: 0.046609\n",
      "\n",
      "Epoch 303 / 500\n",
      "----------\n",
      "train Loss: 0.027689\n",
      "val Loss: 0.046517\n",
      "\n",
      "Epoch 304 / 500\n",
      "----------\n",
      "train Loss: 0.027622\n",
      "val Loss: 0.046425\n",
      "\n",
      "Epoch 305 / 500\n",
      "----------\n",
      "train Loss: 0.027555\n",
      "val Loss: 0.046333\n",
      "\n",
      "Epoch 306 / 500\n",
      "----------\n",
      "train Loss: 0.027489\n",
      "val Loss: 0.046241\n",
      "\n",
      "Epoch 307 / 500\n",
      "----------\n",
      "train Loss: 0.027423\n",
      "val Loss: 0.046149\n",
      "\n",
      "Epoch 308 / 500\n",
      "----------\n",
      "train Loss: 0.027357\n",
      "val Loss: 0.046058\n",
      "\n",
      "Epoch 309 / 500\n",
      "----------\n",
      "train Loss: 0.027291\n",
      "val Loss: 0.045967\n",
      "\n",
      "Epoch 310 / 500\n",
      "----------\n",
      "train Loss: 0.027225\n",
      "val Loss: 0.045877\n",
      "\n",
      "Epoch 311 / 500\n",
      "----------\n",
      "train Loss: 0.027160\n",
      "val Loss: 0.045786\n",
      "\n",
      "Epoch 312 / 500\n",
      "----------\n",
      "train Loss: 0.027095\n",
      "val Loss: 0.045696\n",
      "\n",
      "Epoch 313 / 500\n",
      "----------\n",
      "train Loss: 0.027030\n",
      "val Loss: 0.045606\n",
      "\n",
      "Epoch 314 / 500\n",
      "----------\n",
      "train Loss: 0.026966\n",
      "val Loss: 0.045517\n",
      "\n",
      "Epoch 315 / 500\n",
      "----------\n",
      "train Loss: 0.026901\n",
      "val Loss: 0.045427\n",
      "\n",
      "Epoch 316 / 500\n",
      "----------\n",
      "train Loss: 0.026837\n",
      "val Loss: 0.045338\n",
      "\n",
      "Epoch 317 / 500\n",
      "----------\n",
      "train Loss: 0.026773\n",
      "val Loss: 0.045250\n",
      "\n",
      "Epoch 318 / 500\n",
      "----------\n",
      "train Loss: 0.026710\n",
      "val Loss: 0.045161\n",
      "\n",
      "Epoch 319 / 500\n",
      "----------\n",
      "train Loss: 0.026646\n",
      "val Loss: 0.045073\n",
      "\n",
      "Epoch 320 / 500\n",
      "----------\n",
      "train Loss: 0.026583\n",
      "val Loss: 0.044985\n",
      "\n",
      "Epoch 321 / 500\n",
      "----------\n",
      "train Loss: 0.026520\n",
      "val Loss: 0.044897\n",
      "\n",
      "Epoch 322 / 500\n",
      "----------\n",
      "train Loss: 0.026458\n",
      "val Loss: 0.044810\n",
      "\n",
      "Epoch 323 / 500\n",
      "----------\n",
      "train Loss: 0.026395\n",
      "val Loss: 0.044722\n",
      "\n",
      "Epoch 324 / 500\n",
      "----------\n",
      "train Loss: 0.026333\n",
      "val Loss: 0.044636\n",
      "\n",
      "Epoch 325 / 500\n",
      "----------\n",
      "train Loss: 0.026271\n",
      "val Loss: 0.044549\n",
      "\n",
      "Epoch 326 / 500\n",
      "----------\n",
      "train Loss: 0.026210\n",
      "val Loss: 0.044463\n",
      "\n",
      "Epoch 327 / 500\n",
      "----------\n",
      "train Loss: 0.026148\n",
      "val Loss: 0.044376\n",
      "\n",
      "Epoch 328 / 500\n",
      "----------\n",
      "train Loss: 0.026087\n",
      "val Loss: 0.044291\n",
      "\n",
      "Epoch 329 / 500\n",
      "----------\n",
      "train Loss: 0.026026\n",
      "val Loss: 0.044205\n",
      "\n",
      "Epoch 330 / 500\n",
      "----------\n",
      "train Loss: 0.025965\n",
      "val Loss: 0.044120\n",
      "\n",
      "Epoch 331 / 500\n",
      "----------\n",
      "train Loss: 0.025905\n",
      "val Loss: 0.044035\n",
      "\n",
      "Epoch 332 / 500\n",
      "----------\n",
      "train Loss: 0.025845\n",
      "val Loss: 0.043950\n",
      "\n",
      "Epoch 333 / 500\n",
      "----------\n",
      "train Loss: 0.025785\n",
      "val Loss: 0.043866\n",
      "\n",
      "Epoch 334 / 500\n",
      "----------\n",
      "train Loss: 0.025725\n",
      "val Loss: 0.043782\n",
      "\n",
      "Epoch 335 / 500\n",
      "----------\n",
      "train Loss: 0.025666\n",
      "val Loss: 0.043698\n",
      "\n",
      "Epoch 336 / 500\n",
      "----------\n",
      "train Loss: 0.025606\n",
      "val Loss: 0.043614\n",
      "\n",
      "Epoch 337 / 500\n",
      "----------\n",
      "train Loss: 0.025547\n",
      "val Loss: 0.043531\n",
      "\n",
      "Epoch 338 / 500\n",
      "----------\n",
      "train Loss: 0.025489\n",
      "val Loss: 0.043448\n",
      "\n",
      "Epoch 339 / 500\n",
      "----------\n",
      "train Loss: 0.025430\n",
      "val Loss: 0.043365\n",
      "\n",
      "Epoch 340 / 500\n",
      "----------\n",
      "train Loss: 0.025372\n",
      "val Loss: 0.043283\n",
      "\n",
      "Epoch 341 / 500\n",
      "----------\n",
      "train Loss: 0.025314\n",
      "val Loss: 0.043201\n",
      "\n",
      "Epoch 342 / 500\n",
      "----------\n",
      "train Loss: 0.025256\n",
      "val Loss: 0.043119\n",
      "\n",
      "Epoch 343 / 500\n",
      "----------\n",
      "train Loss: 0.025199\n",
      "val Loss: 0.043037\n",
      "\n",
      "Epoch 344 / 500\n",
      "----------\n",
      "train Loss: 0.025142\n",
      "val Loss: 0.042956\n",
      "\n",
      "Epoch 345 / 500\n",
      "----------\n",
      "train Loss: 0.025085\n",
      "val Loss: 0.042875\n",
      "\n",
      "Epoch 346 / 500\n",
      "----------\n",
      "train Loss: 0.025028\n",
      "val Loss: 0.042794\n",
      "\n",
      "Epoch 347 / 500\n",
      "----------\n",
      "train Loss: 0.024972\n",
      "val Loss: 0.042714\n",
      "\n",
      "Epoch 348 / 500\n",
      "----------\n",
      "train Loss: 0.024916\n",
      "val Loss: 0.042633\n",
      "\n",
      "Epoch 349 / 500\n",
      "----------\n",
      "train Loss: 0.024860\n",
      "val Loss: 0.042553\n",
      "\n",
      "Epoch 350 / 500\n",
      "----------\n",
      "train Loss: 0.024804\n",
      "val Loss: 0.042474\n",
      "\n",
      "Epoch 351 / 500\n",
      "----------\n",
      "train Loss: 0.024748\n",
      "val Loss: 0.042395\n",
      "\n",
      "Epoch 352 / 500\n",
      "----------\n",
      "train Loss: 0.024693\n",
      "val Loss: 0.042316\n",
      "\n",
      "Epoch 353 / 500\n",
      "----------\n",
      "train Loss: 0.024638\n",
      "val Loss: 0.042237\n",
      "\n",
      "Epoch 354 / 500\n",
      "----------\n",
      "train Loss: 0.024584\n",
      "val Loss: 0.042158\n",
      "\n",
      "Epoch 355 / 500\n",
      "----------\n",
      "train Loss: 0.024529\n",
      "val Loss: 0.042080\n",
      "\n",
      "Epoch 356 / 500\n",
      "----------\n",
      "train Loss: 0.024475\n",
      "val Loss: 0.042002\n",
      "\n",
      "Epoch 357 / 500\n",
      "----------\n",
      "train Loss: 0.024421\n",
      "val Loss: 0.041925\n",
      "\n",
      "Epoch 358 / 500\n",
      "----------\n",
      "train Loss: 0.024367\n",
      "val Loss: 0.041848\n",
      "\n",
      "Epoch 359 / 500\n",
      "----------\n",
      "train Loss: 0.024314\n",
      "val Loss: 0.041771\n",
      "\n",
      "Epoch 360 / 500\n",
      "----------\n",
      "train Loss: 0.024261\n",
      "val Loss: 0.041694\n",
      "\n",
      "Epoch 361 / 500\n",
      "----------\n",
      "train Loss: 0.024208\n",
      "val Loss: 0.041617\n",
      "\n",
      "Epoch 362 / 500\n",
      "----------\n",
      "train Loss: 0.024155\n",
      "val Loss: 0.041541\n",
      "\n",
      "Epoch 363 / 500\n",
      "----------\n",
      "train Loss: 0.024103\n",
      "val Loss: 0.041466\n",
      "\n",
      "Epoch 364 / 500\n",
      "----------\n",
      "train Loss: 0.024051\n",
      "val Loss: 0.041390\n",
      "\n",
      "Epoch 365 / 500\n",
      "----------\n",
      "train Loss: 0.023999\n",
      "val Loss: 0.041315\n",
      "\n",
      "Epoch 366 / 500\n",
      "----------\n",
      "train Loss: 0.023947\n",
      "val Loss: 0.041240\n",
      "\n",
      "Epoch 367 / 500\n",
      "----------\n",
      "train Loss: 0.023896\n",
      "val Loss: 0.041165\n",
      "\n",
      "Epoch 368 / 500\n",
      "----------\n",
      "train Loss: 0.023844\n",
      "val Loss: 0.041091\n",
      "\n",
      "Epoch 369 / 500\n",
      "----------\n",
      "train Loss: 0.023793\n",
      "val Loss: 0.041017\n",
      "\n",
      "Epoch 370 / 500\n",
      "----------\n",
      "train Loss: 0.023743\n",
      "val Loss: 0.040943\n",
      "\n",
      "Epoch 371 / 500\n",
      "----------\n",
      "train Loss: 0.023692\n",
      "val Loss: 0.040869\n",
      "\n",
      "Epoch 372 / 500\n",
      "----------\n",
      "train Loss: 0.023642\n",
      "val Loss: 0.040796\n",
      "\n",
      "Epoch 373 / 500\n",
      "----------\n",
      "train Loss: 0.023592\n",
      "val Loss: 0.040723\n",
      "\n",
      "Epoch 374 / 500\n",
      "----------\n",
      "train Loss: 0.023542\n",
      "val Loss: 0.040650\n",
      "\n",
      "Epoch 375 / 500\n",
      "----------\n",
      "train Loss: 0.023493\n",
      "val Loss: 0.040578\n",
      "\n",
      "Epoch 376 / 500\n",
      "----------\n",
      "train Loss: 0.023444\n",
      "val Loss: 0.040506\n",
      "\n",
      "Epoch 377 / 500\n",
      "----------\n",
      "train Loss: 0.023395\n",
      "val Loss: 0.040434\n",
      "\n",
      "Epoch 378 / 500\n",
      "----------\n",
      "train Loss: 0.023346\n",
      "val Loss: 0.040363\n",
      "\n",
      "Epoch 379 / 500\n",
      "----------\n",
      "train Loss: 0.023298\n",
      "val Loss: 0.040292\n",
      "\n",
      "Epoch 380 / 500\n",
      "----------\n",
      "train Loss: 0.023249\n",
      "val Loss: 0.040221\n",
      "\n",
      "Epoch 381 / 500\n",
      "----------\n",
      "train Loss: 0.023201\n",
      "val Loss: 0.040150\n",
      "\n",
      "Epoch 382 / 500\n",
      "----------\n",
      "train Loss: 0.023154\n",
      "val Loss: 0.040080\n",
      "\n",
      "Epoch 383 / 500\n",
      "----------\n",
      "train Loss: 0.023106\n",
      "val Loss: 0.040010\n",
      "\n",
      "Epoch 384 / 500\n",
      "----------\n",
      "train Loss: 0.023059\n",
      "val Loss: 0.039940\n",
      "\n",
      "Epoch 385 / 500\n",
      "----------\n",
      "train Loss: 0.023012\n",
      "val Loss: 0.039870\n",
      "\n",
      "Epoch 386 / 500\n",
      "----------\n",
      "train Loss: 0.022965\n",
      "val Loss: 0.039801\n",
      "\n",
      "Epoch 387 / 500\n",
      "----------\n",
      "train Loss: 0.022919\n",
      "val Loss: 0.039732\n",
      "\n",
      "Epoch 388 / 500\n",
      "----------\n",
      "train Loss: 0.022872\n",
      "val Loss: 0.039664\n",
      "\n",
      "Epoch 389 / 500\n",
      "----------\n",
      "train Loss: 0.022826\n",
      "val Loss: 0.039595\n",
      "\n",
      "Epoch 390 / 500\n",
      "----------\n",
      "train Loss: 0.022781\n",
      "val Loss: 0.039527\n",
      "\n",
      "Epoch 391 / 500\n",
      "----------\n",
      "train Loss: 0.022735\n",
      "val Loss: 0.039459\n",
      "\n",
      "Epoch 392 / 500\n",
      "----------\n",
      "train Loss: 0.022690\n",
      "val Loss: 0.039392\n",
      "\n",
      "Epoch 393 / 500\n",
      "----------\n",
      "train Loss: 0.022645\n",
      "val Loss: 0.039325\n",
      "\n",
      "Epoch 394 / 500\n",
      "----------\n",
      "train Loss: 0.022600\n",
      "val Loss: 0.039258\n",
      "\n",
      "Epoch 395 / 500\n",
      "----------\n",
      "train Loss: 0.022555\n",
      "val Loss: 0.039191\n",
      "\n",
      "Epoch 396 / 500\n",
      "----------\n",
      "train Loss: 0.022511\n",
      "val Loss: 0.039125\n",
      "\n",
      "Epoch 397 / 500\n",
      "----------\n",
      "train Loss: 0.022467\n",
      "val Loss: 0.039059\n",
      "\n",
      "Epoch 398 / 500\n",
      "----------\n",
      "train Loss: 0.022423\n",
      "val Loss: 0.038993\n",
      "\n",
      "Epoch 399 / 500\n",
      "----------\n",
      "train Loss: 0.022379\n",
      "val Loss: 0.038927\n",
      "\n",
      "Epoch 400 / 500\n",
      "----------\n",
      "train Loss: 0.022336\n",
      "val Loss: 0.038862\n",
      "\n",
      "Epoch 401 / 500\n",
      "----------\n",
      "train Loss: 0.022292\n",
      "val Loss: 0.038797\n",
      "\n",
      "Epoch 402 / 500\n",
      "----------\n",
      "train Loss: 0.022249\n",
      "val Loss: 0.038732\n",
      "\n",
      "Epoch 403 / 500\n",
      "----------\n",
      "train Loss: 0.022207\n",
      "val Loss: 0.038668\n",
      "\n",
      "Epoch 404 / 500\n",
      "----------\n",
      "train Loss: 0.022164\n",
      "val Loss: 0.038604\n",
      "\n",
      "Epoch 405 / 500\n",
      "----------\n",
      "train Loss: 0.022122\n",
      "val Loss: 0.038540\n",
      "\n",
      "Epoch 406 / 500\n",
      "----------\n",
      "train Loss: 0.022080\n",
      "val Loss: 0.038476\n",
      "\n",
      "Epoch 407 / 500\n",
      "----------\n",
      "train Loss: 0.022038\n",
      "val Loss: 0.038413\n",
      "\n",
      "Epoch 408 / 500\n",
      "----------\n",
      "train Loss: 0.021996\n",
      "val Loss: 0.038350\n",
      "\n",
      "Epoch 409 / 500\n",
      "----------\n",
      "train Loss: 0.021955\n",
      "val Loss: 0.038287\n",
      "\n",
      "Epoch 410 / 500\n",
      "----------\n",
      "train Loss: 0.021914\n",
      "val Loss: 0.038225\n",
      "\n",
      "Epoch 411 / 500\n",
      "----------\n",
      "train Loss: 0.021873\n",
      "val Loss: 0.038162\n",
      "\n",
      "Epoch 412 / 500\n",
      "----------\n",
      "train Loss: 0.021832\n",
      "val Loss: 0.038100\n",
      "\n",
      "Epoch 413 / 500\n",
      "----------\n",
      "train Loss: 0.021792\n",
      "val Loss: 0.038039\n",
      "\n",
      "Epoch 414 / 500\n",
      "----------\n",
      "train Loss: 0.021752\n",
      "val Loss: 0.037977\n",
      "\n",
      "Epoch 415 / 500\n",
      "----------\n",
      "train Loss: 0.021712\n",
      "val Loss: 0.037916\n",
      "\n",
      "Epoch 416 / 500\n",
      "----------\n",
      "train Loss: 0.021672\n",
      "val Loss: 0.037855\n",
      "\n",
      "Epoch 417 / 500\n",
      "----------\n",
      "train Loss: 0.021632\n",
      "val Loss: 0.037795\n",
      "\n",
      "Epoch 418 / 500\n",
      "----------\n",
      "train Loss: 0.021593\n",
      "val Loss: 0.037734\n",
      "\n",
      "Epoch 419 / 500\n",
      "----------\n",
      "train Loss: 0.021554\n",
      "val Loss: 0.037674\n",
      "\n",
      "Epoch 420 / 500\n",
      "----------\n",
      "train Loss: 0.021515\n",
      "val Loss: 0.037614\n",
      "\n",
      "Epoch 421 / 500\n",
      "----------\n",
      "train Loss: 0.021476\n",
      "val Loss: 0.037555\n",
      "\n",
      "Epoch 422 / 500\n",
      "----------\n",
      "train Loss: 0.021438\n",
      "val Loss: 0.037495\n",
      "\n",
      "Epoch 423 / 500\n",
      "----------\n",
      "train Loss: 0.021399\n",
      "val Loss: 0.037436\n",
      "\n",
      "Epoch 424 / 500\n",
      "----------\n",
      "train Loss: 0.021361\n",
      "val Loss: 0.037378\n",
      "\n",
      "Epoch 425 / 500\n",
      "----------\n",
      "train Loss: 0.021323\n",
      "val Loss: 0.037319\n",
      "\n",
      "Epoch 426 / 500\n",
      "----------\n",
      "train Loss: 0.021286\n",
      "val Loss: 0.037261\n",
      "\n",
      "Epoch 427 / 500\n",
      "----------\n",
      "train Loss: 0.021248\n",
      "val Loss: 0.037203\n",
      "\n",
      "Epoch 428 / 500\n",
      "----------\n",
      "train Loss: 0.021211\n",
      "val Loss: 0.037145\n",
      "\n",
      "Epoch 429 / 500\n",
      "----------\n",
      "train Loss: 0.021174\n",
      "val Loss: 0.037088\n",
      "\n",
      "Epoch 430 / 500\n",
      "----------\n",
      "train Loss: 0.021137\n",
      "val Loss: 0.037030\n",
      "\n",
      "Epoch 431 / 500\n",
      "----------\n",
      "train Loss: 0.021101\n",
      "val Loss: 0.036974\n",
      "\n",
      "Epoch 432 / 500\n",
      "----------\n",
      "train Loss: 0.021064\n",
      "val Loss: 0.036917\n",
      "\n",
      "Epoch 433 / 500\n",
      "----------\n",
      "train Loss: 0.021028\n",
      "val Loss: 0.036860\n",
      "\n",
      "Epoch 434 / 500\n",
      "----------\n",
      "train Loss: 0.020992\n",
      "val Loss: 0.036804\n",
      "\n",
      "Epoch 435 / 500\n",
      "----------\n",
      "train Loss: 0.020957\n",
      "val Loss: 0.036748\n",
      "\n",
      "Epoch 436 / 500\n",
      "----------\n",
      "train Loss: 0.020921\n",
      "val Loss: 0.036693\n",
      "\n",
      "Epoch 437 / 500\n",
      "----------\n",
      "train Loss: 0.020886\n",
      "val Loss: 0.036637\n",
      "\n",
      "Epoch 438 / 500\n",
      "----------\n",
      "train Loss: 0.020851\n",
      "val Loss: 0.036582\n",
      "\n",
      "Epoch 439 / 500\n",
      "----------\n",
      "train Loss: 0.020816\n",
      "val Loss: 0.036527\n",
      "\n",
      "Epoch 440 / 500\n",
      "----------\n",
      "train Loss: 0.020781\n",
      "val Loss: 0.036472\n",
      "\n",
      "Epoch 441 / 500\n",
      "----------\n",
      "train Loss: 0.020746\n",
      "val Loss: 0.036418\n",
      "\n",
      "Epoch 442 / 500\n",
      "----------\n",
      "train Loss: 0.020712\n",
      "val Loss: 0.036364\n",
      "\n",
      "Epoch 443 / 500\n",
      "----------\n",
      "train Loss: 0.020678\n",
      "val Loss: 0.036310\n",
      "\n",
      "Epoch 444 / 500\n",
      "----------\n",
      "train Loss: 0.020644\n",
      "val Loss: 0.036256\n",
      "\n",
      "Epoch 445 / 500\n",
      "----------\n",
      "train Loss: 0.020610\n",
      "val Loss: 0.036203\n",
      "\n",
      "Epoch 446 / 500\n",
      "----------\n",
      "train Loss: 0.020577\n",
      "val Loss: 0.036150\n",
      "\n",
      "Epoch 447 / 500\n",
      "----------\n",
      "train Loss: 0.020543\n",
      "val Loss: 0.036097\n",
      "\n",
      "Epoch 448 / 500\n",
      "----------\n",
      "train Loss: 0.020510\n",
      "val Loss: 0.036044\n",
      "\n",
      "Epoch 449 / 500\n",
      "----------\n",
      "train Loss: 0.020477\n",
      "val Loss: 0.035992\n",
      "\n",
      "Epoch 450 / 500\n",
      "----------\n",
      "train Loss: 0.020445\n",
      "val Loss: 0.035939\n",
      "\n",
      "Epoch 451 / 500\n",
      "----------\n",
      "train Loss: 0.020412\n",
      "val Loss: 0.035887\n",
      "\n",
      "Epoch 452 / 500\n",
      "----------\n",
      "train Loss: 0.020380\n",
      "val Loss: 0.035836\n",
      "\n",
      "Epoch 453 / 500\n",
      "----------\n",
      "train Loss: 0.020347\n",
      "val Loss: 0.035784\n",
      "\n",
      "Epoch 454 / 500\n",
      "----------\n",
      "train Loss: 0.020315\n",
      "val Loss: 0.035733\n",
      "\n",
      "Epoch 455 / 500\n",
      "----------\n",
      "train Loss: 0.020284\n",
      "val Loss: 0.035682\n",
      "\n",
      "Epoch 456 / 500\n",
      "----------\n",
      "train Loss: 0.020252\n",
      "val Loss: 0.035631\n",
      "\n",
      "Epoch 457 / 500\n",
      "----------\n",
      "train Loss: 0.020221\n",
      "val Loss: 0.035581\n",
      "\n",
      "Epoch 458 / 500\n",
      "----------\n",
      "train Loss: 0.020189\n",
      "val Loss: 0.035531\n",
      "\n",
      "Epoch 459 / 500\n",
      "----------\n",
      "train Loss: 0.020158\n",
      "val Loss: 0.035481\n",
      "\n",
      "Epoch 460 / 500\n",
      "----------\n",
      "train Loss: 0.020127\n",
      "val Loss: 0.035431\n",
      "\n",
      "Epoch 461 / 500\n",
      "----------\n",
      "train Loss: 0.020097\n",
      "val Loss: 0.035381\n",
      "\n",
      "Epoch 462 / 500\n",
      "----------\n",
      "train Loss: 0.020066\n",
      "val Loss: 0.035332\n",
      "\n",
      "Epoch 463 / 500\n",
      "----------\n",
      "train Loss: 0.020036\n",
      "val Loss: 0.035283\n",
      "\n",
      "Epoch 464 / 500\n",
      "----------\n",
      "train Loss: 0.020006\n",
      "val Loss: 0.035234\n",
      "\n",
      "Epoch 465 / 500\n",
      "----------\n",
      "train Loss: 0.019976\n",
      "val Loss: 0.035185\n",
      "\n",
      "Epoch 466 / 500\n",
      "----------\n",
      "train Loss: 0.019946\n",
      "val Loss: 0.035137\n",
      "\n",
      "Epoch 467 / 500\n",
      "----------\n",
      "train Loss: 0.019916\n",
      "val Loss: 0.035089\n",
      "\n",
      "Epoch 468 / 500\n",
      "----------\n",
      "train Loss: 0.019887\n",
      "val Loss: 0.035041\n",
      "\n",
      "Epoch 469 / 500\n",
      "----------\n",
      "train Loss: 0.019858\n",
      "val Loss: 0.034993\n",
      "\n",
      "Epoch 470 / 500\n",
      "----------\n",
      "train Loss: 0.019829\n",
      "val Loss: 0.034946\n",
      "\n",
      "Epoch 471 / 500\n",
      "----------\n",
      "train Loss: 0.019800\n",
      "val Loss: 0.034899\n",
      "\n",
      "Epoch 472 / 500\n",
      "----------\n",
      "train Loss: 0.019771\n",
      "val Loss: 0.034852\n",
      "\n",
      "Epoch 473 / 500\n",
      "----------\n",
      "train Loss: 0.019742\n",
      "val Loss: 0.034805\n",
      "\n",
      "Epoch 474 / 500\n",
      "----------\n",
      "train Loss: 0.019714\n",
      "val Loss: 0.034758\n",
      "\n",
      "Epoch 475 / 500\n",
      "----------\n",
      "train Loss: 0.019686\n",
      "val Loss: 0.034712\n",
      "\n",
      "Epoch 476 / 500\n",
      "----------\n",
      "train Loss: 0.019658\n",
      "val Loss: 0.034666\n",
      "\n",
      "Epoch 477 / 500\n",
      "----------\n",
      "train Loss: 0.019630\n",
      "val Loss: 0.034620\n",
      "\n",
      "Epoch 478 / 500\n",
      "----------\n",
      "train Loss: 0.019602\n",
      "val Loss: 0.034574\n",
      "\n",
      "Epoch 479 / 500\n",
      "----------\n",
      "train Loss: 0.019575\n",
      "val Loss: 0.034529\n",
      "\n",
      "Epoch 480 / 500\n",
      "----------\n",
      "train Loss: 0.019547\n",
      "val Loss: 0.034484\n",
      "\n",
      "Epoch 481 / 500\n",
      "----------\n",
      "train Loss: 0.019520\n",
      "val Loss: 0.034439\n",
      "\n",
      "Epoch 482 / 500\n",
      "----------\n",
      "train Loss: 0.019493\n",
      "val Loss: 0.034394\n",
      "\n",
      "Epoch 483 / 500\n",
      "----------\n",
      "train Loss: 0.019466\n",
      "val Loss: 0.034349\n",
      "\n",
      "Epoch 484 / 500\n",
      "----------\n",
      "train Loss: 0.019440\n",
      "val Loss: 0.034305\n",
      "\n",
      "Epoch 485 / 500\n",
      "----------\n",
      "train Loss: 0.019413\n",
      "val Loss: 0.034261\n",
      "\n",
      "Epoch 486 / 500\n",
      "----------\n",
      "train Loss: 0.019387\n",
      "val Loss: 0.034217\n",
      "\n",
      "Epoch 487 / 500\n",
      "----------\n",
      "train Loss: 0.019360\n",
      "val Loss: 0.034173\n",
      "\n",
      "Epoch 488 / 500\n",
      "----------\n",
      "train Loss: 0.019334\n",
      "val Loss: 0.034130\n",
      "\n",
      "Epoch 489 / 500\n",
      "----------\n",
      "train Loss: 0.019308\n",
      "val Loss: 0.034087\n",
      "\n",
      "Epoch 490 / 500\n",
      "----------\n",
      "train Loss: 0.019283\n",
      "val Loss: 0.034043\n",
      "\n",
      "Epoch 491 / 500\n",
      "----------\n",
      "train Loss: 0.019257\n",
      "val Loss: 0.034001\n",
      "\n",
      "Epoch 492 / 500\n",
      "----------\n",
      "train Loss: 0.019232\n",
      "val Loss: 0.033958\n",
      "\n",
      "Epoch 493 / 500\n",
      "----------\n",
      "train Loss: 0.019206\n",
      "val Loss: 0.033916\n",
      "\n",
      "Epoch 494 / 500\n",
      "----------\n",
      "train Loss: 0.019181\n",
      "val Loss: 0.033873\n",
      "\n",
      "Epoch 495 / 500\n",
      "----------\n",
      "train Loss: 0.019156\n",
      "val Loss: 0.033831\n",
      "\n",
      "Epoch 496 / 500\n",
      "----------\n",
      "train Loss: 0.019131\n",
      "val Loss: 0.033790\n",
      "\n",
      "Epoch 497 / 500\n",
      "----------\n",
      "train Loss: 0.019107\n",
      "val Loss: 0.033748\n",
      "\n",
      "Epoch 498 / 500\n",
      "----------\n",
      "train Loss: 0.019082\n",
      "val Loss: 0.033707\n",
      "\n",
      "Epoch 499 / 500\n",
      "----------\n",
      "train Loss: 0.019058\n",
      "val Loss: 0.033665\n",
      "\n",
      "Epoch 500 / 500\n",
      "----------\n",
      "train Loss: 0.019034\n",
      "val Loss: 0.033624\n",
      "\n",
      "Training complete in 41m 58.038667s\n",
      "Best val loss: 0.033624\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoderRNN(input_size, hidden_size, num_layers)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model, losses = train_model(model, criterion, optimizer)\n",
    "torch.save(model.state_dict(), './lstm_autoencoder_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training/val curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJkAAAJcCAYAAABaP3UWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XeUFeXhxvHvu7t0kC4gRUAU6YsUsVHUKNgLKhbsKGLFEjUxRqO/RMUkiGLviiJiQ0GNSrOhFAFRbCAIVoqUpQnL/P6Yi6wIusJeZsv3c857bpm5c59LzpxsnrzzToiiCEmSJEmSJGlbZCQdQJIkSZIkSUWfJZMkSZIkSZK2mSWTJEmSJEmStpklkyRJkiRJkraZJZMkSZIkSZK2mSWTJEmSJEmStpklkyRJkiRJkraZJZMkSRIQQrg7hPC3BL43CiE02cK2sSGEs7d3JkmSpK1hySRJkoq8EMKcEMKB23KMKIr6RlF0wx/83s9CCLtty/dKkiQVF5ZMkiSp2AshZKXhmLsAGVEUfVbQx5YkSSqKLJkkSVKRFkJ4DGgAvBhCyAkh/DmE0DB1GdpZIYSvgNGpfZ8OIXwXQlgaQhgfQmiR5zgPhxBuTD3vGkKYH0K4LITwQwjh2xDCGZt89aHAqBBCp9QxM/Mc6+gQwvTU844hhHdDCEtSx7kjhFB6K35nRgjhmhDC3FSmR0MIlVPbyoYQHg8hLEp9z8QQQq3UttNDCLNDCMtDCF+GEE7Oc8wzQwgzQwg/hhBeDSHsnHo/hBD+m/qepSGE6SGEln80syRJKlksmSRJUpEWRVFv4Cvg8CiKKkZRdEuezV2AZsDBqdcvA7sCOwJTgCG/cejaQGWgLnAWMDiEUDXP9kOAkVEUTQBWAPvn2XYS8ETqeS7QH6gB7AUcAPT7gz8T4PTU6AY0BioCd6S2nZbKWh+oDvQFVoUQKgCDgB5RFFUC9gamAoQQjgL+AhwD1ATeBJ5MHe8goDOwG1AFOAFYtBWZJUlSCWLJJEmSirProihaEUXRKoAoih6Momh5FEVrgOuANhtmA23GWuAfURStjaJoFJADNAUIIZQHOgDjUvs+CZyY2laJuIB6MvWdk6MomhBF0booiuYA9xCXX3/UycB/oiiaHUVRDnA10Ct1KeBa4nKpSRRFuanvXJb63HqgZQihXBRF30ZR9FHq/XOBf0VRNDOKonXAP4Hs1GymtUAlYHcgpPb5disyS5KkEsSSSZIkFWfzNjwJIWSGEG4KIcwKISwD5qQ21djCZxelypcNVhLPHoJ4NtI7URStTr1+AjgmhFCGeGbQlCiK5qa+d7cQwkupS+qWEZc5W/rO37ITMDfP67lAFlALeAx4FRgaQvgmhHBLCKFUFEUriGch9QW+DSGMDCHsnvr8zsBtqcvrlgCLgQDUjaJoNPEsqcHA9yGEe0MIO2xFZkmSVIJYMkmSpOIgysf7JwFHAgcSX1rWMPV+2IrvOwQY+fOXRNHHxKVPD355qRzAXcAnwK5RFO1AfIna1nznN8TF0AYNgHXA96nZVtdHUdSc+JK4w4BTU9lejaLoT0CdVI77Up+fB5wbRVGVPKNcFEXvpD43KIqidkAL4svmrtiKzJIkqQSxZJIkScXB98TrFP2WSsAa4rWFyhPPKNpaPYBRm7z3BHAR8VpGT2/yvcuAnNQsovO28jufBPqHEBqFECoS538qiqJ1IYRuIYRWqcXHlxFf7pYbQqgVQjgitTbTGuJL/nJTx7sbuHrD4uchhMohhONSzzuEEPYMIZQiXm9qdZ7PSZIkbZYlkyRJKg7+BVyTuvTr8i3s8yjxbKOvgY+BCVvzRam7rOVEUfTVJpueBLoCo6MoWpjn/cuJZzctJ55F9NTWfC/wIPFlceOBL4mLnwtT22oDw4kLppnEa0U9Tvy33mXEs6AWE68F1Q8giqLngJuJL7FbBswgLs8Adkhl/ZH432wRcOtW5pYkSSVEiKItzS6XJEnSpkIIfwZqRFH056SzSJIkFSZZSQeQJEkqYuYALyYdQpIkqbBxJpMkSZIkSZK2mWsySZIkSZIkaZsVm8vlatSoETVs2DDpGAVixYoVVKhQIekYUqHnuSLln+eLlD+eK1L+eK5I+VfUz5fJkycvjKKoZn72LTYlU8OGDZk0aVLSMQrE2LFj6dq1a9IxpELPc0XKP88XKX88V6T88VyR8q+ony8hhLn53dfL5SRJkiRJkrTN0loyhRC6hxA+DSF8EUK4ajPby4QQnkptfy+E0DD1/skhhKl5xvoQQnY6s0qSJEmSJGnrpa1kCiFkAoOBHkBz4MQQQvNNdjsL+DGKoibAf4GbAaIoGhJFUXYURdlAb2BOFEVT05VVkiRJkiRJ2yadazJ1BL6Iomg2QAhhKHAk8HGefY4Erks9Hw7cEUIIURRFefY5EXgyjTklSZIkSVIRtnbtWubPn8/q1auTjvIrlStXZubMmUnH+F1ly5alXr16lCpVaquPkc6SqS4wL8/r+cCeW9oniqJ1IYSlQHVgYZ59TiAuo34lhHAOcA5ArVq1GDt2bIEET1pOTk6x+S1SOnmuSPnn+SLlj+eKlD+eKypsKlasSK1atahbty4hhKTj/EJubi6ZmZlJx/hNURSxdOlSpk2bRk5OzlYfJ50l0+b+U43+yD4hhD2BlVEUzdjcF0RRdC9wL0D79u2jorxae15FfeV5aXvxXJHyz/NFyh/PFSl/PFdU2MycOZN69eoVuoIJYPny5VSqVCnpGL+rUqVK5OTk0L59+60+RjoX/p4P1M/zuh7wzZb2CSFkAZWBxXm298JL5SRJkiRJ0u8ojAVTUVIQ/37pLJkmAruGEBqFEEoTF0YjNtlnBHBa6nlPYPSG9ZhCCBnAccDQNGaUJEmSJElSAUhbyRRF0TrgAuBVYCYwLIqij0II/wghHJHa7QGgegjhC+BS4Ko8h+gMzN+wcLgkSZIkSVJhtGTJEu68886t+uwhhxzCkiVL8r3/ddddx6233rpV35Vu6VyTiSiKRgGjNnnv2jzPVxPPVtrcZ8cCndKZT5IkSZIkaVttKJn69ev3q225ubm/+dlRo0b95vaiJJ2Xy0mSJEmSJBV7V111FbNmzSI7O5srrriCsWPH0q1bN0466SQ6dYrnzxx11FG0a9eOFi1acO+99/782YYNG7Jw4ULmzJlDs2bN6NOnDy1atOCggw5i1apVv/m9U6dOpVOnTrRu3Zqjjz6aH3/8EYBBgwbRvHlzWrduTa9evQAYN24c2dnZZGdn07ZtW5YvX17g/w5pnckkSZIkSZK0PV3/4kd8/M2yAj1m85124O+Ht9ji9ptuuokZM2YwdepUIL4D4/vvv8+MGTOoUaMGAA8++CDVqlVj1apVdOjQgWOPPZbq1av/4jiff/45Tz75JPfddx/HH388zzzzDKeccsoWv/fUU0/l9ttvp0uXLlx77bVcf/31DBw4kJtuuokvv/ySMmXK/Hwp3q233srgwYPZZ599yMnJoWzZstv6z/IrzmSSJEmSJEkqYB07dqRRo0Y/vx40aBBt2rShU6dOzJs3j88///xXn2nUqBHZ2dkAtGvXjjlz5mzx+EuXLmXJkiV06dIFgNNOO43x48cD0Lp1a04++WQef/xxsrLi+UX77LMPl156KYMGDWLJkiU/v1+QnMkkSZIkSZKKjd+acbQ9VahQ4efnY8eO5fXXX+fdd9+lfPnydO3aldWrV//qM2XKlPn5eWZm5u9eLrclI0eOZPz48YwYMYIbbriBjz76iKuuuopDDz2UUaNG0alTJ15//XV23333rTr+ljiTSZIkSZIkaRtUqlTpN9c4Wrp0KVWrVqV8+fJ88sknTJgwYZu/s3LlylStWpU333wTgMcee4wuXbqwfv165s2bR7du3bjllltYsmQJOTk5zJo1i1atWnHllVfSvn17Pvnkk23OsClnMkmSJEmSJG2D6tWrs88++9CyZUt69OjBoYce+ovt3bt35+6776Z169Y0bdr058XAt9UjjzxC3759WblyJY0bN+ahhx4iNzeXU045haVLlxJFEf3796dKlSr87W9/Y8yYMWRmZtK8eXN69OhRIBnysmSSJEmSJEnaRk888cQvXnft2vXn52XKlOHll1/e7Oc2rLtUo0YNZsyY8fP7l19++Wb3v+66635+np2dvdlZUW+99dav3rv99tu3FL3AeLmcJEmSJEmStpklkyRJkiRJkraZJZMkSZIkSZK2mSWTJEmSJEmStpklkyRJkiRJkraZd5crbF68hHafjoV5jaHijlChZupxR6hYM35dYUeoUAMyMpNOK0mSJEmSBFgyFT5VG/JT6eqwajEs+BRW/AC5P21mxwDlq2+hiNrxl++XrwFZpbf7T5EkSZIkSZtXsWJFcnJy8v1+UWDJVNjsewkfrsuma9eu8esogtVLYcXCuHDK+QFWLEg9/gA5C+LHee/H769dufnjlq2ymSIqbyGV53Wpstvt50qSJEmSpOLBkqmwCwHKVYlHjSa/v/9PK7ZcRG14/9vpcWm1Zunmj1Fmh/hyvC3NjMr7fpmKBft7JUmSJEkqYq688kp23nln+vXrB8B1111HpUqVOPfcczn88MNZtmwZa9eu5cYbb+TII4/M1zGjKOLPf/4zL7/8MiEErrnmGk444QS+/fZbTjjhBJYtW8a6deu466672HvvvTnrrLOYNGkSIQTOPPNM+vfvn86fvFmWTMVN6QpQrVE8fs/a1XHptLkiasPjgs9gztvx5Xub/b6KULEWVKoDlWpvHBU3PK8DlWpBmUoF+zslSZIkSdqcl6+C7z4s2GPWbgU9btri5l69enHJJZf8XDINGzaMV155hbJlyzJkyBDq1q3LwoUL6dSpE0cccQQhhN/9ymeffZapU6cybdo0Fi5cSIcOHejcuTNPPPEEBx98MH/961/Jzc1l5cqVTJ06la+//poZM2YAsGTJkoL53X+QJVNJVqosVKkfj9+TuzbPJXt5Cqmc72H5d/H4enL8uG7Vrz9fuuIm5VOeEurnksoySpIkSZJU9LRt25YffviBb775hgULFlC1alUaNGjA2rVruf7665kwYQIZGRl8/fXXfP/999SuXft3j/nWW29x4oknkpmZSa1atejSpQsTJ06kQ4cOnHnmmaxdu5ajjjqK7OxsGjduzOzZs7nwwgs59NBDOeigg7bDr/41SyblT2Yp2KFOPH5LFMGaZRuLp+XfQc6G59/C8u/zV0ZVqgM71IUddoLKdWGHeqnn9aBc1fgyQkmSJEmSNvUbM47SqWfPngwfPpzvvvuOXr16ATBkyBAWLVrE5MmTKVWqFA0bNmT16tX5Ol4URZt9v3PnzowfP56RI0fSu3dvrrjiCk499VSmTZvGq6++yuDBgxk2bBgPPvhggf22/LJkUsEKAcpWjkfNplveb3Nl1PJvUzOjvoVl38Dct+PHKPeXn80qt5nyaZPnZatYREmSJEmStptevXrRp08fFi5cyLhx4wBYunQpNWrUoFSpUowZM4a5c+fm+3idO3fmnnvu4bTTTmPx4sWMHz+eAQMGMHfuXOrWrUufPn1YsWIFU6ZM4ZBDDqF06dIce+yx7LLLLpx++ulp+pW/zZJJychvGbU+N74sb9nX8Vj69S+ffzkuLqWi9b/8XKkKG2c+VakPVRpAlZ1Tjw3iy/YyMtL7GyVJkiRJJUaLFi1Yvnw5devWpU6d+Cqgk08+mUMOOYT27duTnZ3N7rvvnu/jHX300bz77ru0adOGEAK33HILtWvX5pFHHmHAgAGUKlWKihUr8uijj/L1119zxhlnsH59/L+N//Wvf6XlN/4eSyYVbhmZeS7Ta7/5fXLXxTOgNltEzYdPX4nXkMors3SqgGqQZ1hCSZIkSZK23ocf/nLB8Ro1avDGG29QqdKv1x/OycnZ7DE2vB9CYMCAAQwYMOAX20877TROO+20X31uypQpWxu7wFgyqejLzIovkatcd8v7/LQyLpyWfAVL5qYeU+P3SqiqDaFa43hUTd25r3SFtP4kSZIkSZKKGksmlQyly0PN3eKxOWtXpUqoTQqoH+fCzBdh5aJf7l+xdqp4SpVOPxdQjaFclfT/HkmSJEmSChlLJgmgVDmosWs8Nmf1Ulj8JSyeDT+mHhd/CbPGwNQhv9y3XLWNxVO1xlBtl43HLvPrKZKSJEmSpG0XRRHBG0BttS3dze6PsGSS8qNsZdgpOx6b+mkl/DhnkwJqNsx7H2Y888tFySvVSRVOu8WjepP4cYe6rgElSZIkSVupbNmyLFq0iOrVq1s0bYUoili0aBFly5bdpuNYMknbqnR5qNU8Hpta91NcQC38LDU+h0Wfw/SnYc3SjfuVKp8qnDYUULtCjabxY1aZ7fZTJEmSJKkoqlevHvPnz2fBggVJR/mV1atXb3N5sz2ULVuWevXqbdMxLJmkdMoqvfm1oKIIVizIUz59ET/OnwQzngVS0xRDZlw+7dgMdmy+8bFao/jOe5IkSZIkSpUqRaNGjZKOsVljx46lbdu2ScfYLiyZpCSEABV3jEfDfX+5be0qWDQLFnwSjx9mwrfT4OMX+Ll8yiobz3jaUDzVahE/7lA3PrYkSZIkSduZJZNU2JQqB7VbxiOvn1bAgk/j0umHj+PHL8fD9KEb9ymzQ1w21W6VGq3jIqpU4Z+aKUmSJEkq2iyZpKKidAWou0c88lr1I/zwycbi6fuPYNpTMPH+eHvIhJpNN5ZOGwqo8tW2/2+QJEmSJBVblkxSUVeuKuy8Vzw2WL8elsyB7z6Eb6fHj1+Oh+lPbdyncv2NpdNObePyquKO2z2+JEmSJKl4sGSSiqOMDKjWOB7Nj9z4fs4C+C5VOm14/HQUP6/1tEPdjYXTTnvEz8tVSeQnSJIkSZKKFksmqSSpWBOaHBCPDdbkxIXT11Pgmynx4ycvbdxerXFcOG0onuq0ji/dkyRJkiQpD0smqaQrUxF23jseG6xcDN9OTRVPH8Dcd2DG8HhbyIAdW0D9jvGo1yEuoryrnSRJkiSVaJZMkn6tfDXYZf94bLD8u7hw+noyzJ8I04fBpAdS+9fIUzp1jC+zK10+meySJEmSpERYMknKn0q1oWmPeACsz43vZjf/fZg3Eea9l1rfCcjIihcUr5cqnhp0gsr1kssuSZIkSUo7SyZJWycjE2q3jEf7M+P3ViyKZznNey9+/OAxeP+eeFuVBrDzPqmxt5fYSZIkSVIxY8kkqeBUqA5Nu8cDIHcdfD8DvpoAc9+Cz/8H056Mt1Wqs3EtqJ33gZq7WzpJkiRJUhFmySQpfTKzYKfseHTqC1EECz+DuW/DnLfjxxnPxPuWrw4N9ooLp4b7QK1WkJGRbH5JkiRJUr5ZMknafkKAmk3j0f7MuHT6cU5cNs19J3785KV433LVoNF+0LgrNOri5XWSJEmSVMhZMklKTghQrVE82p4Sv7f0a5jzJsweB1+Og49fiN+vXD8umxp3hUadoVKtpFJLkiRJkjbDkklS4VK5LrTpFY8ogkWzYPaYuHD65CWY+ni8X81mNCm9C9ReGV9eV7ZysrklSZIkqYSzZJJUeIUANZrEo2MfWJ8L302H2WNh9jjqzPkfDH0JQibU3xOaHAC7/sn1nCRJkiQpAZZMkoqOjEzYqW089u3P22/8j86Ny8KsMfDF6zD6hnhU2BGaHBiXTrvsD+WrJZ1ckiRJkoo9SyZJRdb6zNLx+kyNOsOBf4fl38Os0fDFa/DZyzDtCQgZULddqnT6U3ynu4zMpKNLkiRJUrFjySSp+KhUC7JPjMf6XPh6SjzD6YvXYexNMPZf8V3rmhwAu3WPH8tVTTq1JEmSJBULlkySiqeMTKjfIR7droYVi+IFxDeUTh8+Ha/ltPPe0PQQaNodqjVOOrUkSZIkFVmWTJJKhgrVoVXPeKxfD19Phk9HwWevwKtXx6Pm7tC0B+zWA+q197I6SZIkSfoDLJkklTwZGRtnOR34d1j8ZVw2ffoyvHM7vPVfKF8jvqSuaXdo3A3KVEw6tSRJkiQVapZMklStEXQ6Lx6rlsSX0332CnzyIkx9HDLLwC7doNnh8aV13q1OkiRJkn7FkkmS8ipXZeNldblr4asJ8WV1M1+Mi6eQCY32g2ZHwO6HxYuNS5IkSZIsmSRpizJLxYVSo/3g4H/CNx/AzBHw8QgYeSmMvAwa7AXNj4hnOVWul3RiSZIkSUqMJZMk5UcIUHePeBzwd/hh5sbC6ZWr4lG3XTzDqdnhUH2XpBNLkiRJ0nZlySRJf1QIUKt5PLpeBYtmwccvxKXT63+PR+1W0PJYaHEMVN056cSSJEmSlHaWTJK0rarvAvtdGo8l8+Ky6aPn4PXr4lGvQ1w4NT8KdqiTdFpJkiRJSgtLJkkqSFXqw17nx+PHOXHZNOOZ1CV1V0PDfaHlMdDsSKhQPem0kiRJklRgMpIOIEnFVtWGsG9/6PsWnD8xvrQu53t4qT/cuis8fixMfQJWL006qSRJkiRtM2cySdL2UHO3uGTqciV8PyOe3TTjGXj+PMgsDbseBK2Ph926Q1aZpNNKkiRJ0h9mySRJ21MI8aLgtVvFd6n7egrMGB4XTp+8BGUrQ4ujoXUvaNAp3l+SJEmSigBLJklKSghQr108/nQDfDkWpj0F04fB5Iehys7Q+gRo0yteXFySJEmSCjFLJkkqDDKzoMmB8ViTAzNfhOlDYfwAGH8L1G0fl00tjnHBcEmSJEmFkiWTJBU2ZSpC9onxWPYNfPh0PMNp1OXxXep2PSie4dS0h+s3SZIkSSo0LJkkqTDbYSfY5+J4fDcjnt00/Wn4dBSUqwqtjoe2p0Cd1kknlSRJklTCWTJJUlFRuyXUvhEOvB5mj4EPhsDkh+D9e+KFxNv2hlbHQflqSSeVJEmSVAJZMklSUZORuXH9ppWL4cPhMPVxePnP8L9roOkhceG0S7d4X0mSJEnaDiyZJKkoK18N9jwnHt99GM9umv4UfPw8VNoptbbTyd6dTpIkSVLaZSQdQJJUQGq3gh43wWWfwPGPxpfXvfVfuH0PeLAHTH0S1q5KOqUkSZKkYsqSSZKKm6wy0PxIOPlp6P8xHPB3yPkenu8L/24KL18JP8xMOqUkSZKkYsaSSZKKsx3qwH6XwoWT4bQX43WcJj4Ad3aCBw6GaUOd3SRJkiSpQLgmkySVBCFAo87xWLEQpj4Bkx+G586NFwxvcyK0Ox12bJZ0UkmSJElFlDOZJKmkqVAD9rnI2U2SJEmSCpQzmSSppPrN2U1X5pndtHvSSSVJkiQVAc5kkiRtZnbTATDxfrhzz/jOdDOegdy1SaeUJEmSVIg5k0mStNHmZjdNegCGnwkVa8Uzm9qdES8oLkmSJEl5OJNJkrR5P89u+gBOehrqtIFxt8DAljDsNJjzFkRR0iklSZIkFRLOZJIk/baMDNjtoHgsng2THoQpj8HHz0PNZtDxbGh9ApSplHRSSZIkSQlyJpMkKf+qNYaDboTLPoEjB0NWaRh5Gfy7GYy6AhZ8mnRCSZIkSQlxJpMk6Y8rVQ7angLZJ8P8STDxvvjOdO/fG6/n1KEPND0EMv2vGUmSJKmk8K9/SdLWCwHqd4jHQf8HHzwKEx+EYb1hh3rQsQ/scSqUr5Z0UkmSJElp5uVykqSCUbEm7HcZXDwNThgC1RrB63+H/zSHl/p7KZ0kSZJUzDmTSZJUsDKzoNlh8fhuBrx3F3wwJF4wfJcDoNN58WOG/z+HJEmSVJz4F74kKX1qt4wXCL/0Y9j/Gvj+IxjSEwZ3hPfvgzU5SSeUJEmSVEAsmSRJ6VehBnS+Ai75EI65H8pUglGXx5fS/e8aWPJV0gklSZIkbSNLJknS9pNVGlofB31Gw1mvQZP94d074bY28FRvmPsuRFHSKSVJkiRtBddkkiRtfyFA/Y7xWDo/vnRu8sMwcwTUyYa9LoAWR0FmqaSTSpIkSconZzJJkpJVuR786Xq4dCYc9l9YuxKePRtuy4Z37oDVy5JOKEmSJCkfLJkkSYVD6fLQ/kzo9x6c+BRUawT/+yv8t0W8btPS+UknlCRJkvQbLJkkSYVLRgY07Q6nvwR9xsCuf9q4btMzfeDbaUknlCRJkrQZlkySpMKr7h7Q80G4eCp0PBc+HQX3dIZHDofPX3ORcEmSJKkQsWSSJBV+VRpA939C/4/gwOth4RcwpCfcuRdMeQzWrUk6oSRJklTipbVkCiF0DyF8GkL4IoRw1Wa2lwkhPJXa/l4IoWGeba1DCO+GED4KIXwYQiibzqySpCKgXBXY9xK4eBocfQ9kZMGIC2BgKxg/AFYuTjqhJEmSVGKlrWQKIWQCg4EeQHPgxBBC8012Owv4MYqiJsB/gZtTn80CHgf6RlHUAugKrE1XVklSEZNVGtr0gr5vQu/noVZLGH1jvEj4yMvhxzlJJ5QkSZJKnHTOZOoIfBFF0ewoin4ChgJHbrLPkcAjqefDgQNCCAE4CJgeRdE0gCiKFkVRlJvGrJKkoigE2KUb9H4WznsHWhwNkx+GQXvA8LPguw+TTihJkiSVGCFK06KpIYSeQPcois5Ove4N7BlF0QV59pmR2md+6vUsYE/gFKAdsCNQExgaRdEtm/mOc4BzAGrVqtVu6NChafkt21tOTg4VK1ZMOoZU6HmuaHNKr1lEvfkj2OmbV8jKXc2iau34qsExLK3cIi6lSijPFyl/PFek/PFckfKvqJ8v3bp1mxxFUfv87JuVxhyb+0t+00ZrS/tkAfsCHYCVwBshhMlRFL3xix2j6F7gXoD27dtHXbt23dbMhcLYsWMpLr9FSifPFW3ZsbDqR5h4P9Un3E31qX+Feh1gn0ug6SGQUfLue+H5IuWP54qUP54rUv6VpPMlnX9lzwfq53ldD/hmS/uk1mGqDCxOvT8uiqKFURStBEYBe6QxqySpuClXFTpfAf1nwCG3Qs4P8NTJcOee8MEQWPdT0gklSZKkYiWdJdNEYNcQQqMQQmmgFzBik31GAKelnvcERkfx9XuvAq1DCOVT5VMX4OM0ZpUkFVelykHHPnDhFDj2AcgsDS/0g0HZ8O5gWJOTdEJJkiSpWEhbyRRF0TrgAuLCaCYwLIqij0II/whmE9/nAAAgAElEQVQhHJHa7QGgegjhC+BS4KrUZ38E/kNcVE0FpkRRNDJdWSVJJUBmFrTqCX3fgpOfgaqN4NW/xHekG/1/sGJh0gklSZKkIi2dazIRRdEo4kvd8r53bZ7nq4HjtvDZx4HH05lPklQChQC7HhiPeRPh7YEw/hZ453bYozfsdQFU3TnplJIkSVKRU/JWPpUkaYP6HaDXEDj/fWh5LEx6CAa1hWfPgR8+STqdJEmSVKRYMkmSVLMpHDUYLp4Ge/aFmS/CnZ3gqVPgm6lJp5MkSZKKBEsmSZI2qFwXuv8TLpkBnS+H2ePh3i7weE/4akLS6SRJkqRCzZJJkqRNVagO+18D/T+E/f8G30yBBw+Ghw6FWaMhipJOKEmSJBU6lkySJG1J2crxjKZLPoSD/wWLZ8FjR8P9B8Ano2D9+qQTSpIkSYWGJZMkSb+ndAXYq1+8ZtNhA2HFQhh6Ity9L3w4HNbnJp1QkiRJSpwlkyRJ+ZVVBtqfARdOgaPvgfXr4JmzYHBH+OBxyF2bdEJJkiQpMZZMkiT9UZlZ0KYX9JsAxz8KpcrDC+fDoLbw/n2wdlXSCSVJkqTtzpJJkqStlZEBzY+Ec8fDSU/DDjvBqMthYGt4exCsyUk6oSRJkrTdWDJJkrStQoDdDoIzX4XTXoJazeG1v8HAljB+AKxelnRCSZIkKe0smSRJKighQKP94NQX4Ow3oP6eMPrGuGwaezOsWpJ0QkmSJCltLJkkSUqHeu3hpKfgnLGw874w9p/xZXRj/gkrFyedTpIkSSpwlkySJKXTTm3hxCfg3DehcWcYd3NcNr1xg2WTJEmSihVLJkmStoc6reGEx+G8d2DXA+HNf8PAVvDa32HFwqTTSZIkSdvMkkmSpO2pVgs47mHo9y7s1h3evi0um/53DeT8kHQ6SZIkaatZMkmSlIQdm0HPB+D896HZ4fDu4Pgyulf+Asu/SzqdJEmS9IdZMkmSlKSau8Ex98IFk6DlMfDe3XBbG3j5Slj2TdLpJEmSpHyzZJIkqTCovgscdSdcOAlaHQcT74/LppGXwdL5SaeTJEmSfpclkyRJhUm1xnDkHXDhFMg+CSY/Ardlw4uXwJKvkk4nSZIkbZElkyRJhVHVneHw2+CiD2CPU2HqEBjUFkZcZNkkSZKkQsmSSZKkwqxKfTjsP3DRVGh3Bkx7EgbtAS/19zI6SZIkFSqWTJIkFQWV68Kht26c2TTlsXhm08jLYOnXSaeTJEmSLJkkSSpSKtdLzWz6ALJPjtdsGpQNo66AZd8mnU6SJEklmCWTJElFUZX6cPhAuGgKtDkRJj0Y343u5Sth+XdJp5MkSVIJZMkkSVJRVqUBHDEILpwMrY+H9++Ly6ZXrobl3yedTpIkSSWIJZMkScVB1YZw5B1w4SRoeSy8d09cNr36V8j5Iel0kiRJKgEsmSRJKk6qNYaj7oQLJkKLo2DCnTCwNY1nPQQ5C5JOJ0mSpGLMkkmSpOKo+i5w9N1w/kRofgT1542A21rDa9fCikVJp5MkSVIxZMkkSVJxVqMJHHMvEzvcDrsfCm8PgoGt4PXrYOXipNNJkiSpGLFkkiSpBFhZoR4cez/0mwC7HQxvDYzLpjf+YdkkSZKkAmHJJElSSbLj7nDcQ9DvXWhyILz5bxjYGkbfCKt+TDqdJEmSijBLJkmSSqIdm8Hxj8B578Au3WD8gLhsGvMvWL006XSSJEkqgiyZJEkqyWq1gBMeg75vQaPOMO6muGwafyusyUk6nSRJkooQSyZJkgS1W0GvIXDOOKi/J4y+Ib4b3Tu3w08rk04nSZKkIsCSSZIkbbRTNpw8DM56HWq3hv9dA4Oy4b17YN2apNNJkiSpELNkkiRJv1a/A5z6PJw+Cqo3gZf/DIPawqQHYd1PSaeTJElSIWTJJEmStqzhPnD6SOj9POywE7zUH+5oBx88Drnrkk4nSZKkQsSSSZIk/bYQ4jvQnfUanPQ0lKsGL5wPgzvC9GGwPjfphJIkSSoELJkkSVL+hAC7HQTnjIUThkBWWXi2D9y1N3z0PKxfn3RCSZIkJciSSZIk/TEhQLPDoO9b0PMhiNbD06fBPZ3hk1EQRUknlCRJUgIsmSRJ0tbJyICWx0C/CXD0vbB2BQw9Ee7bHz5/3bJJkiSphLFkkiRJ2yYjE9qcAOdPhCPugBULYcix8ODBMHtc0ukkSZK0nVgySZKkgpGZBXv0hgsnw6H/gSXz4NEj4OHDYO67SaeTJElSmlkySZKkgpVVGjqcBRd9AN1vggWfwkPd4bGjYf7kpNNJkiQpTSyZJElSepQqC53Og4unwZ/+Ad9Mhfv3hydOgG+nJZ1OkiRJBcySSZIkpVfp8rDPxXDJdNj/Gvjq3fhOdE/1hh9mJp1OkiRJBcSSSZIkbR9lKkHnK+Di6dDlSpg1Bu7cC4afBQs/TzqdJEmStpElkyRJ2r7KVYFuf4lnNu17CXw6CgZ3hOfOg8VfJp1OkiRJW8mSSZIkJaN8NTjwunhmU6d+8NGzcEd7GHFRfGc6SZIkFSmWTJIkKVkVa8LB/wcXTYX2Z8K0J+H2PWDk5bDs26TTSZIkKZ8smSRJUuGwQx04ZABcOAXanAiTH4JB2fDqXyFnQdLpJEmS9DssmSRJUuFSpT4cMQgumAQtjoEJd8JtbeD162Dl4qTTSZIkaQssmSRJUuFUrREcfRec/z407QFvDYSBrWHMP2HVkqTTSZIkaROWTJIkqXCrsSv0fADOewd26QrjbobbWsP4AbBmedLpJEmSlGLJJEmSioZazeGEx+Hc8dBgLxh9Y3wZ3du3wU8rk04nSZJU4lkySZKkoqVOGzjpKTj7jfj5a9fGZdOEu2Dt6qTTSZIklViWTJIkqWiq1x56PwdnvAI1m8IrV8GgtjDxAVj3U9LpJEmSShxLJkmSVLTtvBec/hKcOiK+M93IS+GOdjDlMchdl3Q6SZKkEsOSSZIkFQ+Nu8CZr8LJz0D56jDiAhjcAaY9Betzk04nSZJU7FkySZKk4iME2PVA6DMGej0JpSrAc+fAnXvBR8/B+vVJJ5QkSSq2LJkkSVLxEwLsfkh8J7rjHonfe/p0uGc/+GQkRFGi8SRJkoojSyZJklR8ZWRAi6Og37twzH2wdhUMPQnu6wafv2bZJEmSVIAsmSRJUvGXkQmtj4fz34cjB8PKRTCkJzxwEMwel3Q6SZKkYsGSSZIklRyZWdD2FLhgMhz2X1j2NTx6BDx8GMx9N+l0kiRJRZolkyRJKnmySkP7M+HCKdD9ZljwKTzUHR47GuZPTjqdJElSkWTJJEmSSq5SZaFTX7h4GvzpBvh2Gty/PzxxQvxckiRJ+WbJJEmSVLo87HNRXDbt/zf4agLc0xmeOgW+/zjpdJIkSUWCJZMkSdIGZSpB58vhkunQ5ap4UfC79obhZ8LCz5NOJ0mSVKhZMkmSJG2qbGXodnU8s2nf/vDpKzC4Izx3Hiz+Mul0kiRJhZIlkyRJ0paUrwYH/j0umzr1g4+ehTvaw4iLYMm8pNNJkiQVKpZMkiRJv6diTTj4/+Kyqf1ZMO1JuH0PGHk5LPs26XSSJEmFgiWTJElSflWqDYfcAhd9ANknweSHYFA2vPIXyFmQdDpJkqREWTJJkiT9UZXrweG3wQWToOWx8N5dcFtreO3vsHJx0ukkSZISYckkSZK0tao1gqPuhPMnwu6Hwtu3wcDWMOafsGpJ0ukkSZK2K0smSZKkbVWjCRx7P/R7F5rsD+Nujmc2jR8Aa5YnnU6SJGm7sGSSJEkqKDs2g+MfhXPfhAZ7w+gb4bY28Qynn1YmnU6SJCmtLJkkSZIKWp3WcNJQOHs01MmG166Ny6YJd8Ha1UmnkyRJSgtLJkmSpHSp1w56Pwtnvgo1m8IrV8GgtjDxAVj3U9LpJEmSCpQlkyRJUro16ASnvwSnvQhVGsDIS+H2djD5Echdm3Q6SZKkAmHJJEmStL006gxnvgKnPAMVa8KLF8Vl05THLJskSVKRZ8kkSZK0PYUATQ6Es9+Ak56G8tVgxAVwR3v44HHLJkmSVGRZMkmSJCUhBNjtIOgzBk4aBmWrwAvnwx0d4IMhkLsu6YSSJEl/iCWTJElSkkKA3Q6Gc8bCiUOh7A7wQj8Y3AGmPmnZJEmSigxLJkmSpMIgBGjaA84ZB72ehNIV4fm+MLgjTBtq2SRJkgo9SyZJkqTCJATY/RA4dzycMARKlYfnzoU794Tpw2B9btIJJUmSNsuSSZIkqTAKAZodliqbHoessvBsHxi8J0x/2rJJkiQVOpZMkiRJhVlGBjQ7HM59E45/DDJLw7Nnw52d4MPhlk2SJKnQsGSSJEkqCjIyoPkR0PctOO4RyMiCZ86CO/eCGc/A+vVJJ5QkSSWcJZMkSVJRkpEBLY6Cvm/DcQ9DyIDhZ8Jde8GMZy2bJElSYiyZJEmSiqKMDGhxNJz3DvR8EKIIhp8Bd+0NHz1n2SRJkrY7SyZJkqSiLCMDWh4L/d6FYx+AKBeePh3u3hc+fsGySZIkbTeWTJIkScVBRia06gn9JsAx90PuTzDsVLhnP/h4hGWTJElKu7SWTCGE7iGET0MIX4QQrtrM9jIhhKdS298LITRMvd8whLAqhDA1Ne5OZ05JkqRiIyMTWh8H578Hx9wH61bDsN5wT2eY+aJlkyRJSpu0lUwhhExgMNADaA6cGEJovsluZwE/RlHUBPgvcHOebbOiKMpOjb7pyilJklQsZWRC6+Oh33tw9D2wdiU8dUp8GZ1rNkmSpDRI50ymjsAXURTNjqLoJ2AocOQm+xwJPJJ6Phw4IIQQ0phJkiSpZMnMgja94Pz345lN69fGazbdtRd8OBzW5yadUJIkFRMhiqL0HDiEnkD3KIrOTr3uDewZRdEFefaZkdpnfur1LGBPoCLwEfAZsAy4JoqiNzfzHecA5wDUqlWr3dChQ9PyW7a3nJwcKlasmHQMqdDzXJHyz/NFP4tyqbngHRrOGUaFlV+xslxd5u58HD/s2JkoIzPpdInzXJHyx3NFyr+ifr5069ZtchRF7fOzb1Yac2xuRtKmjdaW9vkWaBBF0aIQQjvg+RBCiyiKlv1ixyi6F7gXoH379lHXrl23PXUhMHbsWIrLb5HSyXNFyj/PF/3SAbD+rzBzBOXHD6DZJwNp9v0L0PlyaH0CZJZKOmBiPFek/PFckfKvJJ0v6bxcbj5QP8/resA3W9onhJAFVAYWR1G0JoqiRQBRFE0GZgG7pTGrJElSyZKRAS2OgnPfhBOGQJlK8ML5cHs7mPwIrPsp6YSSJKmISWfJNBHYNYTQKIRQGugFjNhknxHAaannPYHRURRFIYSaqYXDCSE0BnYFZqcxqyRJUsmUkQHNDoNzx8OJT0H56vDiRXD7HjDxAVi3JumEkiSpiEhbyRRF0TrgAuBVYCYwLIqij0II/wghHJHa7QGgegjhC+BS4KrU+52B6SGEacQLgveNomhxurJKkiSVeCFA0+7QZzSc/AxUqg0jL4XbsuG9e2Ht6qQTSpKkQi6dazIRRdEoYNQm712b5/lq4LjNfO4Z4Jl0ZpMkSdJmhAC7HghNDoDZY2HczfDyFfDmv2Gfi6Hd6VC6fNIpJUlSIZTOy+UkSZJUVIUAu3SDM16G016CGrvCq1fDba3h7UHw04qkE0qSpELGkkmSJElbFgI02g9OfykunGq1hNf+BgNbwZv/gTXLk04oSZIKCUsmSZIk5c/Oe8Opz8NZr8FOe8Ab18dl0/gBsHpp0ukkSVLCLJkkSZL0x9TvCKcMjxcJr98JRt8Yl01j/gUrvVeLJEkllSWTJEmStk7ddnDSUDhnHDTcD8bdFJdNr10LOT8knU6SJG1nlkySJEnaNjtlQ68hcN47sFt3eOf2uGwadQUsmZd0OkmStJ1YMkmSJKlg1GoBPR+ACyZBq54w6UEY1BZeuAAWzUo6nSRJSjNLJkmSJBWs6rvAkYPhoqnQ/gz48Gm4oz0MPwu+/zjpdJIkKU0smSRJkpQeVerDIQPgkg9h7wvhs1fgrr3gyZPg68lJp5MkSQXMkkmSJEnpVXFH+NM/4rKp69Uw9224b3949CiY83bS6SRJUgGxZJIkSdL2Ub4adL0K+s+AA6+H72fAw4fAg93h89chipJOKEmStoElkyRJkravMpVg30vimU09BsR3oBtyLNzbFT4eAevXJ51QkiRtBUsmSZIkJaNUOdjzHLjoAzjidlizDIb1jtdtmj4MctclnVCSJP0BlkySJElKVlZp2ONUOH8iHPsAhAx4tg/c0Q4mPwzr1iSdUJIk5YMlkyRJkgqHzCxo1RP6vg29noBy1eDFi2FQW3j3TliTk3RCSZL0GyyZJEmSVLhkZMDuh0Kf0dD7OajaCF69Gga2hDH/gpWLk04oSZI2w5JJkiRJhVMIsMv+cMZIOOt1aLA3jLsJ/tsCXrkals5POqEkScrDkkmSJEmFX/0OcOIT0O89aH4UvH8v3NYGnu8HCz5NOp0kScKSSZIkSUXJjrvD0XfFd6TrcDbMeBYG7wlDT4b5k5NOJ0lSiWbJJEmSpKKnSgPocTP0/wi6/BnmvAX37w8PHwZfvAFRlHRCSZJKHEsmSZIkFV0VqkO3v8Rl08H/hEWz4PFj4J7O8Syn9blJJ5QkqcSwZJIkSVLRV6Yi7HU+XDwVjrgD1q6E4WfAHe1h8sOwbk3SCSVJKvYsmSRJklR8ZJWBPXrD+e/D8Y9B2crw4sUwsDW8fRusXpZ0QkmSii1LJkmSJBU/GZnQ/AjoMwZOfSFeMPy1a2FgS3jjBshZkHRCSZKKHUsmSZIkFV8hQOOucdHUZ0z8/M1/x2XTi5fEazhJkqQCYckkSZKkkqHuHnD8o3DBJGjTC6Y+Abe3g6Enw7z3k04nSVKRZ8kkSZKkkqVGEzj8Nug/A/a7DOa8BQ/8CR44mOoL34P165NOKElSkWTJJEmSpJKp4o5wwN+g/0fQ/WZY9g2tZvwTBneM70i3dnXSCSVJKlIsmSRJklSylakInfrCRR/wcbPLoHT51B3pWsH4W2HVj0knlCSpSLBkkiRJkgAys/ihVmc4ZxycOgJqt4LRN8B/WsDLV8GSr5JOKElSoZaVdABJkiSpUAkBGneJx3cz4J3bYeJ98P690OJo2OciqNMm6ZSSJBU6zmSSJEmStqR2SzjmHrh4GnQ6Dz57Fe7pDI8cAV+8AVGUdEJJkgoNSyZJkiTp91SuBwf/X3xHugOvh4WfwePHwN37wbSnIHdt0gklSUqcJZMkSZKUX+WqwL6XxDObjhwM69fCc+fAbW3g7dtg1ZKkE0qSlBhLJkmSJOmPyioDbU+B896Fk4ZBtcbw2rXwn+bw8pWweHbSCSVJ2u5c+FuSJEnaWhkZsNvB8fh2Oky4EyY+wP+zd+fhUZb3/sffz0wymWwz2ZfJZE9ICJBAEnZQkEWQTUTQ2mPbU+1uW/VXe+xm7XpsTzdbu2nVttaqgOyLCIKKiEKAsIV9zcYS9i0EyPP7444s1iUqYbJ8Xtd1X5PM8wz9ptc1Mnzyvb83b/8V8kdB33sgrY8ZJi4iItLOqZNJRERERORqSC6E8X+Be9fDwPthzzJ4egQ8cQOsn6q5TSIi0u4pZBIRERERuZo8yTDkIbhvI4z6NZw9Di/eBY9219wmERFp1xQyiYiIiIi0BFc49LwbvrYSPvUCxGS+a27TrkBXKCIiclVpJpOIiIiISEtyOCBvhFm1a2H5n2Dl38zcps6joc/XNLdJRETaBXUyiYiIiIhcK8lFcMtf4d4NZm7TrqWa2yQiIu2GQiYRERERkWvtnblN91eYuU31xzS3SURE2jyFTCIiIiIigfLO3KZ7yuBTz1+a2/TbLjDvAajbHugKRUREmk0zmUREREREAs3hgLyRZtWuhbf+DKv+Diseh5xh0OfLkHWDuU9ERKSV0t9SIiIiIiKtSXIRjP8L3LcRBn3HhE7/mgB/6g0rnoCzJwNdoYiIyHtSyCQiIiIi0hpFJMCgB03YNP5xs7Vu3rfgNwWw4HtweFegKxQREbmCQiYRERERkdYsyAVFt8EXlsBdCyFniNlO9/se8NwdsOt1sO1AVykiIqKZTCIiIiIibYJlQWovs45VQ9mTUPY0bJkLCV2g95egcBIEhwa6UhER6aDUySQiIiIi0tZ4U2DIQ3B/BYx9zARQs78Bv+kMix6GY1WBrlBERDoghUwiIiIiIm1VcCgU3wlffgM+NxfS+8OyR+F3hTD5s7D3LW2lExGRa0bb5URERERE2jrLgowBZh3ZAyseh9XPQMUMSCqEXl+EbrdqK52IiLQodTKJiIiIiLQn0elw48/MVrpRv4YL52DWPfDrfHj5+zqVTkREWoxCJhERERGR9igkAnreDV9dDp+dA1nXw/I/mVPpnp0E2xZCY2OgqxQRkXakWSGTZVnftCzLYxlPWpa12rKs4S1dnIiIiIiIfEKWBZkDYdI/4d71cN0DULMGnr0VHiuBNx+DM0cCXaWIiLQDze1k+rxt28eB4UA88N/AIy1WlYiIiIiIXH3eFLjhe3DfRpjwJIQnwMvfg193hllfh33rA12hiIi0Yc0d/G01Pd4EPG3b9lrLsqwPeoGIiIiIiLRSQS4zCLzbrVC7DlY+AeumwOp/Qmof6PUF6DzW3CciItJMzQ2ZVlmW9TKQCXzHsqxIQBu4W8DM8mqW7mygJnQv3tBgosKC8YY2rbBgIkOCUL4nIiIiIldNciGM/QMM+zGseRZW/g1evAsiEqHkc2Z5fIGuUkRE2oDmhkx3Ad2BnbZtn7YsKwazZU6uspnlNSzeeo6pW9+7VdnpsPC4g5pCJ5cJoppCqCsCqdBgot653vS8O9h5jX8aEREREWkzQqOh3z3Q56uw4xVY8QS89kt4/VfQeYzpbkrvb2Y8iYiIvIfmhkx9gXLbtk9ZlvVfQDHwaMuV1XE9+dlSXl78KkWlfTl6poFjp89x7Mw5jp45x/Ez5zh62ffHzpzj2OkG9h46dfF6o/3+f3ZIkOOyAOqdMOrKICoqLBjPFcGVC487iCCnDiIUERER6RAcDsgdZtbhXVD2JKx+BipmQFwelH4eim4zoZSIiMhlmhsy/RkosiyrCPg28CTwT+D6liqso7IsixCnRZLXTZLX/ZFe29hoc+Ls+SvCKBNINTQFUk3fNz1WH61nU+0Jjp5u4FTDhQ/8syNDgvC8K6C6FEi53qeTKpgIbe8TERERabtiMmH4T2HQd2HjdCh7Cl76H1j0MHSdYAKnlGJ1N4mICND8kOm8bdu2ZVnjgEdt237SsqzPtmRh8tE5HNbFgCc15qO99tyFxkuh1OmmrqmmTqqLXVOXBVXbDpy8+H3DhfcfzxXksIgOdxET5iI6PJiYcBfRYa4rH991PTTYqWBKREREpDVxhUGPT5tVu9aETeumQPm/IKnQhE3dJkJIRKArFRGRAGpuyHTCsqzvAHcCAy3LcgLBLVeWXGvBTgdxESHERYR8pNfZtk39ucaL3VIXO6hOm5Dq6OlzHDndwOFTDRw5dY6t+09y5FQDR043vO/WvpAgx3uEUMFEh7uIvSKUMtdjwl0EazufiIiIyLWRXARjHoVhP4H1k2HlUzDnXnj5B2YbXennIbFLoKsUEZEAaG7IdBtwB/B527b3WZaVBvxfy5UlbYVlWYS6nIS6Qkn2hjb7dY2NNsfrz3H4VMPFZcKoy0OpBg6fbqDqyGkOn2rgeP359/3zosKCm0Iy18Ww7IqvIy99rwHoIiIiIleB2wM974bSu6ByheluWv2MOZ0utbcJmwpuhuCPNgJCRETarmaFTE3B0rNAT8uyRgMrbNv+Z8uWJu2Zw2ERFeYiKsxFVnzzXnPuQuO7OqMaqDvVwKGTZ6k7eZa6Ew3UnTzLxprj1J04y4mz7x1KRYQEvSuAchEbboKo+AgXCR43CZEhJES6cQWpQ0pERETkA1kWpPU2a8T/Qvm/TeA0/Uvw0oPQ/dMmcIrNDnSlIiLSwpoVMlmWNQnTufQqYAF/sCzrAdu2p7ZgbSJXCHY6iI8MIT6yeVv66s9doO7kWQ6dNOGTWQ0cPHGWQ6caqDtxlh0HT/L2rrMcOX3uPf+MmHAXCZEhJDYFT4keN4mekItBVKLHTXxkiLbriYiIiACExUC/e6DPV2H36yZsevsvsPwxyBpkwqa8m8CpyRsiIu1Rc7fLfQ/oadv2AQDLsuKBRYBCJmm13MFO/NFh+KPDPvTe8xcaOXyqgQMnznLw5FkOHK9n//Gz7G96PHiini37TnDw5FkuvGuYlGVBbLiLhEg3CZ4QEiNNEJXodePzhpIc5SbZG4rHrZP2REREpINwOEyolDUITuwz2+hW/R0mfwYiEk13U/FnzOl1IiLSbjQ3ZHK8EzA1OQSodUPajSCnw3QneT54ZsCFRptDp85yoCmAOnDiUhB14Hg9+0/UU1FznLqTZ/9jsHm4y0lyVCjJl4VPPm8ovqhLX4e6NC9KRERE2pnIJLj+ARh4P2xbCKuehmW/gzd+A5nXQ8lnIX80BH20A2hERKT1aW7I9JJlWQuA55q+vw2Y1zIlibReTodlOpYi3XRN8b7vfecvNHLw5Flqjp6h5mg9tccuPdYeq2dT7QnqTp79j9dFhQWT7A3F53XjiwrFHx1KakwYqdFh+KNDiQoLVjeUiIiItE0OJ+SNMOtYNZQ/azqcpn4ewmKh6FNQ/FmI7xToSkVE5GNq7uDvByzLmgD0x8xkety27ektWplIGxbkdJDsNSfulaS/9z1nz19g/7Gz1Bw7c2UIdbSemmP1rNx9+D9O1IsICcIfHdq0DfCdAMp8nxoTSqRb8w1ERESkDfCmwPXfhoH/D3YugVX/uDS7Ka2vCZsKxoHrw8ceiIhI69HcTiZs234ReLEFaxHpUEKCnKTFhpEW+/4fno7Xn6Pq8Bkqj5ym8vBpqo6coerIaaqOnAfTIXMAACAASURBVGb5jjpONVy44n5vaDCpMaH4o0zolB4bTkZsOBlxYSR7Q3E61AUlIiIirYjDCTlDzTp5wJxMt/ofMOPLMP9/oHCS2U6X1C3QlYqISDN8YMhkWdYJwH6vS4Bt27anRaoSEQA87mAKfMEU+P7zrWbbNkdPn6PyiAmf3gmhKo+cZvvBkyzZcoCz5xsv3u9yOkiNCSUjNtyET3FhJoCKDccX5SZIJ+SJiIhIIEUkwIB7of83YfcbJmxa/U9Y+QT4ik3Y1HUChEQGulIREXkfHxgy2bat/4KLtFKWZREd7iI63EWhP+o/rjc22uw/Uc/uutPsOXSK3YdOs7vuFLsPneLNHYc4c+5SF1SQwyI1Joz0WBM8ZcWHkx0fQXZ8BImeEM2BEhERkWvHsiBzoFkjD8O6F8x2utnfhJe+C90mQPHnIKXY3CsiIq1Gs7fLiUjb4nBYF+dC9c2OveKabdscPHH2iuBpz6HT7D50ipW7Dl+xDS/c5SQ7IaIpdAonqyl8yogLIyRIp+GJiIhICwqLgT5fgd5fhqqVJmxaP9V0OCV2heLPQLeJ5j4REQk4hUwiHZBlWSR43CR43PTKvPJDmW3bHDhxlh0HTrLj4El2HDzFjoMnWbHrMNPXVF+8z2FBakzYxfApOz6CnIQIchMj8YZqALmIiIhcRZYFqb3MGvG/sH6K2U43/9vw8vch7ybocSdkDzZznkREJCAUMonIFSzLItHjJtHjpl9O3BXXTjecZ2dT6PRO+LTjwEmWba+7Yv5TstdNp8RI8pIizWNiJDkJEYS69KFPREREPiG3B3reZda+9bDmWbOlrmIGRPqg+6eg+6chNjvQlYqIdDgKmUSk2cJcQXRN8dI1xXvF842NNtVHz7DtwAm27DvJ1v0n2LLvBMt3HqKhKXyyLEiLCbsYOnVKMo+ZceG4gjR0XERERD6GpG4w8hEY9mPYOh/W/Ave+C0s/TWk9YMe/wUF4yAkItCVioh0CAqZROQTczQNDk+NCeOG/MSLz5+/0Mjew6ebQqem8Gn/CRZvPsCFRnNwZZDDIjs+ggKfh4Jkz8XH6HBXoH4cERERaWuCXCZMKhgHx2th7XMmcJr5VZj3AHQdb7bTpfbWsHARkRakkElEWkyQ00FWfARZ8RGM6Hrp+bPnL7Dz4Cm27j/B1v0n2FR7guU7Dl0x8ynZ674idCrweUiNDsPh0AdDERER+QCeZBh4Pwy4DyrfhjXPwIbpJnSKzTFb6Yo+Ze4TEZGrSiGTiFxzIUFOOid76JzsueL5QyfPsqn2BBW1x6ioOU5F7XFe3XrwYtdTZEgQnS8Lnk4fu0DD+UZttxMREZH/ZFmQ1sesEb+AipkmaHrlR7D4J5Az1Gyn6zTSdEKJiMgnppBJRFqN2IgQBuSGMCD30sDx+nMX2Lr/BBU1x9nYFDxNLqvkdMMFAH6+cgGdkz0Upngp9HspSo0iOz4CpzqeRERE5B0hEdDj02Yd2gHlz0L5v2HyZyA0Bgonme6m5CJtpxMR+QQUMolIq+YOdlLoj6LQH3XxucZGmz2HTzN54XIueFNYW3mUaaureOatPQCEuZx09Xnp5jfBU6E/iozYMCx9aBQREZHYbBjyEAz+HuxYbLbTlT0Fb/8F4jub0+m6TdJ2OhGRj0Ehk4i0OQ6HRWZcOL2Tgxg0qDNggqeddSdZV3WMdVXHWFt1lH+9tYezTafbedxBFPqj6Ob3UuT30iMtmkSPO5A/hoiIiASSwwm5w8w6fRg2TjcDwxc+BIsehqxBUHQH5I8CV1iAixURaRsUMolIu+BwWOQkRJKTEMktxX4Azl1oZOv+ExeDp3VVR3ni9Z2cb5rxlBIVSo+0KIrToilOj6Yg2aP5TiIiIh1RWAz0vMusuu2w7nlY+zxMuxtckebUuu6fgrR+4NBnBRGR96OQSUTarWCngy4+L118Xj7VyzxXf+4CFbXHWbP3KKv3HGHVniPMWVcLQEiQg0K/l+K0aHqkRVOcHkVCpLqdREREOpS4HLjh+zDou7BnmQmbKmZA+b/AmwZFt5n5TbHZga5URKTVUcgkIh2KO9hpOpfSorlrQCYAtcfOsHrPUVbvPcLqvUd4etlu/vr6TgD80aFN90dRkh5D5+RIgpz6DaaIiEi753BA5kCzbvolbJ5rhoW//it4/f/A38t0N3UZD6HRga5WRKRVUMgkIh1esjeUUYWhjCo0Az7rz11gY81x1jSFTm/vOsSstTWAGSpekh5Nr4wYemXGUJQahTvYGcjyRUREpKW5ws0JdIWT4HgNrJts5jfNuQ/mPwh5I013U84QcAYHuloRkYBRyCQi8i7uYBMklaSb30ratk3NsXpW7zlC2e7DvL3rML9ZtBXbBpfTQVGql16ZMfTKjKUkPZqIEP2nVUREpN3y+GDAvdD/m1BbDuXPwfopZktdWBx0vQUKb4OUEtDJtiLSwehfQiIiH8KyLFKiQkmJCmVMkQ+Ao6cbKNt9hBVNodNfXtvJH5fswGFBF987oVMMPTNiiAl3BfgnEBERkavOssDXw6zhP4Xti0x306p/wIrHITrTdD51m2TmPImIdAAKmUREPoaoMBdDCxIZWpAIwKmz51mz9ygrdh3i7V2HeeatPTz5xi4AchMi6J0VQ//sOPpkxRKt0ElERKR9CXJB/k1m1R+DilmwfjK89kt47RcmiOo2CbpOgMjEQFcrItJiFDKJiFwF4SFBDMiNY0BuHABnz19gfdUx3t5lOp2mr67mX2/txbKgc5KH/jmx9MuOo2dmjLbXiYiItCduLxTfadbxGtjwopnhtOA78PL3IPN60+GUPxrcnkBXKyJyVelfNiIiLSAkyElpRgylGTF8bTCcu9DIuqqjvLn9EMt21PGPN/fwxNJdBDksilKj6JcdS9/sWIrTojVIXEREpL3w+KDf1806uMWETesnw4yvQNB9ZmB44W2QPcR0Q4mItHEKmUREroFgp4OS9BhK0mP4+pBc6s9dYNWeIyzbXsebOw7xxyXb+cPi7YQEOSjNiKZfdhz9smPpluIlyOkIdPkiIiLyScXnwZAfwA3fh8oVJmzaMA02TofQaOgy3mypS+0NDv3dLyJtU4uGTJZljQAeBZzA32zbfuRd10OAfwIlwCHgNtu2d192PQ2oAB62bftXLVmriMi15A520j8njv45Znvd8fpzrNh5mDd3HOLNHXX834ItAESGBNE3O5brOsVzfad4UmPCAlm2iIiIfFKWBWm9zRrxCOxYbDqcyp+DsqfAmwbdbjUrsUugqxUR+UhaLGSyLMsJ/BEYBlQBKy3LmmXbdsVlt90FHLFtO8eyrNuBXwC3XXb9t8D8lqpRRKS18LiDrxgkXnfyLG/tPMSy7XW8vrWOlyv2A5AZF87A3Diuy42nb3Ys4ZrnJCIi0nY5g6HTjWadPQmb58K6F2DZ7+CN30B8vhkW3uUWnVAnIm1CS/7rpBew3bbtnQCWZT0PjMN0Jr1jHPBw09dTgccsy7Js27Yty7oZ2AmcasEaRURapbiIEEYX+hhd6MO2bXYcPMXSbQd5fetBppRV8c/lewh2WpSkRzMw13Q5FSR7cDisQJcuIiIiH0dIBBTdZtbJg1Axw2ylW/Izs5KLTNjU9RaISgt0tSIi78mybbtl/mDLuhUYYdv23U3f3wn0tm37nsvu2dB0T1XT9zuA3sAZYBGmC+pbwMn32i5nWdYXgS8CJCYmljz//PMt8rNcaydPniQiIiLQZYi0eh31vXKu0WbbkUY21F1gfd0FKk80AhDpgi6xTrrFOekS5yQqRPMc5JKO+n4R+aj0XpHWJqS+jviDy0g4sBTPiW0AHPPkcSBhIAfj+9MQEhOQuvReEWm+tv5+GTx48Crbtkubc29LdjK916/T351ovd89PwJ+a9v2Sct6/9/K27b9OPA4QGlpqT1o0KCPV2kr8+qrr9JefhaRltSR3yvDLvv6wIl63thWx+tbD7J0Wx1v1TYA0DXFww15CQzOT6DIH6Uupw6uI79fRD4KvVekdbrVPBzeBRun4d0wHe/2v5G7/UnIGGC6mzqPg/DYa1aR3isizdeR3i8tGTJVAamXfe8Hat7nnirLsoIAL3AY0810q2VZvwSigEbLsupt236sBesVEWmTEiLd3FLs55ZiP42NNhW1x3lt60GWbD7AY0u28/vF24kNd3F9p3gG5ydwXad4vKHBgS5bREREPqqYTBj4/8w6uMWcTrfhRZhzH8z9FmQPNlvq8kdBaFSgqxWRDqglQ6aVQK5lWZlANXA7cMe77pkFfBZYjonnF9tm/97Ad26wLOthzHY5BUwiIh/C4bDomuKla4qXrw3O4cipBl7fdpDFmw+weMsBpq2pxukws5xuyE/ghvwEchMi+KCuUREREWmF4vNg8Hdg0IOwbz1sbAqcZn4V5rggZ5jpcOo0wsx7EhG5BlosZLJt+7xlWfcACwAn8JRt2xsty/oxUGbb9izgSeAZy7K2YzqYbm+pekREOqLocBfjuqcwrnsKFxpt1uw9YgKnzQd4ZP5mHpm/GX90KIPzTODUNzsWd7Az0GWLiIhIc1kWJBeaNeSHUL3KhE0bp8OWuRAUCrlDoeBmc4pdSGSgKxaRdqxFz762bXseMO9dzz102df1wMQP+TMebpHiREQ6GKfDojQjhtKMGL49Ip/aY2dYstl0OU1dVcUzb+3BHexgQE4cwwoSGdI5kbiIkECXLSIiIs1lWeAvNWv4z2Dvm7BxBmyaBZtmQ5AbcoZCwTjT4eT2BLpiEWlnWjRkEhGR1ivZG8odvdO4o3ca9ecu8PauwyzetJ9Fmw6waNMBLGs9xWnRDCtIZFhBItnxarUXERFpMxwOMxQ8YwCM/AVUvg0VM83aPAecLsgeAl1uhryR4PYGumIRaQcUMomICO5gJ9d3iuf6TvE8PNZmU+0JFlbsZ+GmfRe31WXFh5vAqXMiPdKiceq0OhERkbbB4YT0fmbd+L9QtRIqZpjAaet8cARD9g1NgdNNGhouIh+bQiYREbmCZVkU+DwU+Dx8c2guNUfPsGjTfhZW7OfJpbv462s7iQ13MaRzAsMKkhiQE0eoS3OcRERE2gSHA9J6mzX8Z2aG0zuB07YFJnDKGnQpcAqLCXTFItKGKGQSEZEP5IsK5TN9M/hM3wyO15/j1S0HWVixn/nr9zG5rKppjlM8N3ZJZGjnRKLDXYEuWURERJrD4YDUnmYN/ylUr24KnGbAzK+BIwgyrzcznPJHQ3hsoCsWkVZOIZOIiDSbxx3M2CIfY4t8NJxvZMWuwyys2MfCiv0s2rQfp8Oib1YsI7omMbxLIgmR7kCXLCIiIs1hWeAvMWvYj6G23AwNr5gBs78Bc+4z2+06j4X8UYGuVkRaKYVMIiLysbiCHAzIjWNAbhwPj+3C+upjvLRhHy9t2Mf3Z2zgBzM3UJoezYiuydzYJRF/dFigSxYREZHmsCzw9TBr6MOwbx1UzDIDw+c/APMfoDgyF5x3QOcxEJcb6IpFpJVQyCQiIp+YZVkU+qMo9EfxwI15bN1/kvkbanlpwz5+MqeCn8ypoNDvZUTXJEZ2TSYzLjzQJYuIiEhzWBYkF5k15AdQtw02zYYV/4ZXfmRWXJ4JmzqPhuTu5jUi0iEpZBIRkavKsizykiLJS4rk3qGd2FV3qqnDqZZfvrSFX760hbzESBM4dUsiLzESSx9GRURE2oa4XBh4P6svFDOoRw5snmtCpzd+C0t/Bd5UM7+p82hI62tOthORDkMhk4iItKjMuHC+MiibrwzKpvroGRY0ban7/eJtPPrKNjLjwrmxSxIjuyZR6PcqcBIREWkrvH7o/SWzTh2CrfNh0xwoewre/jOExUHeSNPllDUIgkICXbGItDCFTCIics2kRIXy+QGZfH5AJgdO1LOwYj8vbdjHE0t38pfXdpAaE8qobj5GFybTxedR4CQiItJWhMdCj/8y6+wJ2L7IBE4bZ8CaZ8AVCbnDTIdTzjBwewJdsYi0AIVMIiISEAmRbj7dO51P907n6OkGXq7Yz9x1tfytKXDKiA1jVGEyo7r56JysLXUiIiJtRkgkdBlv1vmzsOt1s6Vu81zYOA0cwZA5EPJuMp1OXn+gKxaRq0Qhk4iIBFxUmItJpalMKk3lyKkGFmzcx5x1tfz51R38cckOsuLDGd0tmdFFPjolRga6XBEREWmuoBDTwZQ7DEb/Firfhi3zYPM8mPcts5IKLwVOyUUaHC7ShilkEhGRViU63MXtvdK4vVcah06e5aWN+5iztpbHlmzn94u3k5sQwehCH6MKk8lJiAh0uSIiItJcDiek9zNr+E/NSXWb58KW+fDaL+C1R8CTYsKmvJGQMVBznETaGIVMIiLSasVGhFzcUnfgRD0LNuxj9rpafvfKVn67aCv5SZGMLkxmVKGPzLjwQJcrIiIiH0VcLgy416yTB2HbAhM4lf8bVv7NzHHKGWK6nHKHQVhMoCsWkQ+hkElERNqEhEg3d/bN4M6+Gew/Xs+89bXMXVfLr17eyq9e3koXn4cxRT7GFPlIiQoNdLkiIiLyUUTEXxocfu4M7HzNbKvb+hJUzADLCWl9Ib9pW11MVqArFpH3oJBJRETanESPm//un8l/98+k9tgZ5q6rZfa6Wh6Zv5lH5m+mV0YMY7v7uKlbMjHhrkCXKyIiIh9FcCjkjTCrsRFq1sCWpm11C75rVnw+dBoBnW4Efy9w6p+2Iq2B3okiItKmJXtDuXtgFncPzGLPoVPMXlvDjPIavj9jAw/P2sjA3DjGdU9hWEEi4SH6a09ERKRNcTjAX2LWkIfg8C7T3bR5Lix/DJb9DtxRkDPUBE45Q7WtTiSA9GlbRETajfTYcO65IZevDc5hU+0JZq6tZnZ5Dfe+UI472MHQzomM657C9Z3icQU5Al2uiIiIfFQxmdDnK2bVH4Mdi2Hry7DtZdgwFSyH6WzqNBxyb4TELjqtTuQaUsgkIiLtjmVZFPg8FPg8/M+N+azae4SZ5dXMXVfLnHW1eEODualbEmOKfPTOjMXp0IdPERGRNsfthS7jzWpshJrVsHWBGSD+yo/N8vgvBU6Z14ErLNBVi7RrCplERKRdczgsembE0DMjhh+O6cIb2+uYVV7DzPIanltRSaInhDGFPsZ1T6FrigdLv+0UERFpexwO8JeadcP34HgtbF9oQqe1L0DZUxDkhoyBZltdpxshKi3QVYu0OwqZRESkwwh2Ohicl8DgvATONFxg0ab9zFpbwz+W7+Zvb+wiMy6csUU+bu6RQmZceKDLFRERkY/LkwzFnzHr/FnYs6xpW90CmPcts+I7X+pySu0FzuBAVy3S5ilkEhGRDinU5WRMkY8xRT6OnT7H/A21zCyv4feLt/HoK9vonhrF+B4pjCny6YQ6ERGRtiwoBLJvMGvkI1C33QwP37YAlv8Rlj0KIR7Iut4MDs8ZCl5/oKsWaZMUMomISIfnDQvm9l5p3N4rjX3H6pm1tpppq6v54ayN/GROBYPy4hnfw8+Qzgm4g52BLldEREQ+ibgciLsH+t0D9cdh12uwbSFsfwU2zTb3xHeGnCEmcErvZ4IqEflQCplEREQuk+R188Xrsvniddlsqj3O9DXVzFhTzaJNB4h0BzGqWzLje6TQMyMGhwaGi4iItG1uD3QeY5Ztw8EtZpbT9kWw4nFY/hgEh5mh4TlDTfAUkxXoqkVaLYVMIiIi76NzsofOyR7+Z0Q+b+6oY/rqamatreH5lZWkRIVycw8f43v4yUmICHSpIiIi8klZFiTkm9Xv69BwCna/0dTltNBssQOIyb60rS5jgE6sE7mMQiYREZEP4XRYDMyNZ2BuPD9tOM+CjfuYvqaGP7+6gz8u2UGh33txflNchNrpRURE2gVX+KWT6AAO7TAdTtsXwep/woq/gjMEMvpfCp3iOpmwSqSDUsgkIiLyEYS5ghjfw8/4Hn4OHK9n1toapq2u5kezK/jp3E1c3yme8T1SGFaQqPlNIiIi7Ulstlm9vwTn6mHvm7CtKXRa8F2zPCmQNRiyB0PWIAiPC3TVIteUQiYREZGPKcHj5u6BWdw9MIst+04wbU0VM9fUsHjzASJCghjZNYnxxSn0yYzV/CYREZH2JNh96cQ6fg5H95rB4TuXwOY5UP4vc19SN3NP1mBI62teJ9KOKWQSERG5CvKSIvnOyM58+8Z83tp5iGmrq5m3vpYpq6pIiQplfI8UJpT4yYwLD3SpIiIicrVFpUHpf5vVeAFqy2HHYtjxKiz/Eyx7FILcJmjKHmxCp8Su4HAEunKRq0ohk4iIyFXkdFj0z4mjf04cP725Ky9X7OPF1dX86dXtPLZkO6Xp0Uwo8TOqMBmPOzjQ5YqIiMjV5nBCSolZ1z0AZ0/CnjdNl9OOJbDwIXNfeLzZUvfO9jqPL5BVi1wVCplERERaSKjLybjuKYzrnsK+Y/VMX1PN1FWVfGfaeh6etZERXZOYUOynf04cTm2nExERaZ9CIqDTcLMAjtfAzldN4LTzVVg/xTwfl9e0BW8wpPc3rxNpYxQyiYiIXANJXjdfGZTNl6/PYm3VMaauqmRWeQ0zy2tI8ri5pdhsp8uO1wdKERGRds3jg+53mGXbsH+j2Vq3cwmsehre/jM4giG1l+l0yrzOdEU51QEtrZ9CJhERkWvIsiy6p0bRPTWK748q4JVNB3hxdRV/fX0nf3p1Bz3SophQ7GdMoQ9vmD5MioiItGuWBUldzer/DXNqXeVbTV1OS2DJz2HJzyA4HNL7msAp8zpIKjTb8kRaGYVMIiIiAeIOdjKqMJlRhckcOFHPzDU1TF1VxfdnbODHcyoYXpDIhBI/A3PiCHJqMKiIiEi7F+xumtM0CPgRnD4Me5bBrtfNemeekzsKMgZA5vUmdIrPM4GVSIApZBIREWkFEiLdfOG6LO4emMnGmuNMXVXFjPJq5qyrJSEyhPHFKdxa7Cc3MTLQpYqIiMi1EhYDnceYBXBiH+xaCrteM6HT5jnm+fCES11OmddBdIZCJwkIhUwiIiKtiGVZdE3x0jXFy3dv6szizQeYuqqKJ5fu4q+v7aTI72VCiZ+xRT6iwlyBLldERESupcgkKJxoFsCR3U2hU1On04ap5nlv2mWh00CdXCfXjEImERGRVsoV5GBE1yRGdE2i7uRZZpab7XQPzdzIT+dsYmhBAhNLUhmYq+10IiIiHVJ0hlnFd5oh4nXbLnU5bZkL5f8y98XmXgqc0gdARHwgq5Z2TCGTiIhIGxAXEcJdAzK5a0AmG2uO8eKqamaWVzNv/T4SIkOYUOJnYomfLJ1OJyIi0jFZFsR3MqvXF6CxEfavv9TltO4FKHvS3BvXCdL7m7lO6f3BkxzY2qXdUMgkIiLSxnTxeeni8/LgyPym7XSVPP76Tv786g56ZkQzsSSVmwqTiQjRX/MiIiIdlsMByUVm9fs6XDgHtWth9xtmrZ8Kq54298ZkXRk6RaUGtnZps/TpU0REpI26fDvdgeP1TFtTzeSySr794joenr2RUd2SmViaSs+M6ECXKiIiIoHmDAZ/qVkD7oUL52HfOnN63e5lsGkWrHnG3BuVZrbVZfQ3oZMGiUszKWQSERFpBxI8br58fTZfui6L1XuPMqWsktlra5iyqorMuHBKohvI71FPktcd6FJFRESkNXAGQUqxWf2+Do0XYP/GptDpDdj6Eqz9t7nXk9LU6dTfhE+x2Qqd5D0pZBIREWlHLMuiJD2akvRoHhpTwLz1+5hcVsnUbaeY9sgrXNcpnkmlqQzpnEBIkDPQ5YqIiEhr4XBCcqFZfb5iZjod3HwpdNq5BNZPNvdGJEF6PxM6pfWD+HyzPU86PIVMIiIi7VSYK4hbS/zcWuLnhbmLqQxKYeqqKr767Gqiw4K5uUcKE0tSKfB5Al2qiIiItDYOByQWmNXrC5dOr9vzhtlet2cZbJxm7nV7IbUPpPWBtL7g6wHB6p7uiBQyiYiIdACJ4Q5uG5THfcM68cb2OiaXVfLsW3t5etluuqZ4mFSaytgiH1FhrkCXKiIiIq3R5afXlX7ehE6Hd0Ll27B3Oex9C7YtMPc6XeArvhQ6pfaCsJjA1i/XhEImERGRDsTpsLi+UzzXd4rnyKkGZpZXM7msiodmbuSnczcxvCCRSaWp9M+Jw+nQrAURERF5H5ZlZjPFZkP3O8xzp+quDJ2WPwbLfmeuJRRcCp3S+oA3VXOd2iGFTCIiIh1UdLiLz/XP5HP9M9lQfYypq6qYvqaaOetq8XndTCjxM7EklbTYsECXKiIiIm1BeBzkjzILoOE01Ky+FDqtnwplT5lrnpQrQ6eEAjMXSto0hUwiIiJC1xQvXVO8PDgyn0Wb9jOlrIrHlmznD4u30ycrhkmlqYzsmkyoSx/+REREpJlcYZAxwCwwJ9gdqDCB097lsGc5bHjRXAvxmG11qb3NY0oJhEQGrnb5WBQyiYiIyEXuYCejC32MLvRRc/QM01ZXMbmsivsnr+WhmRsZU5TMxNJUeqRGYanFXURERD4KhxOSupn1zjDxY5VXhk7bfw7YYDlMd5O/56XwKSZLW+xaOYVMIiIi8p58UaHcc0MuXx2Uw4rdh5lSVsWMNTU8t6KSnIQIJpX6Gd/DT3xkSKBLFRERkbbIsiAqzazCSea5M0ehugwqV0LVCtPptOppcy0s1oRO/p4mdEopBld44OqX/6CQSURERD6Qw2HRJyuWPlmxPDy2gLnraplcVsnP523mly9tYXB+AreVpjIoL54gpyPQ5YqIiEhbFhoFOUPNAmhshLotZqD4O8HT1pfMNcsJiV0udTr5e0J0hrqdAkghk4iIiDRbpDuY23ulcXuvNLYfOMHksiqmra5iYcV+4iNDmFDsZ2Kpn+z4iECXKiIiIu2BwwEJnc0q+Zx57vRhqCozgVPlClj7PKz8m7kWHg/+XpDa1O2U3N3MhpJrAr7jrwAAIABJREFUQiGTiIiIfCw5CZF896bOPHBjHks2H2ByWRVPLN3JX17bQWl6NJNKUxlVmEx4iD5uiIiIyFUUFgOdhpsFlwaKV66AqpXmcctcc+2dbqeUEvCXmse4PBNeyVWnT30iIiLyiQQ7HQzvksTwLkkcOF7PtDXVTC6r5NsvruPh2RsZXZjMpNJUStKjNSxcRERErr7LB4r3vMs8d6rOBE5VZWbG0+WznVyRkNLDBE4pJZBSCp7kwNXfjihkEhERkasmwePmy9dn86Xrsli99wgvrKxkzrpaJpdVkRUfzqTSVG4pTiEh0h3oUkVERKQ9C4+DvJFmgZntdGi7CZyqV5nw6c0/QON5cz3SB/7LQidfDwjR9v+PSiGTiIiIXHWWZVGSHkNJegw/HNOFuetrmbyykkfmb+b/FmxhcF48k0pTGZyfQLCGhYuIiEhLczggvpNZ3e8wz52rh33rLoVO1atg02xzzXJAfP6lbid/KcR3BqdilA+i/3dERESkRYWHBDGpNJVJpansOHiSKWVVvLi6ikWbDhAX4eKWYj+TSv3kJEQGulQRERHpSILdTSfT9br03KlDULP6Uui0eQ6seabp/jBILgJfMaQUm26nmCydZncZhUwiIiJyzWTHR/DgyHy+NbwTr245yOSySp56YxePv76T4rQoJpWmMrrIR4SGhYuIiEgghMdC7jCzAGwbjuyCqlUmdKoug7In4a0/muturznB7p3QyVcMXn+HDZ70CU5ERESuuSCng6EFiQwtSOTgibNMX1PF5LIqHpy2nh/NrmBU07DwnhkaFi4iIiIBZFmmWykmCwonmucunIODm6F6NdSsMZ1Pl893CoszoVP/eyGjf+BqDwCFTCIiIhJQ8ZEhfPG6bL4wMIs1lUeZUlbJ7LW1TF1VRWZcOBNL/Uwo9pPo0bBwERERaQWcwZdOsyv5rHnuXD3s32gCp5py83jhbGDrDACFTCIiItIqWJZFcVo0xWnR/GB0AfPW72NyWSW/fGkLv1qwhUF5CUwqTeWG/ARcQRoWLiIiIq1IsNucTucvCXQlAaWQSURERFqdMFcQt5b4ubXEz666U0wpq2TqqioWbz5AbLiL8T1SmNQzlU6JGhYuIiIi0looZBIREZFWLTMunG+PyOf+YZ1Yuq2OF1ZW8vc3d/O3N3bRPfWdYeHJeNzBgS5VREREpENTyCQiIiJtQpDTweD8BAbnJ3Do5Fmmr6lmclkl352+nh/P2chN3cyw8N6ZMRoWLiIiIhIACplERESkzYmNCOHugVncNSCTtVXHmFxWyezyGqatriY9NoxJpalMKPaT5NWwcBEREZFrRSGTiIiItFmWZdE9NYruqVH8YFQB8zfUMrmskv9bsIVfv7yF6zrFM6k0laGdEzUsXERERKSFKWQSERGRdiHU5eSWYj+3FPvZc+gUU8qqmLqqiq8+u5qYcBc3d09hUk8/+UmeQJcqIiIi0i4pZBIREZF2Jz02nG/dmMd9wzqxdNtBppRV8cxbu3lq2S4K/V4mlaYypsiHN1TDwkVERESuFoVMIiIi0m45HRaD8hIYlJfA4VMNzGgaFv79GRv4yZwKbuqWzMRSP30yY3E4NCxcRERE5JNQyCQiIiIdQky4i88PyOS/+2ewofo4L5TtZWZ5DdPXVJMaE8rEklRuLfHjiwoNdKkiIiIibZJCJhEREelQLMuim99LN383vj+qgAUb9/HCykp+s3Arv120lYG58Uwq9TOsIJGQIGegyxURERFpMxQyiYiISIflDnYyrnsK47qnUHn4NFNWVTG1rJJ7/r2GqLBgMyy8NJUCn4aFi4iIiHwYhUwiIiIiQGpMGPcP68Q3h+SybHsdk8sq+ffbe/n7m7vpluJlUqmfsUUpeMM0LFxERETkvShkEhEREbmM02FxXad4rusUz9HTZlj4C2VV/GDmRn4ydxMjuiRxW89U+mZpWLiIiIjI5RQyiYiIiLyPqDAXn+ufyef6Z7Kh+hhTyiqZUV7DrLU1pESFMrHUz60lfvzRYYEuVURERCTgFDKJiIiINEPXFC9dU7x856bOvFyxn8krK3n0lW08+so2BuTEMbE0leEFibiDNSxcREREOiaFTCIiIiIfgTvYydgiH2OLfFQePs2Lq6uYUlbFN55bgzc0mJu7+5hYmkrXFG+gSxURERG5phQyiYiIiHxMqTFh3Du0E9+4IZc3dxxiclklz62s5B/L91CQ7OG2nqmM6+4jKswV6FJFREREWpxCJhEREZFPyOGwGJAbx4DcOI6dPsestdW8UFbJD2dt5GdzNzG8SyK39Uylf3achoWLiIhIu6WQSUREROQq8oYFc2ffDO7sm8HGmmNMKatiRnk1c9bVkhIVyoQSPxNL/KTGaFi4iIiItC8KmURERERaSBefly5jvXznpnwWVuxnclkVf1i8jd+/so3+ObFMKk3lxi5JGhYuIiIi7YJCJhEREZEWFhLkZHShj9GFPqqPnuHFVVVMWVXJN58vx+MOYlz3FCaVptI1xYNlaTudiIiItE0KmURERESuoZSoUL4xJJd7Bufw1q5DTF5ZyeSySp55aw/5SZHc1jOVm7unEB2uYeEiIiLStihkEhEREQkAh8OiX3Yc/bLj+NGZc8xeW8OUskp+NLuC/523mWEFidxa4mdgbhxBTkegyxURERH5UAqZRERERALMGxrMf/VJ57/6pLN533Emr6xi+poq5q6vJT4yhJu7+5hQ4ic/yRPoUkVERETel0ImERERkVYkP8nDQ2MKeHBkPku2HODFVVU8vWw3TyzdRRefhwnFfsZ19xEbERLoUkVERESuoJBJREREpBVyBTm4sUsSN3ZJ4vCpBmaVVzN1dRU/nlPBz+dtYnB+AhOK/dyQn4ArSNvpREREJPAUMomIiIi0cjHhLj7XP5PP9c9ky74TvLi6iulrqllYsZ/osGDGFpntdN1SvDqdTkRERAJGIZOIiIhIG5KXFMl3b+rMt2/MY+n2Ol5cVcVzKyv5x/I95CZEMKHEz/geKSR63IEuVURERDoYhUwiIiIibVCQ08HgvAQG5yVw7Mw55qyr4cVVVTwyfzO/fGkzA3PjmVDiZ3hBIu5gZ6DLFRERkQ5AIZOIiIhIG+cNDebTvdP5dO90dh48ybTV1UxbXcU3nltDpDuI0YXJTCj2U5Iere10IiIi0mIUMomIiIi0I1nxEXzrxjzuH9aJt3YeYuqqKmasqeG5FZVkxIYxodjP+OIU/NFhgS5VRERE2hmFTCIiIiLtkMNh0S8njn45cfz45vPMX1/Li6ur+PXCrfx64Vb6ZsUyocTPyK5JhIfoI6GIiIh8ci163q1lWSMsy9piWdZ2y7IefI/rIZZlvdB0/W3LsjKanu9lWVZ501prWdb4lqxTREREpD2LCAliYmkqz3+xL0u/PZj7hnai5tgZvjVlLT1/toj7Xyhn6baDXGi0A12qiIiItGEt9msry7KcwB+BYUAVsNKyrFm2bVdcdttdwBHbtnMsy7od+AVwG7ABKLVt+7xlWcnAWsuyZtu2fb6l6hURERHpCFJjwvjm0Fy+MSSHsj1HeHFVFXPX1zJtTTUJkSGM6+5jfA8/BT5PoEsVERGRNqYle6N7Adtt294JYFnW88A44PKQaRzwcNPXU4HHLMuybNs+fdk9bkC/VhMRERG5iizLomdGDD0zYnh4bBcWbz7AtNXVPL1sN08s3UV+UiQ390hhXHcfyd7QQJcrIiIibYBl2y2T31iWdSswwrbtu5u+vxPobdv2PZfds6Hpnqqm73c03VNnWVZv4CkgHbjTtu3p7/G/8UXgiwCJiYklzz//fIv8LNfayZMniYiICHQZIq2e3isizaf3izTXiQabFfvO82b1eXYca8QC8mMc9PMFUZoURGhQ+z6dTu8VkebRe0Wk+dr6+2Xw4MGrbNsubc69LdnJ9F6fQN6daL3vPbZtvw10sSyrM/APy7Lm27Zdf8WNtv048DhAaWmpPWjQoE9cdGvw6quv0l5+FpGWpPeKSPPp/SIfxZimx911p5i+ppoZ5dU8ueE0z245z7CCJMb38DEwN55gZ4uO9wwIvVdEmkfvFZHm60jvl5YMmaqA1Mu+9wM173NPlWVZQYAXOHz5DbZtb7Is6xTQFShruXJFRERE5HIZceHcN6wT9w7NZfXeo8xYU83sdTXMXltDbLiLMUU+xvdIodDvxbLad4eTiIiIfLiWDJlWArmWZWUC1cDtwB3vumcW8FlgOXArsNi2bbvpNZVNg7/TgTxgdwvWKiIiIiLvw7IsStKjKUmP5gejC3h1ywFmlFfz7xV7+fubu8mKD2d89xRu7pFCakxYoMsVERGRAGmxkKkpILoHWAA4gads295oWdaPgTLbtmcBTwLPWJa1HdPBdHvTywcAD1qWdQ5oBL5q23ZdS9UqIiIiIs3jCnIwvEsSw7skcezMOeY3nUz364Vb+fXCrfTMiGZ8Dz+juiXjDQsOdLkiIiJyDbVkJxO2bc8D5r3ruYcu+7oemPger3sGeKYlaxMRERGRT8YbGsztvdK4vVcaVUdOM7O8hmmrq/ju9PU8PGsjN+QnML44hUF58YQEOQNdroiIiLSwFg2ZRERERKRj8EeH8bXBOXx1UDYbqo8zbU0Vs9fW8NLGfXhDg7mpWxJji1LonRmDw6H5TSIiIu2RQiYRERERuWosy6Kb30s3v5fv3dSZpdvrmLGmmpnlNTy3opIkj5sxRcmM655CF59HA8NFRETaEYVMIiIiItIigpwOBuclMDgvgdMN51m06QCzymv4+5u7eWLpLrLiwhnb3cfYIh9Z8RGBLldEREQ+IYVMIiIiItLiwlxBjC0ygdLR0w3M37CPmeXVPPrKNn63aBvdUryM6+5jdKGPJK870OWKiIjIx6CQSURERESuqagwF5/qlcaneqWx71g9c9bVMLO8hp/O3cTP5m2iT2YsY7v7GNk1iagwV6DLFRERkWZSyCQiIiIiAZPkdXP3wCzuHpjFzoMnmbW2hlnlNXxn2noemrmB6zslMK67j6GdEwl16YQ6ERGR1kwhk4iIiIi0ClnxEdw7tBPfHJLLhurjzCyvZva6GhZt2k+Yy8nwgkTGdU9hQG4cwU5HoMsVERGRd1HIJCIiIiKtyuUn1H3nps6s2HWYWWurmbd+HzPKa4gOC2ZUYTJji1IoTY/G4dAJdSIiIq2BQiYRERERabWcDou+2bH0zY7lR2O78vrWg8xcW8PUVVX86629JHvd3NQtmdGFyXRPjcKyFDiJiIgEikImEREREWkTXEEOhhYkMrQgkVNnz7OwYj9z1tXwz+W7efKNXfijQxlVmMyYQh9dfB4FTiIiIteYQiYRERERaXPCQ4K4uUcKN/dI4diZc7y8cR9z1tXy5NJd/PW1nWTGhTOqWzJjinzkJUUGulwREZEOQSGTiIiIiLRp3tBgJpamMrE0lSOnGnhp4z7mrKvhT69u57El28lNiGB0oY/RRclkx0cEulwREZF2SyGTiIiIiPz/9u48SO6zvvP4+5n7vg/NPSONblmyDssWtmzZCNsQB1Mps1wBsoFy2MAuu5VsliSb3Q0kFBRJSCiS7FKBEAjgpBwgxhh8yja2seRblkb3fYzm1jEzuufZP7o1HsmyGXsk9RzvV1VX9+/pp3u+vyk/Vs+nn+f5TRql+Vl8aHkjH1reSNexk/x8Qzs/Wd/OXz+6la8+spW5NUXckVxS11iel+pyJUmaVAyZJEmSNClVFmbz0RXNfHRFM4eOnOCBV9u5f/1BvvLgFr7y4BYW1hdzx8Iafm1hLXUluakuV5KkCc+QSZIkSZPetOIcfvuGFn77hhb29w0mA6d2vvjAZr74wGaWNJZwx8JaSk8MpbpUSZImLEMmSZIkTSn1pXncfeMM7r5xBnt6Brh/fSJw+vz9bQB8b9czvPuqGt69YBq1znCSJGnUDJkkSZI0ZTWV5/Ppm1v59M2tbO/s5+9+8gyb+s/yhfvb+ML9bVzdUMJ7rprGuxfU0FDmHk6SJL0ZQyZJkiQJaK0q4L0zsvirVSvZ1T3Azza087NXDw0vqVtYX8y7FyRmODVX5Ke6XEmSxh1DJkmSJOkCLRX5/O6qVn53VSv7ehN7OD2w4RBf/vlmvvzzzcyrKUrMcLqqhhmVBakuV5KkccGQSZIkSXoTDWV5/M5NM/idm2awv2+Qn284xM82HOIvHtrKXzy0ldnVhbznqhrec9U0ZlYXprpcSZJSxpBJkiRJGqX60jw+uXI6n1w5nUNHTvDzDYkZTn/96Fa++shWWqsKeM+CxAynOdMKCSGkumRJkq4YQyZJkiTpbZhWnMNvXd/Cb13fQufREzy48RAPvHqIr6/Zztce205LRT7vXjCN2+ZPY2F9sYGTJGnSM2SSJEmSxqiqKIePrmjmoyua6e4/yUMbO/jZhnb+35M7+bvHd1BbnMOt86dx6/xqljeXkZGeluqSJUm65AyZJEmSpEuooiCbD1/byIevbaRv4BSPbu7kwY2H+MG6vXz7md2U5mXyzrnV3DZ/GitnVpCTmZ7qkiVJuiQMmSRJkqTLpDQ/i7uW1nPX0noGT53hya1dPLixgwc3HuLeF/aTl5XOTbMquW3+NG6eU0VxbmaqS5Yk6W0zZJIkSZKugLysDG5fUMPtC2o4dWaIZ3f28ODGQzzU1sHPNhwiMz2wYkYFt82v5l3zqqkqzEl1yZIkvSWGTJIkSdIVlpWRxo2zKrlxViVfuHMBL+07zEMbD/HgxkP88Y828D9/vIEljaXcNj+xrK6pPD/VJUuS9CsZMkmSJEkplJYWWNpUytKmUj737jls6TjGgxsSS+q++MBmvvjAZuZMK+S2+Ykr1c2tKfRKdZKkccmQSZIkSRonQgjMmVbEnGlFfHb1TPb1DiaW1G3s4GuPbeNvHt1GfWkuq+cmltQtbykj0yvVSZLGCUMmSZIkaZxqKMvjkyun88mV0+k6dpJHNnXw6KaO4SvVFeZksGp2FavnVrFqthuHS5JSy5BJkiRJmgAqC7P50PJGPrS8keOnzvLU9m4eaevg0c0d/OSVg2SkBZa3lA3Pcmooy0t1yZKkKcaQSZIkSZpgcrPSede8RJh0dijy8r7DPLKpg0faOvj8/W18/v425kwrZPXcalbPq2ZhXTFpae7jJEm6vAyZJEmSpAksfcTG4f/j9jns7h5IBE6bOvj7J3bw9TXbqSzMZvXcKlbPreb61gpyMtNTXbYkaRIyZJIkSZImkeaK/OF9nA4PnuLxLV08vKmDn7zSzg/W7SMnM42VMyt519xqbplbRUVBdqpLliRNEoZMkiRJ0iRVkpfF+xbX8b7FdZw6M8TaXT083JZYVvdwWwchwNUNJdwyu4qb51Qxv7aIEFxWJ0l6ewyZJEmSpCkgKyMxg2nlzEr+9L3zaWs/yiNtnTy2uYO/fHgrf/nwVqqLsrk5GTjd0FpBfrZ/LkiSRs9/NSRJkqQpJoTA/Npi5tcW89nVM+k6dpLHt3SyZksnP13fzj3P7SMrPY1rp5dx8+wqbplTRXNFfqrLliSNc4ZMkiRJ0hRXWZjN+5c18P5lDZw+O8Rzu3tZs7mTxzZ3Dl+tbnpFPquSgdPyljKyMtJSXbYkaZwxZJIkSZI0LDM9jXfMqOAdMyr441+bx96eQdZsSQRO/7x2D996ehf5WencMLOCW+ZUcfPsKqqKclJdtiRpHDBkkiRJkvSGGsvz+Pg7mvn4O5oZPHWGZ7b38NiWTtZs7uTBjR0ALKgrGt48fFF9CWlpbh4uSVORIZMkSZKkUcnLymD1vGpWz6smxsjmQ8d4bHMicPr6mu187bHtlOdnsXJmBTfNTmwyXlGQneqyJUlXiCGTJEmSpLcshMDcmiLm1hTx6Ztb6Rs4xZPbulizuZNfbOvmxy8fBOCqumJunFXBTbOqWNxYQma6ezlJ0mRlyCRJkiRpzErzs7jz6jruvLqOoaHIxoNHeXJbF09s6eL/PrGTv12zg8LsDK5vreDGWZXcNLuSupLcVJctSbqEDJkkSZIkXVJpaYGr6ou5qr6YT9/cytETp3lmezdPbE2ETj/feAiA1qoCbppVyU2zKlneUkZOZnqKK5ckjYUhkyRJkqTLqignk9sX1HD7ghpijOzo6ufxLV08sbWL7z67h28+tYvsjDSum16eCJ1mVzK9Ip8Q3EBckiYSQyZJkiRJV0wIgdaqQlqrCvnkyukcP3WWtbt6ErOctnbx+fvb4H6oK8nlptmJWU4rZpRTlJOZ6tIlSb+CIZMkSZKklMnNSmfV7CpWza4CYF/v4PBeTv/+0gG+v3Yv6WmBRfXF3DCzkhtaK9xAXJLGKUMmSZIkSeNGQ1keH7m2iY9c28SpM0O8uLePp7d384tt3Xz9sW187dFt5Gelc+30cm5orWDlzApaqwpcWidJ44AhkyRJkqRxKSu5T9N108v5vVtnc+T4aX65o4ent3fz1PZuHtvcCUB1UTbXt1ZwQ/JWVZST4solaWoyZJIkSZI0IRTnZnL7gmncvmAaAPv7BodnOT2+pYsfvngAgFnVBdzQWsnKmRUsbykjP9s/eyTpSvD/tpIkSZImpPrSPD5wTSMfuKaRoaFIW/tRntrezdPbu/ne2j186+ldZKYHFjeWsrK1gutnVrCwrpgM93OSpMvCkEmSJEnShJeWFlhQV8yCumI+ddMMTpw+ywt7+vjFtm6e2t7FXz2ylb98eCuFORlcN72cd8woZ8WMcmZVFZKW5n5OknQpGDJJkiRJmnRyMtO5vrWC61srgDn0DpzimR3dPLWtm2d29PBwWwcAZflZrJheznUzEsHT9Ip8NxGXpLfJkEmSJEnSpFeWn8UdC2u5Y2EtAAcOH+eXO3p4Zkc3z+7o4aevtgNQVZjNimTgtGJ6BQ1luYZOkjRKhkySJEmSppy6klzuWlrPXUvriTGyp2eQX+7sSV69rod/f/ngcL8VM8pZMb2cd7SWU1Ocm+LKJWn8MmSSJEmSNKWFEGiuyKe5Ip8PLW8kxsiOrn6e2ZEInR7d1MG9L+wHoLk8jxUzKoaDp8rC7BRXL0njhyGTJEmSJI0QQqC1qpDWqkI+tqKZoaHI5kPHhmc63b/+ID9YtxeAmVUFrJhRzrUt5VzTUkpVYU6Kq5ek1DFkkiRJkqQ3kZYWmFdbxLzaIj5xQwtnhyIbDx4Znul07wv7+c4v9wAwvSKf5S1lXDu9jOUt5dSVuLxO0tRhyCRJkiRJb0F6WmBhfQkL60v41E0zOHN2iI0Hj7J2Vw/rdvXywKvt3PPcPiCxp9O1I0Kn5vI8NxKXNGkZMkmSJEnSGGSkp7GooYRFDSXcfeOM4eV163b1sG53L09u6+KHLx0AoLIwm+UtZVzXkgidZlYVkJZm6CRpcjBkkiRJkqRLaOTyut+6viW5kfgA63b1sm5XD2t39fLT9e0AlORlck1zWWK2U0s5c2sKyUhPS/EZSNLbY8gkSZIkSZdRYiPxAlqrCvjwtYmr1+3vO87aXb2s3ZmY7fRwWwcABdkZLG0q5ZrmUpY2lXF1Qwm5WekpPgNJGh1DJkmSJEm6gkIINJTl0VCWx11L6wE4dOQE63YnQ6ddvfzFQ10AZKQF5tcVs6yplGVNpSxt9gp2ksYvQyZJkiRJSrFpxTm8d1Et711UC8DhwVO8sKeP5/f08cLuPv752T1886ldADSV57G0qZRlTWUsay6ltdJ9nSSND4ZMkiRJkjTOlORl8c651bxzbjUAp84MseHgEZ7f3cvzu/t4YksXP3wxsZl4cW4mSxpLWNZcxrKmUhY1lJCT6RI7SVeeIZMkSZIkjXNZGWksaSxlSWMpd98IMUZ29wwOh07P7+llzZbEErvM9MD82uQSu+bEbKeKguwUn4GkqcCQSZIkSZImmBACLRX5tFTk8/5lDQD0Dby2xO753b1859k9/MOIJXaLG0pY0lTK4oZS5tQUkulV7CRdYoZMkiRJkjQJlOZnsXpeNavnJZbYnTxzlg0HjvD87j5e3NvH0zt6+PHLBwHIzkhjYX0xixtLWdxQwuLGUqYVu6G4pLExZJIkSZKkSSg7I52lTWUsbSoDEkvsDh45wUt7+3hp72Fe3NvHt5/ezTfODgFQU5zDksZSFjeWsLixhPm1xe7tJOktMWSSJEmSpCkghEBdSS51JbncsTBxFbuTZ87SdvAoL+09zEv7DvPS3j5++mo7kNjbaV5NUWK2U2MJSxpLqS/NJQSvZCfp4gyZJEmSJGmKys5IT4ZIpcNtncdOJEKnvYnQ6V+e28e3n9kNQEVBFlc3lFJy5hQZdd1cVV9McW5miqqXNN4YMkmSJEmShlUV5nDb/GncNn8aAGfODrGl49h5wdPO7tPcu20tAC0V+SyqL2ZhfQmLGopdZidNYYZMkiRJkqQ3lJGexvzaRHj0m9c1AfDTh9dQ1LyAV/Yd5pX9R/jlztc2FU9PC8yuLmRRQyJ4WlhfzOzqQjK8mp006RkySZIkSZLekvzMwMqZlaycWTnc1nH0BK/sO8z6/Ud4Zf9hHnj1ED9Ytw+AnMxEULWwvphF9SUsaiihuTzP/Z2kScaQSZIkSZI0ZtVFOdw6fxq3JpfZxRjZ0zPIK/sP88q+I6zff5gfrNvLPz69G4CinIzhmU7n7muKcwyepAnMkEmSJEmSdMmFEGiuyKe5Ip87r64DEvs7bevsZ/3+w7ycDJ6+8eROzgxFAMrys5hfW8RVdcUsqCtmQW0xDWVe0U6aKAyZJEmSJElXREZ6GnNriphbU8QHrkm0nTh9lrb2o2w8cIRXDxxhw4Gj5wVPRTkZLKgr5qq6YubXFbOgtojm8nzS0gyepPHGkEmSJEmSlDI5meksaSxlSWPpcNvJM2fZcugYGw4cZcPBI2w4cIR/fHo3p84OAVCQncG82iIW1BZzVX3ifnplAekGT1JKGTJJkiRJksaJyYB3AAARIklEQVSV7Iz05D5NJcNtp88Osa2jnw0HjgwHT99ft4cTTyeCp9zMdObWFA7PeJpfW8TMqkKyMryqnXSlGDJJkiRJksa9zPQ05tUWMa+2iP9AA5DY42ln9wAbkkvtNh44yr0v7Oeffrkn+ZpAa1Uhc2sKmVeTeO28miJK8rJSeSrSpGXIJEmSJEmakDLS05hVXcis6kJ+Y0k9AENDkV09A7QdPEpb+1HaDh7lqW3d/PDFA8Ovqy3OYV5tYm+oc+FTQ2me+zxJY2TIJEmSJEmaNNLSAjMqC5hRWcCvL6odbu/uP8mmZOjU1n6UTe1HWbOli7PJDcbzs9KHNyU/N+Np9rRCcjLTU3Uq0oRjyCRJkiRJmvQqCrJZObOSlTMrh9tOnD7Lto5+2tqP0HbwKJvaj/Hjlw7w3WcTy+3SAkyvLBie8TRnWiGzpxVSU5xDCM56ki5kyCRJkiRJmpJyMtO5qr6Yq+qLh9tijOzvO87Gg4nZTm3tR3lxTx8/eeXgcJ/CnAxmVycCp0TwlJj1VJybmYrTkMYNQyZJkiRJkpJCCDSU5dFQlsftC6YNtx85fpqtHcfYfOgYWw4dZcuhY9z3ykG+t/bMcJ+a4hxmTxsRPlUXMaMqn+wMl9xpajBkkiRJkiTpVyjOzeSa5jKuaS4bbosx0n7kBFsOvRY+bT50jKe3d3P6bGKvp/S0wPSKfGZNK2TO8OynIupLc91oXJOOIZMkSZIkSW9DCIHaklxqS3K5eU7VcPvps0Ps6h5gy6FjwwHU+v2H+en69uE++VnptFYVMLO6kJlVBcysLmBmVSF1JYZPmrgMmSRJkiRJuoQy09OYVV3IrOpCfn3Ra+39J8+wtePYcPi0rfMYT2zt4t4X9g/3yc08Fz4lQqeZVQXMqi505pMmBEMmSZIkSZKugILsDJY0lrKksfS89sODp9je2c/Wjn62dR5je2c/z2zv4YcvHhjuk5OZxozKRODUWlWQnP1USGNZHumGTxonDJkkSZIkSUqhkrwsljWXsWzEfk+Q2Gx8e2c/2zuPJQOoftbu7OFHL70WPmVlJMKnxIynAlqrEiFUU3kemelpV/pUNMUZMkmSJEmSNA4V52aytKmUpU3nz3w6diIRPm3r7E/cdxzjhT193PfKweE+GWmBxvI8plcUMKMqnxnn7isLKMnLutKnoinisoZMIYTbgb8B0oF/iDF+6YLns4HvAEuBHuADMcbdIYR3AV8CsoBTwH+PMT52OWuVJEmSJGkiKMzJZHFjKYsvWHY3cPIM2zv72dGVuO3sGmBHVz9Pbu3i1Nmh4X5l+VnMqEwETtOH7wtoKM0lw9lPGoPLFjKFENKBvwXeBewHngsh3BdjbBvR7RNAX4yxNYTwQeDLwAeAbuDXY4wHQwgLgAeBustVqyRJkiRJE11+dgaLGkpY1FByXvvZocj+vsFE+NQ5wM7uxP3DbR30DJwa7peZHmguzx8Ons6FUNMrCyjOzbzSp6MJ6HLOZFoObI8x7gQIIdwD3AmMDJnuBP5P8vG9wNdDCCHG+NKIPhuBnBBCdozx5GWsV5IkSZKkSSc9LdBUnk9TeT63zDn/ucODp9jRNcDOrn52JGc+be/s59FNnZwZisP9KgqymVGZT0tFPs0V+TSXJx43leeRk5l+hc9I41WIMf7qXm/njUO4C7g9xvjJ5PFHgWtjjJ8Z0WdDss/+5PGOZJ/uC97nUzHG1Rf5GXcDdwNUV1cvveeeey7LuVxp/f39FBQUpLoMadxzrEij53iRRsexIo2OY2XyOzMU6RqMHBocor1/iPaBSPvAEB2DQxx7bfITASjLCVTnB6rz0hK35OOqvECGV76b8OPl5ptvfiHGuGw0fS/nTKaL/Zd0YaL1pn1CCPNJLKG79WI/IMb4DeAbAMuWLYurVq16W4WON48//jiT5Vyky8mxIo2e40UaHceKNDqOlantyPHT7OkZYFd34ra7e4BdPYO82D3AkeOvJVBpAepKc2mpKKClPC8xA6oin5byfOqn0P5PU2m8XM6QaT/QMOK4Hjj4Bn32hxAygGKgFyCEUA/8CPhYjHHHZaxTkiRJkiSNUnFuJgvrS1hYX/K65/oGTrGrZ4BdXQPsTgZRu3sGeHFPH/0nzwz3y0gLNJTl0XwufCrPp7E8j8ayPOpLc8nOcAneRHQ5Q6bngJkhhBbgAPBB4MMX9LkP+DjwS+Au4LEYYwwhlAA/Bf4wxvj0ZaxRkiRJkiRdIqX5WZTmZ7HkgivfxRjp7j+VCJ66BtjVk5wB1T3Aszt7OX767HDfEKC2OJeGslyayl4Ln5rK82gqy6c4z03Ix6vLFjLFGM+EED5D4spw6cC3YowbQwifB56PMd4HfBP4bghhO4kZTB9MvvwzQCvwJyGEP0m23Rpj7Lxc9UqSJEmSpMsjhEBlYTaVhdlc01x23nMxRrqOnWRP7yB7ewbZ0zvIvt5B9vQM8OjmDrr7T53Xvygng6byfBrL8mgsz6OpLG/4cU1xLunuA5Uyl3MmEzHGB4AHLmj7XyMenwDef5HX/RnwZ5ezNkmSJEmSlHohBKqKcqgqynldAAUwcPIMe3sH2dOTDJ96B9jbe5yNB4/w4MZD510FLzM9UF/62synxhEBVH1pHgXZlzUGmfL87UqSJEmSpHErPzuDuTVFzK0pet1zZ84O0X7kxHAItbd3kL29A+ztHeTFvX0cO3HmvP4leZk0lCb2fUrc8s67zzeEGhN/e5IkSZIkaULKSE+joSyPhrI8rm89/7kYI4cHTyeDp0H29x1nf1/ifmvHMR7b3MnJM0PnvaYsP+siAdRrj/OyjFHejL8dSZIkSZI06YQQhjciX9Tw+ivhxRjp6j+ZDJ9eC6D29x1nc/sxHtnUyakLQqjy4RDq9QFUnSGUIZMkSZIkSZp6QghUFeZQVZjzuqvhAQwNRbr7T7LvvAAqcd/WfpSH2zo4dfb8EKo0L5O60lzqSnL5xA3TWd7y+j2mJjNDJkmSJEmSpAukpb22IfnSpouHUImZUIPs6z3OgcPJW99xdnQNMHDqzEXedXIzZJIkSZIkSXqL0tIC1UU5VBflsLQp1dWMD2mpLkCSJEmSJEkTnyGTJEmSJEmSxsyQSZIkSZIkSWNmyCRJkiRJkqQxM2SSJEmSJEnSmBkySZIkSZIkacwMmSRJkiRJkjRmhkySJEmSJEkaM0MmSZIkSZIkjZkhkyRJkiRJksbMkEmSJEmSJEljZsgkSZIkSZKkMTNkkiRJkiRJ0pgZMkmSJEmSJGnMDJkkSZIkSZI0ZoZMkiRJkiRJGjNDJkmSJEmSJI2ZIZMkSZIkSZLGzJBJkiRJkiRJY2bIJEmSJEmSpDEzZJIkSZIkSdKYGTJJkiRJkiRpzAyZJEmSJEmSNGYhxpjqGi6JEEIXsCfVdVwiFUB3qouQJgDHijR6jhdpdBwr0ug4VqTRm+jjpSnGWDmajpMmZJpMQgjPxxiXpboOabxzrEij53iRRsexIo2OY0Uavak0XlwuJ0mSJEmSpDEzZJIkSZIkSdKYGTKNT99IdQHSBOFYkUbP8SKNjmNFGh3HijR6U2a8uCeTJEmSJEmSxsyZTJIkSZIkSRozQyZJkiRJkiSNmSHTOBNCuD2EsCWEsD2E8LlU1yOlUgjhWyGEzhDChhFtZSGEh0MI25L3pcn2EEL4WnLsrA8hLEld5dKVFUJoCCGsCSFsCiFsDCF8NtnueJFGCCHkhBDWhRBeSY6VP022t4QQ1ibHyr+EELKS7dnJ4+3J55tTWb90pYUQ0kMIL4UQ7k8eO1akiwgh7A4hvBpCeDmE8HyybUp+DjNkGkdCCOnA3wLvBuYBHwohzEttVVJKfRu4/YK2zwGPxhhnAo8mjyExbmYmb3cDf3+FapTGgzPA78UY5wLXAZ9O/vvheJHOdxK4Jca4CLgauD2EcB3wZeCrybHSB3wi2f8TQF+MsRX4arKfNJV8Ftg04tixIr2xm2OMV8cYlyWPp+TnMEOm8WU5sD3GuDPGeAq4B7gzxTVJKRNjfBLovaD5TuCfko//CXjfiPbvxIRngZIQQs2VqVRKrRhje4zxxeTjYyT+IKjD8SKdJ/nffH/yMDN5i8AtwL3J9gvHyrkxdC/wzhBCuELlSikVQqgHfg34h+RxwLEivRVT8nOYIdP4UgfsG3G8P9km6TXVMcZ2SPxhDVQl2x0/EpBcorAYWIvjRXqd5PKfl4FO4GFgB3A4xngm2WXkeBgeK8nnjwDlV7ZiKWX+GvgDYCh5XI5jRXojEXgohPBCCOHuZNuU/ByWkeoCdJ6Lpf3xilchTUyOH015IYQC4N+A/xpjPPomXyI7XjRlxRjPAleHEEqAHwFzL9Ytee9Y0ZQUQrgD6IwxvhBCWHWu+SJdHStSwvUxxoMhhCrg4RDC5jfpO6nHizOZxpf9QMOI43rgYIpqkcarjnPTSZP3ncl2x4+mtBBCJomA6Xsxxh8mmx0v0huIMR4GHiexj1lJCOHcl68jx8PwWEk+X8zrl3FLk9H1wHtDCLtJbOFxC4mZTY4V6SJijAeT950kvsBYzhT9HGbINL48B8xMXrUhC/ggcF+Ka5LGm/uAjycffxz49xHtH0tereE64Mi56anSZJfc9+KbwKYY41+NeMrxIo0QQqhMzmAihJALrCaxh9ka4K5ktwvHyrkxdBfwWIxx0nzbLL2RGOMfxhjrY4zNJP4meSzG+BEcK9LrhBDyQwiF5x4DtwIbmKKfw4Jjf3wJIbyHxLcE6cC3Yox/nuKSpJQJIfwAWAVUAB3A/wZ+DPwr0AjsBd4fY+xN/pH9dRJXoxsE/mOM8flU1C1daSGEG4BfAK/y2t4Zf0RiXybHi5QUQlhIYvPVdBJftv5rjPHzIYTpJGZrlAEvAb8ZYzwZQsgBvktin7Ne4IMxxp2pqV5KjeRyud+PMd7hWJFeLzkufpQ8zAC+H2P88xBCOVPwc5ghkyRJkiRJksbM5XKSJEmSJEkaM0MmSZIkSZIkjZkhkyRJkiRJksbMkEmSJEmSJEljZsgkSZIkSZKkMTNkkiRJ+hVCCM8k75tDCB++xO/9Rxf7WZIkSRNNiDGmugZJkqQJIYSwCvj9GOMdb+E16THGs2/yfH+MseBS1CdJkpRKzmSSJEn6FUII/cmHXwJWhhBeDiH8txBCegjhKyGE50II60MIv5PsvyqEsCaE8H3g1WTbj0MIL4QQNoYQ7k62fQnITb7f90b+rJDwlRDChhDCqyGED4x478dDCPeGEDaHEL4XQghX9jciSZL0ehmpLkCSJGkC+RwjZjIlw6IjMcZrQgjZwNMhhIeSfZcDC2KMu5LHvx1j7A0h5ALPhRD+Lcb4uRDCZ2KMV1/kZ/0GcDWwCKhIvubJ5HOLgfnAQeBp4HrgqUt/upIkSaPnTCZJkqS371bgYyGEl4G1QDkwM/ncuhEBE8B/CSG8AjwLNIzo90ZuAH4QYzwbY+wAngCuGfHe+2OMQ8DLQPMlORtJkqQxcCaTJEnS2xeA/xxjfPC8xsTeTQMXHK8GVsQYB0MIjwM5o3jvN3JyxOOz+JlOkiSNA85kkiRJGr1jQOGI4weB/xRCyAQIIcwKIeRf5HXFQF8yYJoDXDfiudPnXn+BJ4EPJPd9qgRuBNZdkrOQJEm6DPzWS5IkafTWA2eSy96+DfwNiaVqLyY33+4C3neR1/0c+FQIYT2whcSSuXO+AawPIbwYY/zIiPYfASuAV4AI/EGM8VAypJIkSRp3Qowx1TVIkiRJkiRpgnO5nCRJkiRJksbMkEmSJEmSJEljZsgkSZIkSZKkMTNkkiRJkiRJ0pgZMkmSJEmSJGnMDJkkSZIkSZI0ZoZMkiRJkiRJGrP/D8sliJZbIoPuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for phase in ['train', 'val']:\n",
    "    plt.plot(losses[phase], label='{} loss'.format(phase))\n",
    " \n",
    "plt.legend()\n",
    "\n",
    "plt.title('train/val losses')\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
