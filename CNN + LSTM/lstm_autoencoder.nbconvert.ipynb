{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from resnet_feature_extracter import Img2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 6\n",
    "input_size = 2048\n",
    "hidden_size = 32#64#1024\n",
    "num_layers = 1#2\n",
    "num_classes = 10\n",
    "batch_size = 36\n",
    "num_epoches = 500#250\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vector extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Img2Vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoencoder definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, \n",
    "                            dropout=0.2, bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # initialize weights\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return out[:, -1, :].unsqueeze(1)\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(hidden_size, output_size, num_layers, batch_first=True,\n",
    "                            dropout=0.2, bidirectional=False)\n",
    "\n",
    "        # initialize weights\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        #nn.init.xavier_uniform_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_ih_l0, gain=np.sqrt(2))\n",
    "        nn.init.orthogonal_(self.lstm.weight_hh_l0, gain=np.sqrt(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.output_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.output_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class AutoEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(AutoEncoderRNN, self).__init__()\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size, num_layers)\n",
    "        self.decoder = DecoderRNN(hidden_size, input_size, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded_x = self.encoder(x).expand(-1, sequence_length, -1)\n",
    "        decoded_x = self.decoder(encoded_x)\n",
    "\n",
    "        return decoded_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './pregnant'\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform=data_transforms) for x in ['train', 'val']}\n",
    "data_loaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    losses = {'train': [], 'val': []}\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "\n",
    "    for epoch in range(num_epoches):\n",
    "        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                # scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for inputs, _ in data_loaders[phase]:\n",
    "                inputs = extractor.get_vec(inputs)\n",
    "                \n",
    "                inputs = inputs.reshape(-1, sequence_length, input_size).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
    "                    loss = criterion(outputs, inputs[:, inv_idx, :])\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuchen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 25\n",
      "----------\n",
      "train Loss: 0.043770\n",
      "val Loss: 0.068139\n",
      "\n",
      "Epoch 2 / 25\n",
      "----------\n",
      "train Loss: 0.043756\n",
      "val Loss: 0.068121\n",
      "\n",
      "Epoch 3 / 25\n",
      "----------\n",
      "train Loss: 0.043742\n",
      "val Loss: 0.068102\n",
      "\n",
      "Epoch 4 / 25\n",
      "----------\n",
      "train Loss: 0.043729\n",
      "val Loss: 0.068084\n",
      "\n",
      "Epoch 5 / 25\n",
      "----------\n",
      "train Loss: 0.043715\n",
      "val Loss: 0.068066\n",
      "\n",
      "Epoch 6 / 25\n",
      "----------\n",
      "train Loss: 0.043702\n",
      "val Loss: 0.068048\n",
      "\n",
      "Epoch 7 / 25\n",
      "----------\n",
      "train Loss: 0.043688\n",
      "val Loss: 0.068030\n",
      "\n",
      "Epoch 8 / 25\n",
      "----------\n",
      "train Loss: 0.043675\n",
      "val Loss: 0.068012\n",
      "\n",
      "Epoch 9 / 25\n",
      "----------\n",
      "train Loss: 0.043661\n",
      "val Loss: 0.067995\n",
      "\n",
      "Epoch 10 / 25\n",
      "----------\n",
      "train Loss: 0.043648\n",
      "val Loss: 0.067977\n",
      "\n",
      "Epoch 11 / 25\n",
      "----------\n",
      "train Loss: 0.043635\n",
      "val Loss: 0.067960\n",
      "\n",
      "Epoch 12 / 25\n",
      "----------\n",
      "train Loss: 0.043621\n",
      "val Loss: 0.067943\n",
      "\n",
      "Epoch 13 / 25\n",
      "----------\n",
      "train Loss: 0.043608\n",
      "val Loss: 0.067925\n",
      "\n",
      "Epoch 14 / 25\n",
      "----------\n",
      "train Loss: 0.043595\n",
      "val Loss: 0.067908\n",
      "\n",
      "Epoch 15 / 25\n",
      "----------\n",
      "train Loss: 0.043582\n",
      "val Loss: 0.067891\n",
      "\n",
      "Epoch 16 / 25\n",
      "----------\n",
      "train Loss: 0.043568\n",
      "val Loss: 0.067873\n",
      "\n",
      "Epoch 17 / 25\n",
      "----------\n",
      "train Loss: 0.043555\n",
      "val Loss: 0.067856\n",
      "\n",
      "Epoch 18 / 25\n",
      "----------\n",
      "train Loss: 0.043542\n",
      "val Loss: 0.067839\n",
      "\n",
      "Epoch 19 / 25\n",
      "----------\n",
      "train Loss: 0.043529\n",
      "val Loss: 0.067822\n",
      "\n",
      "Epoch 20 / 25\n",
      "----------\n",
      "train Loss: 0.043515\n",
      "val Loss: 0.067804\n",
      "\n",
      "Epoch 21 / 25\n",
      "----------\n",
      "train Loss: 0.043502\n",
      "val Loss: 0.067787\n",
      "\n",
      "Epoch 22 / 25\n",
      "----------\n",
      "train Loss: 0.043489\n",
      "val Loss: 0.067769\n",
      "\n",
      "Epoch 23 / 25\n",
      "----------\n",
      "train Loss: 0.043475\n",
      "val Loss: 0.067752\n",
      "\n",
      "Epoch 24 / 25\n",
      "----------\n",
      "train Loss: 0.043462\n",
      "val Loss: 0.067734\n",
      "\n",
      "Epoch 25 / 25\n",
      "----------\n",
      "train Loss: 0.043448\n",
      "val Loss: 0.067716\n",
      "\n",
      "Epoch 26 / 25\n",
      "----------\n",
      "train Loss: 0.043435\n",
      "val Loss: 0.067698\n",
      "\n",
      "Epoch 27 / 25\n",
      "----------\n",
      "train Loss: 0.043421\n",
      "val Loss: 0.067680\n",
      "\n",
      "Epoch 28 / 25\n",
      "----------\n",
      "train Loss: 0.043407\n",
      "val Loss: 0.067662\n",
      "\n",
      "Epoch 29 / 25\n",
      "----------\n",
      "train Loss: 0.043393\n",
      "val Loss: 0.067644\n",
      "\n",
      "Epoch 30 / 25\n",
      "----------\n",
      "train Loss: 0.043379\n",
      "val Loss: 0.067626\n",
      "\n",
      "Epoch 31 / 25\n",
      "----------\n",
      "train Loss: 0.043365\n",
      "val Loss: 0.067607\n",
      "\n",
      "Epoch 32 / 25\n",
      "----------\n",
      "train Loss: 0.043351\n",
      "val Loss: 0.067588\n",
      "\n",
      "Epoch 33 / 25\n",
      "----------\n",
      "train Loss: 0.043337\n",
      "val Loss: 0.067570\n",
      "\n",
      "Epoch 34 / 25\n",
      "----------\n",
      "train Loss: 0.043322\n",
      "val Loss: 0.067550\n",
      "\n",
      "Epoch 35 / 25\n",
      "----------\n",
      "train Loss: 0.043308\n",
      "val Loss: 0.067531\n",
      "\n",
      "Epoch 36 / 25\n",
      "----------\n",
      "train Loss: 0.043293\n",
      "val Loss: 0.067512\n",
      "\n",
      "Epoch 37 / 25\n",
      "----------\n",
      "train Loss: 0.043278\n",
      "val Loss: 0.067492\n",
      "\n",
      "Epoch 38 / 25\n",
      "----------\n",
      "train Loss: 0.043263\n",
      "val Loss: 0.067472\n",
      "\n",
      "Epoch 39 / 25\n",
      "----------\n",
      "train Loss: 0.043248\n",
      "val Loss: 0.067452\n",
      "\n",
      "Epoch 40 / 25\n",
      "----------\n",
      "train Loss: 0.043233\n",
      "val Loss: 0.067432\n",
      "\n",
      "Epoch 41 / 25\n",
      "----------\n",
      "train Loss: 0.043217\n",
      "val Loss: 0.067411\n",
      "\n",
      "Epoch 42 / 25\n",
      "----------\n",
      "train Loss: 0.043201\n",
      "val Loss: 0.067390\n",
      "\n",
      "Epoch 43 / 25\n",
      "----------\n",
      "train Loss: 0.043185\n",
      "val Loss: 0.067369\n",
      "\n",
      "Epoch 44 / 25\n",
      "----------\n",
      "train Loss: 0.043169\n",
      "val Loss: 0.067347\n",
      "\n",
      "Epoch 45 / 25\n",
      "----------\n",
      "train Loss: 0.043153\n",
      "val Loss: 0.067326\n",
      "\n",
      "Epoch 46 / 25\n",
      "----------\n",
      "train Loss: 0.043136\n",
      "val Loss: 0.067304\n",
      "\n",
      "Epoch 47 / 25\n",
      "----------\n",
      "train Loss: 0.043119\n",
      "val Loss: 0.067281\n",
      "\n",
      "Epoch 48 / 25\n",
      "----------\n",
      "train Loss: 0.043102\n",
      "val Loss: 0.067259\n",
      "\n",
      "Epoch 49 / 25\n",
      "----------\n",
      "train Loss: 0.043085\n",
      "val Loss: 0.067236\n",
      "\n",
      "Epoch 50 / 25\n",
      "----------\n",
      "train Loss: 0.043067\n",
      "val Loss: 0.067212\n",
      "\n",
      "Epoch 51 / 25\n",
      "----------\n",
      "train Loss: 0.043050\n",
      "val Loss: 0.067189\n",
      "\n",
      "Epoch 52 / 25\n",
      "----------\n",
      "train Loss: 0.043032\n",
      "val Loss: 0.067165\n",
      "\n",
      "Epoch 53 / 25\n",
      "----------\n",
      "train Loss: 0.043013\n",
      "val Loss: 0.067140\n",
      "\n",
      "Epoch 54 / 25\n",
      "----------\n",
      "train Loss: 0.042995\n",
      "val Loss: 0.067115\n",
      "\n",
      "Epoch 55 / 25\n",
      "----------\n",
      "train Loss: 0.042976\n",
      "val Loss: 0.067090\n",
      "\n",
      "Epoch 56 / 25\n",
      "----------\n",
      "train Loss: 0.042957\n",
      "val Loss: 0.067065\n",
      "\n",
      "Epoch 57 / 25\n",
      "----------\n",
      "train Loss: 0.042938\n",
      "val Loss: 0.067039\n",
      "\n",
      "Epoch 58 / 25\n",
      "----------\n",
      "train Loss: 0.042918\n",
      "val Loss: 0.067013\n",
      "\n",
      "Epoch 59 / 25\n",
      "----------\n",
      "train Loss: 0.042898\n",
      "val Loss: 0.066986\n",
      "\n",
      "Epoch 60 / 25\n",
      "----------\n",
      "train Loss: 0.042878\n",
      "val Loss: 0.066960\n",
      "\n",
      "Epoch 61 / 25\n",
      "----------\n",
      "train Loss: 0.042858\n",
      "val Loss: 0.066932\n",
      "\n",
      "Epoch 62 / 25\n",
      "----------\n",
      "train Loss: 0.042837\n",
      "val Loss: 0.066904\n",
      "\n",
      "Epoch 63 / 25\n",
      "----------\n",
      "train Loss: 0.042816\n",
      "val Loss: 0.066876\n",
      "\n",
      "Epoch 64 / 25\n",
      "----------\n",
      "train Loss: 0.042794\n",
      "val Loss: 0.066848\n",
      "\n",
      "Epoch 65 / 25\n",
      "----------\n",
      "train Loss: 0.042773\n",
      "val Loss: 0.066819\n",
      "\n",
      "Epoch 66 / 25\n",
      "----------\n",
      "train Loss: 0.042751\n",
      "val Loss: 0.066789\n",
      "\n",
      "Epoch 67 / 25\n",
      "----------\n",
      "train Loss: 0.042729\n",
      "val Loss: 0.066760\n",
      "\n",
      "Epoch 68 / 25\n",
      "----------\n",
      "train Loss: 0.042706\n",
      "val Loss: 0.066729\n",
      "\n",
      "Epoch 69 / 25\n",
      "----------\n",
      "train Loss: 0.042683\n",
      "val Loss: 0.066699\n",
      "\n",
      "Epoch 70 / 25\n",
      "----------\n",
      "train Loss: 0.042660\n",
      "val Loss: 0.066667\n",
      "\n",
      "Epoch 71 / 25\n",
      "----------\n",
      "train Loss: 0.042636\n",
      "val Loss: 0.066636\n",
      "\n",
      "Epoch 72 / 25\n",
      "----------\n",
      "train Loss: 0.042613\n",
      "val Loss: 0.066604\n",
      "\n",
      "Epoch 73 / 25\n",
      "----------\n",
      "train Loss: 0.042588\n",
      "val Loss: 0.066571\n",
      "\n",
      "Epoch 74 / 25\n",
      "----------\n",
      "train Loss: 0.042564\n",
      "val Loss: 0.066538\n",
      "\n",
      "Epoch 75 / 25\n",
      "----------\n",
      "train Loss: 0.042539\n",
      "val Loss: 0.066505\n",
      "\n",
      "Epoch 76 / 25\n",
      "----------\n",
      "train Loss: 0.042514\n",
      "val Loss: 0.066471\n",
      "\n",
      "Epoch 77 / 25\n",
      "----------\n",
      "train Loss: 0.042488\n",
      "val Loss: 0.066437\n",
      "\n",
      "Epoch 78 / 25\n",
      "----------\n",
      "train Loss: 0.042462\n",
      "val Loss: 0.066402\n",
      "\n",
      "Epoch 79 / 25\n",
      "----------\n",
      "train Loss: 0.042436\n",
      "val Loss: 0.066366\n",
      "\n",
      "Epoch 80 / 25\n",
      "----------\n",
      "train Loss: 0.042409\n",
      "val Loss: 0.066330\n",
      "\n",
      "Epoch 81 / 25\n",
      "----------\n",
      "train Loss: 0.042382\n",
      "val Loss: 0.066294\n",
      "\n",
      "Epoch 82 / 25\n",
      "----------\n",
      "train Loss: 0.042354\n",
      "val Loss: 0.066257\n",
      "\n",
      "Epoch 83 / 25\n",
      "----------\n",
      "train Loss: 0.042327\n",
      "val Loss: 0.066220\n",
      "\n",
      "Epoch 84 / 25\n",
      "----------\n",
      "train Loss: 0.042298\n",
      "val Loss: 0.066182\n",
      "\n",
      "Epoch 85 / 25\n",
      "----------\n",
      "train Loss: 0.042270\n",
      "val Loss: 0.066143\n",
      "\n",
      "Epoch 86 / 25\n",
      "----------\n",
      "train Loss: 0.042241\n",
      "val Loss: 0.066104\n",
      "\n",
      "Epoch 87 / 25\n",
      "----------\n",
      "train Loss: 0.042212\n",
      "val Loss: 0.066065\n",
      "\n",
      "Epoch 88 / 25\n",
      "----------\n",
      "train Loss: 0.042182\n",
      "val Loss: 0.066025\n",
      "\n",
      "Epoch 89 / 25\n",
      "----------\n",
      "train Loss: 0.042152\n",
      "val Loss: 0.065984\n",
      "\n",
      "Epoch 90 / 25\n",
      "----------\n",
      "train Loss: 0.042121\n",
      "val Loss: 0.065943\n",
      "\n",
      "Epoch 91 / 25\n",
      "----------\n",
      "train Loss: 0.042090\n",
      "val Loss: 0.065901\n",
      "\n",
      "Epoch 92 / 25\n",
      "----------\n",
      "train Loss: 0.042059\n",
      "val Loss: 0.065859\n",
      "\n",
      "Epoch 93 / 25\n",
      "----------\n",
      "train Loss: 0.042027\n",
      "val Loss: 0.065817\n",
      "\n",
      "Epoch 94 / 25\n",
      "----------\n",
      "train Loss: 0.041995\n",
      "val Loss: 0.065773\n",
      "\n",
      "Epoch 95 / 25\n",
      "----------\n",
      "train Loss: 0.041962\n",
      "val Loss: 0.065729\n",
      "\n",
      "Epoch 96 / 25\n",
      "----------\n",
      "train Loss: 0.041929\n",
      "val Loss: 0.065685\n",
      "\n",
      "Epoch 97 / 25\n",
      "----------\n",
      "train Loss: 0.041896\n",
      "val Loss: 0.065640\n",
      "\n",
      "Epoch 98 / 25\n",
      "----------\n",
      "train Loss: 0.041862\n",
      "val Loss: 0.065595\n",
      "\n",
      "Epoch 99 / 25\n",
      "----------\n",
      "train Loss: 0.041828\n",
      "val Loss: 0.065549\n",
      "\n",
      "Epoch 100 / 25\n",
      "----------\n",
      "train Loss: 0.041793\n",
      "val Loss: 0.065502\n",
      "\n",
      "Epoch 101 / 25\n",
      "----------\n",
      "train Loss: 0.041758\n",
      "val Loss: 0.065455\n",
      "\n",
      "Epoch 102 / 25\n",
      "----------\n",
      "train Loss: 0.041723\n",
      "val Loss: 0.065408\n",
      "\n",
      "Epoch 103 / 25\n",
      "----------\n",
      "train Loss: 0.041687\n",
      "val Loss: 0.065359\n",
      "\n",
      "Epoch 104 / 25\n",
      "----------\n",
      "train Loss: 0.041651\n",
      "val Loss: 0.065311\n",
      "\n",
      "Epoch 105 / 25\n",
      "----------\n",
      "train Loss: 0.041614\n",
      "val Loss: 0.065262\n",
      "\n",
      "Epoch 106 / 25\n",
      "----------\n",
      "train Loss: 0.041577\n",
      "val Loss: 0.065212\n",
      "\n",
      "Epoch 107 / 25\n",
      "----------\n",
      "train Loss: 0.041539\n",
      "val Loss: 0.065161\n",
      "\n",
      "Epoch 108 / 25\n",
      "----------\n",
      "train Loss: 0.041501\n",
      "val Loss: 0.065111\n",
      "\n",
      "Epoch 109 / 25\n",
      "----------\n",
      "train Loss: 0.041463\n",
      "val Loss: 0.065059\n",
      "\n",
      "Epoch 110 / 25\n",
      "----------\n",
      "train Loss: 0.041424\n",
      "val Loss: 0.065007\n",
      "\n",
      "Epoch 111 / 25\n",
      "----------\n",
      "train Loss: 0.041385\n",
      "val Loss: 0.064955\n",
      "\n",
      "Epoch 112 / 25\n",
      "----------\n",
      "train Loss: 0.041346\n",
      "val Loss: 0.064902\n",
      "\n",
      "Epoch 113 / 25\n",
      "----------\n",
      "train Loss: 0.041306\n",
      "val Loss: 0.064849\n",
      "\n",
      "Epoch 114 / 25\n",
      "----------\n",
      "train Loss: 0.041265\n",
      "val Loss: 0.064795\n",
      "\n",
      "Epoch 115 / 25\n",
      "----------\n",
      "train Loss: 0.041224\n",
      "val Loss: 0.064740\n",
      "\n",
      "Epoch 116 / 25\n",
      "----------\n",
      "train Loss: 0.041183\n",
      "val Loss: 0.064685\n",
      "\n",
      "Epoch 117 / 25\n",
      "----------\n",
      "train Loss: 0.041142\n",
      "val Loss: 0.064630\n",
      "\n",
      "Epoch 118 / 25\n",
      "----------\n",
      "train Loss: 0.041100\n",
      "val Loss: 0.064574\n",
      "\n",
      "Epoch 119 / 25\n",
      "----------\n",
      "train Loss: 0.041057\n",
      "val Loss: 0.064517\n",
      "\n",
      "Epoch 120 / 25\n",
      "----------\n",
      "train Loss: 0.041015\n",
      "val Loss: 0.064460\n",
      "\n",
      "Epoch 121 / 25\n",
      "----------\n",
      "train Loss: 0.040971\n",
      "val Loss: 0.064403\n",
      "\n",
      "Epoch 122 / 25\n",
      "----------\n",
      "train Loss: 0.040928\n",
      "val Loss: 0.064345\n",
      "\n",
      "Epoch 123 / 25\n",
      "----------\n",
      "train Loss: 0.040884\n",
      "val Loss: 0.064287\n",
      "\n",
      "Epoch 124 / 25\n",
      "----------\n",
      "train Loss: 0.040840\n",
      "val Loss: 0.064228\n",
      "\n",
      "Epoch 125 / 25\n",
      "----------\n",
      "train Loss: 0.040795\n",
      "val Loss: 0.064168\n",
      "\n",
      "Epoch 126 / 25\n",
      "----------\n",
      "train Loss: 0.040750\n",
      "val Loss: 0.064108\n",
      "\n",
      "Epoch 127 / 25\n",
      "----------\n",
      "train Loss: 0.040704\n",
      "val Loss: 0.064048\n",
      "\n",
      "Epoch 128 / 25\n",
      "----------\n",
      "train Loss: 0.040659\n",
      "val Loss: 0.063987\n",
      "\n",
      "Epoch 129 / 25\n",
      "----------\n",
      "train Loss: 0.040612\n",
      "val Loss: 0.063926\n",
      "\n",
      "Epoch 130 / 25\n",
      "----------\n",
      "train Loss: 0.040566\n",
      "val Loss: 0.063865\n",
      "\n",
      "Epoch 131 / 25\n",
      "----------\n",
      "train Loss: 0.040519\n",
      "val Loss: 0.063802\n",
      "\n",
      "Epoch 132 / 25\n",
      "----------\n",
      "train Loss: 0.040472\n",
      "val Loss: 0.063740\n",
      "\n",
      "Epoch 133 / 25\n",
      "----------\n",
      "train Loss: 0.040424\n",
      "val Loss: 0.063677\n",
      "\n",
      "Epoch 134 / 25\n",
      "----------\n",
      "train Loss: 0.040376\n",
      "val Loss: 0.063613\n",
      "\n",
      "Epoch 135 / 25\n",
      "----------\n",
      "train Loss: 0.040328\n",
      "val Loss: 0.063550\n",
      "\n",
      "Epoch 136 / 25\n",
      "----------\n",
      "train Loss: 0.040279\n",
      "val Loss: 0.063485\n",
      "\n",
      "Epoch 137 / 25\n",
      "----------\n",
      "train Loss: 0.040230\n",
      "val Loss: 0.063421\n",
      "\n",
      "Epoch 138 / 25\n",
      "----------\n",
      "train Loss: 0.040181\n",
      "val Loss: 0.063355\n",
      "\n",
      "Epoch 139 / 25\n",
      "----------\n",
      "train Loss: 0.040131\n",
      "val Loss: 0.063290\n",
      "\n",
      "Epoch 140 / 25\n",
      "----------\n",
      "train Loss: 0.040081\n",
      "val Loss: 0.063224\n",
      "\n",
      "Epoch 141 / 25\n",
      "----------\n",
      "train Loss: 0.040031\n",
      "val Loss: 0.063157\n",
      "\n",
      "Epoch 142 / 25\n",
      "----------\n",
      "train Loss: 0.039980\n",
      "val Loss: 0.063090\n",
      "\n",
      "Epoch 143 / 25\n",
      "----------\n",
      "train Loss: 0.039929\n",
      "val Loss: 0.063023\n",
      "\n",
      "Epoch 144 / 25\n",
      "----------\n",
      "train Loss: 0.039877\n",
      "val Loss: 0.062956\n",
      "\n",
      "Epoch 145 / 25\n",
      "----------\n",
      "train Loss: 0.039826\n",
      "val Loss: 0.062887\n",
      "\n",
      "Epoch 146 / 25\n",
      "----------\n",
      "train Loss: 0.039774\n",
      "val Loss: 0.062819\n",
      "\n",
      "Epoch 147 / 25\n",
      "----------\n",
      "train Loss: 0.039721\n",
      "val Loss: 0.062750\n",
      "\n",
      "Epoch 148 / 25\n",
      "----------\n",
      "train Loss: 0.039669\n",
      "val Loss: 0.062681\n",
      "\n",
      "Epoch 149 / 25\n",
      "----------\n",
      "train Loss: 0.039616\n",
      "val Loss: 0.062611\n",
      "\n",
      "Epoch 150 / 25\n",
      "----------\n",
      "train Loss: 0.039562\n",
      "val Loss: 0.062541\n",
      "\n",
      "Epoch 151 / 25\n",
      "----------\n",
      "train Loss: 0.039509\n",
      "val Loss: 0.062470\n",
      "\n",
      "Epoch 152 / 25\n",
      "----------\n",
      "train Loss: 0.039455\n",
      "val Loss: 0.062399\n",
      "\n",
      "Epoch 153 / 25\n",
      "----------\n",
      "train Loss: 0.039401\n",
      "val Loss: 0.062328\n",
      "\n",
      "Epoch 154 / 25\n",
      "----------\n",
      "train Loss: 0.039346\n",
      "val Loss: 0.062257\n",
      "\n",
      "Epoch 155 / 25\n",
      "----------\n",
      "train Loss: 0.039291\n",
      "val Loss: 0.062184\n",
      "\n",
      "Epoch 156 / 25\n",
      "----------\n",
      "train Loss: 0.039236\n",
      "val Loss: 0.062112\n",
      "\n",
      "Epoch 157 / 25\n",
      "----------\n",
      "train Loss: 0.039181\n",
      "val Loss: 0.062039\n",
      "\n",
      "Epoch 158 / 25\n",
      "----------\n",
      "train Loss: 0.039125\n",
      "val Loss: 0.061966\n",
      "\n",
      "Epoch 159 / 25\n",
      "----------\n",
      "train Loss: 0.039069\n",
      "val Loss: 0.061892\n",
      "\n",
      "Epoch 160 / 25\n",
      "----------\n",
      "train Loss: 0.039012\n",
      "val Loss: 0.061818\n",
      "\n",
      "Epoch 161 / 25\n",
      "----------\n",
      "train Loss: 0.038956\n",
      "val Loss: 0.061744\n",
      "\n",
      "Epoch 162 / 25\n",
      "----------\n",
      "train Loss: 0.038899\n",
      "val Loss: 0.061669\n",
      "\n",
      "Epoch 163 / 25\n",
      "----------\n",
      "train Loss: 0.038842\n",
      "val Loss: 0.061594\n",
      "\n",
      "Epoch 164 / 25\n",
      "----------\n",
      "train Loss: 0.038784\n",
      "val Loss: 0.061519\n",
      "\n",
      "Epoch 165 / 25\n",
      "----------\n",
      "train Loss: 0.038726\n",
      "val Loss: 0.061443\n",
      "\n",
      "Epoch 166 / 25\n",
      "----------\n",
      "train Loss: 0.038668\n",
      "val Loss: 0.061367\n",
      "\n",
      "Epoch 167 / 25\n",
      "----------\n",
      "train Loss: 0.038610\n",
      "val Loss: 0.061291\n",
      "\n",
      "Epoch 168 / 25\n",
      "----------\n",
      "train Loss: 0.038551\n",
      "val Loss: 0.061214\n",
      "\n",
      "Epoch 169 / 25\n",
      "----------\n",
      "train Loss: 0.038493\n",
      "val Loss: 0.061137\n",
      "\n",
      "Epoch 170 / 25\n",
      "----------\n",
      "train Loss: 0.038433\n",
      "val Loss: 0.061059\n",
      "\n",
      "Epoch 171 / 25\n",
      "----------\n",
      "train Loss: 0.038374\n",
      "val Loss: 0.060981\n",
      "\n",
      "Epoch 172 / 25\n",
      "----------\n",
      "train Loss: 0.038314\n",
      "val Loss: 0.060903\n",
      "\n",
      "Epoch 173 / 25\n",
      "----------\n",
      "train Loss: 0.038254\n",
      "val Loss: 0.060824\n",
      "\n",
      "Epoch 174 / 25\n",
      "----------\n",
      "train Loss: 0.038194\n",
      "val Loss: 0.060746\n",
      "\n",
      "Epoch 175 / 25\n",
      "----------\n",
      "train Loss: 0.038134\n",
      "val Loss: 0.060666\n",
      "\n",
      "Epoch 176 / 25\n",
      "----------\n",
      "train Loss: 0.038073\n",
      "val Loss: 0.060587\n",
      "\n",
      "Epoch 177 / 25\n",
      "----------\n",
      "train Loss: 0.038012\n",
      "val Loss: 0.060507\n",
      "\n",
      "Epoch 178 / 25\n",
      "----------\n",
      "train Loss: 0.037951\n",
      "val Loss: 0.060427\n",
      "\n",
      "Epoch 179 / 25\n",
      "----------\n",
      "train Loss: 0.037889\n",
      "val Loss: 0.060346\n",
      "\n",
      "Epoch 180 / 25\n",
      "----------\n",
      "train Loss: 0.037828\n",
      "val Loss: 0.060265\n",
      "\n",
      "Epoch 181 / 25\n",
      "----------\n",
      "train Loss: 0.037766\n",
      "val Loss: 0.060184\n",
      "\n",
      "Epoch 182 / 25\n",
      "----------\n",
      "train Loss: 0.037703\n",
      "val Loss: 0.060103\n",
      "\n",
      "Epoch 183 / 25\n",
      "----------\n",
      "train Loss: 0.037641\n",
      "val Loss: 0.060021\n",
      "\n",
      "Epoch 184 / 25\n",
      "----------\n",
      "train Loss: 0.037578\n",
      "val Loss: 0.059939\n",
      "\n",
      "Epoch 185 / 25\n",
      "----------\n",
      "train Loss: 0.037515\n",
      "val Loss: 0.059857\n",
      "\n",
      "Epoch 186 / 25\n",
      "----------\n",
      "train Loss: 0.037452\n",
      "val Loss: 0.059774\n",
      "\n",
      "Epoch 187 / 25\n",
      "----------\n",
      "train Loss: 0.037389\n",
      "val Loss: 0.059691\n",
      "\n",
      "Epoch 188 / 25\n",
      "----------\n",
      "train Loss: 0.037325\n",
      "val Loss: 0.059608\n",
      "\n",
      "Epoch 189 / 25\n",
      "----------\n",
      "train Loss: 0.037262\n",
      "val Loss: 0.059525\n",
      "\n",
      "Epoch 190 / 25\n",
      "----------\n",
      "train Loss: 0.037198\n",
      "val Loss: 0.059441\n",
      "\n",
      "Epoch 191 / 25\n",
      "----------\n",
      "train Loss: 0.037133\n",
      "val Loss: 0.059357\n",
      "\n",
      "Epoch 192 / 25\n",
      "----------\n",
      "train Loss: 0.037069\n",
      "val Loss: 0.059272\n",
      "\n",
      "Epoch 193 / 25\n",
      "----------\n",
      "train Loss: 0.037004\n",
      "val Loss: 0.059188\n",
      "\n",
      "Epoch 194 / 25\n",
      "----------\n",
      "train Loss: 0.036940\n",
      "val Loss: 0.059103\n",
      "\n",
      "Epoch 195 / 25\n",
      "----------\n",
      "train Loss: 0.036875\n",
      "val Loss: 0.059018\n",
      "\n",
      "Epoch 196 / 25\n",
      "----------\n",
      "train Loss: 0.036809\n",
      "val Loss: 0.058932\n",
      "\n",
      "Epoch 197 / 25\n",
      "----------\n",
      "train Loss: 0.036744\n",
      "val Loss: 0.058847\n",
      "\n",
      "Epoch 198 / 25\n",
      "----------\n",
      "train Loss: 0.036678\n",
      "val Loss: 0.058761\n",
      "\n",
      "Epoch 199 / 25\n",
      "----------\n",
      "train Loss: 0.036613\n",
      "val Loss: 0.058675\n",
      "\n",
      "Epoch 200 / 25\n",
      "----------\n",
      "train Loss: 0.036547\n",
      "val Loss: 0.058588\n",
      "\n",
      "Epoch 201 / 25\n",
      "----------\n",
      "train Loss: 0.036480\n",
      "val Loss: 0.058502\n",
      "\n",
      "Epoch 202 / 25\n",
      "----------\n",
      "train Loss: 0.036414\n",
      "val Loss: 0.058415\n",
      "\n",
      "Epoch 203 / 25\n",
      "----------\n",
      "train Loss: 0.036347\n",
      "val Loss: 0.058328\n",
      "\n",
      "Epoch 204 / 25\n",
      "----------\n",
      "train Loss: 0.036281\n",
      "val Loss: 0.058240\n",
      "\n",
      "Epoch 205 / 25\n",
      "----------\n",
      "train Loss: 0.036214\n",
      "val Loss: 0.058153\n",
      "\n",
      "Epoch 206 / 25\n",
      "----------\n",
      "train Loss: 0.036147\n",
      "val Loss: 0.058065\n",
      "\n",
      "Epoch 207 / 25\n",
      "----------\n",
      "train Loss: 0.036080\n",
      "val Loss: 0.057977\n",
      "\n",
      "Epoch 208 / 25\n",
      "----------\n",
      "train Loss: 0.036012\n",
      "val Loss: 0.057889\n",
      "\n",
      "Epoch 209 / 25\n",
      "----------\n",
      "train Loss: 0.035945\n",
      "val Loss: 0.057800\n",
      "\n",
      "Epoch 210 / 25\n",
      "----------\n",
      "train Loss: 0.035877\n",
      "val Loss: 0.057711\n",
      "\n",
      "Epoch 211 / 25\n",
      "----------\n",
      "train Loss: 0.035809\n",
      "val Loss: 0.057622\n",
      "\n",
      "Epoch 212 / 25\n",
      "----------\n",
      "train Loss: 0.035741\n",
      "val Loss: 0.057533\n",
      "\n",
      "Epoch 213 / 25\n",
      "----------\n",
      "train Loss: 0.035673\n",
      "val Loss: 0.057444\n",
      "\n",
      "Epoch 214 / 25\n",
      "----------\n",
      "train Loss: 0.035604\n",
      "val Loss: 0.057354\n",
      "\n",
      "Epoch 215 / 25\n",
      "----------\n",
      "train Loss: 0.035536\n",
      "val Loss: 0.057264\n",
      "\n",
      "Epoch 216 / 25\n",
      "----------\n",
      "train Loss: 0.035467\n",
      "val Loss: 0.057174\n",
      "\n",
      "Epoch 217 / 25\n",
      "----------\n",
      "train Loss: 0.035399\n",
      "val Loss: 0.057084\n",
      "\n",
      "Epoch 218 / 25\n",
      "----------\n",
      "train Loss: 0.035330\n",
      "val Loss: 0.056994\n",
      "\n",
      "Epoch 219 / 25\n",
      "----------\n",
      "train Loss: 0.035261\n",
      "val Loss: 0.056903\n",
      "\n",
      "Epoch 220 / 25\n",
      "----------\n",
      "train Loss: 0.035191\n",
      "val Loss: 0.056812\n",
      "\n",
      "Epoch 221 / 25\n",
      "----------\n",
      "train Loss: 0.035122\n",
      "val Loss: 0.056721\n",
      "\n",
      "Epoch 222 / 25\n",
      "----------\n",
      "train Loss: 0.035053\n",
      "val Loss: 0.056630\n",
      "\n",
      "Epoch 223 / 25\n",
      "----------\n",
      "train Loss: 0.034983\n",
      "val Loss: 0.056539\n",
      "\n",
      "Epoch 224 / 25\n",
      "----------\n",
      "train Loss: 0.034913\n",
      "val Loss: 0.056447\n",
      "\n",
      "Epoch 225 / 25\n",
      "----------\n",
      "train Loss: 0.034844\n",
      "val Loss: 0.056355\n",
      "\n",
      "Epoch 226 / 25\n",
      "----------\n",
      "train Loss: 0.034774\n",
      "val Loss: 0.056264\n",
      "\n",
      "Epoch 227 / 25\n",
      "----------\n",
      "train Loss: 0.034704\n",
      "val Loss: 0.056171\n",
      "\n",
      "Epoch 228 / 25\n",
      "----------\n",
      "train Loss: 0.034634\n",
      "val Loss: 0.056079\n",
      "\n",
      "Epoch 229 / 25\n",
      "----------\n",
      "train Loss: 0.034563\n",
      "val Loss: 0.055987\n",
      "\n",
      "Epoch 230 / 25\n",
      "----------\n",
      "train Loss: 0.034493\n",
      "val Loss: 0.055894\n",
      "\n",
      "Epoch 231 / 25\n",
      "----------\n",
      "train Loss: 0.034422\n",
      "val Loss: 0.055801\n",
      "\n",
      "Epoch 232 / 25\n",
      "----------\n",
      "train Loss: 0.034352\n",
      "val Loss: 0.055708\n",
      "\n",
      "Epoch 233 / 25\n",
      "----------\n",
      "train Loss: 0.034281\n",
      "val Loss: 0.055615\n",
      "\n",
      "Epoch 234 / 25\n",
      "----------\n",
      "train Loss: 0.034210\n",
      "val Loss: 0.055522\n",
      "\n",
      "Epoch 235 / 25\n",
      "----------\n",
      "train Loss: 0.034140\n",
      "val Loss: 0.055429\n",
      "\n",
      "Epoch 236 / 25\n",
      "----------\n",
      "train Loss: 0.034069\n",
      "val Loss: 0.055335\n",
      "\n",
      "Epoch 237 / 25\n",
      "----------\n",
      "train Loss: 0.033998\n",
      "val Loss: 0.055241\n",
      "\n",
      "Epoch 238 / 25\n",
      "----------\n",
      "train Loss: 0.033926\n",
      "val Loss: 0.055147\n",
      "\n",
      "Epoch 239 / 25\n",
      "----------\n",
      "train Loss: 0.033855\n",
      "val Loss: 0.055053\n",
      "\n",
      "Epoch 240 / 25\n",
      "----------\n",
      "train Loss: 0.033784\n",
      "val Loss: 0.054959\n",
      "\n",
      "Epoch 241 / 25\n",
      "----------\n",
      "train Loss: 0.033713\n",
      "val Loss: 0.054865\n",
      "\n",
      "Epoch 242 / 25\n",
      "----------\n",
      "train Loss: 0.033641\n",
      "val Loss: 0.054770\n",
      "\n",
      "Epoch 243 / 25\n",
      "----------\n",
      "train Loss: 0.033570\n",
      "val Loss: 0.054676\n",
      "\n",
      "Epoch 244 / 25\n",
      "----------\n",
      "train Loss: 0.033498\n",
      "val Loss: 0.054581\n",
      "\n",
      "Epoch 245 / 25\n",
      "----------\n",
      "train Loss: 0.033426\n",
      "val Loss: 0.054486\n",
      "\n",
      "Epoch 246 / 25\n",
      "----------\n",
      "train Loss: 0.033355\n",
      "val Loss: 0.054392\n",
      "\n",
      "Epoch 247 / 25\n",
      "----------\n",
      "train Loss: 0.033283\n",
      "val Loss: 0.054296\n",
      "\n",
      "Epoch 248 / 25\n",
      "----------\n",
      "train Loss: 0.033211\n",
      "val Loss: 0.054201\n",
      "\n",
      "Epoch 249 / 25\n",
      "----------\n",
      "train Loss: 0.033139\n",
      "val Loss: 0.054106\n",
      "\n",
      "Epoch 250 / 25\n",
      "----------\n",
      "train Loss: 0.033067\n",
      "val Loss: 0.054011\n",
      "\n",
      "Epoch 251 / 25\n",
      "----------\n",
      "train Loss: 0.032995\n",
      "val Loss: 0.053915\n",
      "\n",
      "Epoch 252 / 25\n",
      "----------\n",
      "train Loss: 0.032923\n",
      "val Loss: 0.053820\n",
      "\n",
      "Epoch 253 / 25\n",
      "----------\n",
      "train Loss: 0.032851\n",
      "val Loss: 0.053724\n",
      "\n",
      "Epoch 254 / 25\n",
      "----------\n",
      "train Loss: 0.032779\n",
      "val Loss: 0.053629\n",
      "\n",
      "Epoch 255 / 25\n",
      "----------\n",
      "train Loss: 0.032707\n",
      "val Loss: 0.053533\n",
      "\n",
      "Epoch 256 / 25\n",
      "----------\n",
      "train Loss: 0.032635\n",
      "val Loss: 0.053437\n",
      "\n",
      "Epoch 257 / 25\n",
      "----------\n",
      "train Loss: 0.032563\n",
      "val Loss: 0.053341\n",
      "\n",
      "Epoch 258 / 25\n",
      "----------\n",
      "train Loss: 0.032491\n",
      "val Loss: 0.053245\n",
      "\n",
      "Epoch 259 / 25\n",
      "----------\n",
      "train Loss: 0.032418\n",
      "val Loss: 0.053149\n",
      "\n",
      "Epoch 260 / 25\n",
      "----------\n",
      "train Loss: 0.032346\n",
      "val Loss: 0.053053\n",
      "\n",
      "Epoch 261 / 25\n",
      "----------\n",
      "train Loss: 0.032274\n",
      "val Loss: 0.052957\n",
      "\n",
      "Epoch 262 / 25\n",
      "----------\n",
      "train Loss: 0.032202\n",
      "val Loss: 0.052861\n",
      "\n",
      "Epoch 263 / 25\n",
      "----------\n",
      "train Loss: 0.032130\n",
      "val Loss: 0.052764\n",
      "\n",
      "Epoch 264 / 25\n",
      "----------\n",
      "train Loss: 0.032057\n",
      "val Loss: 0.052668\n",
      "\n",
      "Epoch 265 / 25\n",
      "----------\n",
      "train Loss: 0.031985\n",
      "val Loss: 0.052572\n",
      "\n",
      "Epoch 266 / 25\n",
      "----------\n",
      "train Loss: 0.031913\n",
      "val Loss: 0.052476\n",
      "\n",
      "Epoch 267 / 25\n",
      "----------\n",
      "train Loss: 0.031841\n",
      "val Loss: 0.052379\n",
      "\n",
      "Epoch 268 / 25\n",
      "----------\n",
      "train Loss: 0.031769\n",
      "val Loss: 0.052283\n",
      "\n",
      "Epoch 269 / 25\n",
      "----------\n",
      "train Loss: 0.031696\n",
      "val Loss: 0.052187\n",
      "\n",
      "Epoch 270 / 25\n",
      "----------\n",
      "train Loss: 0.031624\n",
      "val Loss: 0.052090\n",
      "\n",
      "Epoch 271 / 25\n",
      "----------\n",
      "train Loss: 0.031552\n",
      "val Loss: 0.051994\n",
      "\n",
      "Epoch 272 / 25\n",
      "----------\n",
      "train Loss: 0.031480\n",
      "val Loss: 0.051898\n",
      "\n",
      "Epoch 273 / 25\n",
      "----------\n",
      "train Loss: 0.031408\n",
      "val Loss: 0.051801\n",
      "\n",
      "Epoch 274 / 25\n",
      "----------\n",
      "train Loss: 0.031336\n",
      "val Loss: 0.051705\n",
      "\n",
      "Epoch 275 / 25\n",
      "----------\n",
      "train Loss: 0.031264\n",
      "val Loss: 0.051609\n",
      "\n",
      "Epoch 276 / 25\n",
      "----------\n",
      "train Loss: 0.031192\n",
      "val Loss: 0.051512\n",
      "\n",
      "Epoch 277 / 25\n",
      "----------\n",
      "train Loss: 0.031120\n",
      "val Loss: 0.051416\n",
      "\n",
      "Epoch 278 / 25\n",
      "----------\n",
      "train Loss: 0.031049\n",
      "val Loss: 0.051320\n",
      "\n",
      "Epoch 279 / 25\n",
      "----------\n",
      "train Loss: 0.030977\n",
      "val Loss: 0.051224\n",
      "\n",
      "Epoch 280 / 25\n",
      "----------\n",
      "train Loss: 0.030905\n",
      "val Loss: 0.051128\n",
      "\n",
      "Epoch 281 / 25\n",
      "----------\n",
      "train Loss: 0.030834\n",
      "val Loss: 0.051031\n",
      "\n",
      "Epoch 282 / 25\n",
      "----------\n",
      "train Loss: 0.030762\n",
      "val Loss: 0.050935\n",
      "\n",
      "Epoch 283 / 25\n",
      "----------\n",
      "train Loss: 0.030690\n",
      "val Loss: 0.050839\n",
      "\n",
      "Epoch 284 / 25\n",
      "----------\n",
      "train Loss: 0.030619\n",
      "val Loss: 0.050743\n",
      "\n",
      "Epoch 285 / 25\n",
      "----------\n",
      "train Loss: 0.030548\n",
      "val Loss: 0.050647\n",
      "\n",
      "Epoch 286 / 25\n",
      "----------\n",
      "train Loss: 0.030476\n",
      "val Loss: 0.050551\n",
      "\n",
      "Epoch 287 / 25\n",
      "----------\n",
      "train Loss: 0.030405\n",
      "val Loss: 0.050456\n",
      "\n",
      "Epoch 288 / 25\n",
      "----------\n",
      "train Loss: 0.030334\n",
      "val Loss: 0.050360\n",
      "\n",
      "Epoch 289 / 25\n",
      "----------\n",
      "train Loss: 0.030263\n",
      "val Loss: 0.050264\n",
      "\n",
      "Epoch 290 / 25\n",
      "----------\n",
      "train Loss: 0.030192\n",
      "val Loss: 0.050169\n",
      "\n",
      "Epoch 291 / 25\n",
      "----------\n",
      "train Loss: 0.030122\n",
      "val Loss: 0.050073\n",
      "\n",
      "Epoch 292 / 25\n",
      "----------\n",
      "train Loss: 0.030051\n",
      "val Loss: 0.049978\n",
      "\n",
      "Epoch 293 / 25\n",
      "----------\n",
      "train Loss: 0.029980\n",
      "val Loss: 0.049882\n",
      "\n",
      "Epoch 294 / 25\n",
      "----------\n",
      "train Loss: 0.029910\n",
      "val Loss: 0.049787\n",
      "\n",
      "Epoch 295 / 25\n",
      "----------\n",
      "train Loss: 0.029839\n",
      "val Loss: 0.049692\n",
      "\n",
      "Epoch 296 / 25\n",
      "----------\n",
      "train Loss: 0.029769\n",
      "val Loss: 0.049597\n",
      "\n",
      "Epoch 297 / 25\n",
      "----------\n",
      "train Loss: 0.029699\n",
      "val Loss: 0.049502\n",
      "\n",
      "Epoch 298 / 25\n",
      "----------\n",
      "train Loss: 0.029629\n",
      "val Loss: 0.049407\n",
      "\n",
      "Epoch 299 / 25\n",
      "----------\n",
      "train Loss: 0.029559\n",
      "val Loss: 0.049312\n",
      "\n",
      "Epoch 300 / 25\n",
      "----------\n",
      "train Loss: 0.029489\n",
      "val Loss: 0.049218\n",
      "\n",
      "Epoch 301 / 25\n",
      "----------\n",
      "train Loss: 0.029419\n",
      "val Loss: 0.049123\n",
      "\n",
      "Epoch 302 / 25\n",
      "----------\n",
      "train Loss: 0.029350\n",
      "val Loss: 0.049029\n",
      "\n",
      "Epoch 303 / 25\n",
      "----------\n",
      "train Loss: 0.029280\n",
      "val Loss: 0.048934\n",
      "\n",
      "Epoch 304 / 25\n",
      "----------\n",
      "train Loss: 0.029211\n",
      "val Loss: 0.048840\n",
      "\n",
      "Epoch 305 / 25\n",
      "----------\n",
      "train Loss: 0.029142\n",
      "val Loss: 0.048746\n",
      "\n",
      "Epoch 306 / 25\n",
      "----------\n",
      "train Loss: 0.029073\n",
      "val Loss: 0.048652\n",
      "\n",
      "Epoch 307 / 25\n",
      "----------\n",
      "train Loss: 0.029004\n",
      "val Loss: 0.048558\n",
      "\n",
      "Epoch 308 / 25\n",
      "----------\n",
      "train Loss: 0.028935\n",
      "val Loss: 0.048465\n",
      "\n",
      "Epoch 309 / 25\n",
      "----------\n",
      "train Loss: 0.028867\n",
      "val Loss: 0.048371\n",
      "\n",
      "Epoch 310 / 25\n",
      "----------\n",
      "train Loss: 0.028798\n",
      "val Loss: 0.048278\n",
      "\n",
      "Epoch 311 / 25\n",
      "----------\n",
      "train Loss: 0.028730\n",
      "val Loss: 0.048185\n",
      "\n",
      "Epoch 312 / 25\n",
      "----------\n",
      "train Loss: 0.028662\n",
      "val Loss: 0.048092\n",
      "\n",
      "Epoch 313 / 25\n",
      "----------\n",
      "train Loss: 0.028594\n",
      "val Loss: 0.047999\n",
      "\n",
      "Epoch 314 / 25\n",
      "----------\n",
      "train Loss: 0.028526\n",
      "val Loss: 0.047906\n",
      "\n",
      "Epoch 315 / 25\n",
      "----------\n",
      "train Loss: 0.028458\n",
      "val Loss: 0.047813\n",
      "\n",
      "Epoch 316 / 25\n",
      "----------\n",
      "train Loss: 0.028391\n",
      "val Loss: 0.047721\n",
      "\n",
      "Epoch 317 / 25\n",
      "----------\n",
      "train Loss: 0.028324\n",
      "val Loss: 0.047629\n",
      "\n",
      "Epoch 318 / 25\n",
      "----------\n",
      "train Loss: 0.028257\n",
      "val Loss: 0.047537\n",
      "\n",
      "Epoch 319 / 25\n",
      "----------\n",
      "train Loss: 0.028190\n",
      "val Loss: 0.047445\n",
      "\n",
      "Epoch 320 / 25\n",
      "----------\n",
      "train Loss: 0.028123\n",
      "val Loss: 0.047353\n",
      "\n",
      "Epoch 321 / 25\n",
      "----------\n",
      "train Loss: 0.028056\n",
      "val Loss: 0.047262\n",
      "\n",
      "Epoch 322 / 25\n",
      "----------\n",
      "train Loss: 0.027990\n",
      "val Loss: 0.047170\n",
      "\n",
      "Epoch 323 / 25\n",
      "----------\n",
      "train Loss: 0.027924\n",
      "val Loss: 0.047079\n",
      "\n",
      "Epoch 324 / 25\n",
      "----------\n",
      "train Loss: 0.027857\n",
      "val Loss: 0.046988\n",
      "\n",
      "Epoch 325 / 25\n",
      "----------\n",
      "train Loss: 0.027792\n",
      "val Loss: 0.046897\n",
      "\n",
      "Epoch 326 / 25\n",
      "----------\n",
      "train Loss: 0.027726\n",
      "val Loss: 0.046807\n",
      "\n",
      "Epoch 327 / 25\n",
      "----------\n",
      "train Loss: 0.027660\n",
      "val Loss: 0.046717\n",
      "\n",
      "Epoch 328 / 25\n",
      "----------\n",
      "train Loss: 0.027595\n",
      "val Loss: 0.046626\n",
      "\n",
      "Epoch 329 / 25\n",
      "----------\n",
      "train Loss: 0.027530\n",
      "val Loss: 0.046537\n",
      "\n",
      "Epoch 330 / 25\n",
      "----------\n",
      "train Loss: 0.027465\n",
      "val Loss: 0.046447\n",
      "\n",
      "Epoch 331 / 25\n",
      "----------\n",
      "train Loss: 0.027400\n",
      "val Loss: 0.046357\n",
      "\n",
      "Epoch 332 / 25\n",
      "----------\n",
      "train Loss: 0.027336\n",
      "val Loss: 0.046268\n",
      "\n",
      "Epoch 333 / 25\n",
      "----------\n",
      "train Loss: 0.027271\n",
      "val Loss: 0.046179\n",
      "\n",
      "Epoch 334 / 25\n",
      "----------\n",
      "train Loss: 0.027207\n",
      "val Loss: 0.046090\n",
      "\n",
      "Epoch 335 / 25\n",
      "----------\n",
      "train Loss: 0.027143\n",
      "val Loss: 0.046001\n",
      "\n",
      "Epoch 336 / 25\n",
      "----------\n",
      "train Loss: 0.027080\n",
      "val Loss: 0.045913\n",
      "\n",
      "Epoch 337 / 25\n",
      "----------\n",
      "train Loss: 0.027016\n",
      "val Loss: 0.045825\n",
      "\n",
      "Epoch 338 / 25\n",
      "----------\n",
      "train Loss: 0.026953\n",
      "val Loss: 0.045737\n",
      "\n",
      "Epoch 339 / 25\n",
      "----------\n",
      "train Loss: 0.026890\n",
      "val Loss: 0.045649\n",
      "\n",
      "Epoch 340 / 25\n",
      "----------\n",
      "train Loss: 0.026827\n",
      "val Loss: 0.045562\n",
      "\n",
      "Epoch 341 / 25\n",
      "----------\n",
      "train Loss: 0.026764\n",
      "val Loss: 0.045474\n",
      "\n",
      "Epoch 342 / 25\n",
      "----------\n",
      "train Loss: 0.026702\n",
      "val Loss: 0.045387\n",
      "\n",
      "Epoch 343 / 25\n",
      "----------\n",
      "train Loss: 0.026640\n",
      "val Loss: 0.045301\n",
      "\n",
      "Epoch 344 / 25\n",
      "----------\n",
      "train Loss: 0.026578\n",
      "val Loss: 0.045214\n",
      "\n",
      "Epoch 345 / 25\n",
      "----------\n",
      "train Loss: 0.026516\n",
      "val Loss: 0.045128\n",
      "\n",
      "Epoch 346 / 25\n",
      "----------\n",
      "train Loss: 0.026454\n",
      "val Loss: 0.045042\n",
      "\n",
      "Epoch 347 / 25\n",
      "----------\n",
      "train Loss: 0.026393\n",
      "val Loss: 0.044956\n",
      "\n",
      "Epoch 348 / 25\n",
      "----------\n",
      "train Loss: 0.026332\n",
      "val Loss: 0.044870\n",
      "\n",
      "Epoch 349 / 25\n",
      "----------\n",
      "train Loss: 0.026271\n",
      "val Loss: 0.044785\n",
      "\n",
      "Epoch 350 / 25\n",
      "----------\n",
      "train Loss: 0.026210\n",
      "val Loss: 0.044700\n",
      "\n",
      "Epoch 351 / 25\n",
      "----------\n",
      "train Loss: 0.026150\n",
      "val Loss: 0.044615\n",
      "\n",
      "Epoch 352 / 25\n",
      "----------\n",
      "train Loss: 0.026090\n",
      "val Loss: 0.044530\n",
      "\n",
      "Epoch 353 / 25\n",
      "----------\n",
      "train Loss: 0.026030\n",
      "val Loss: 0.044446\n",
      "\n",
      "Epoch 354 / 25\n",
      "----------\n",
      "train Loss: 0.025970\n",
      "val Loss: 0.044362\n",
      "\n",
      "Epoch 355 / 25\n",
      "----------\n",
      "train Loss: 0.025910\n",
      "val Loss: 0.044278\n",
      "\n",
      "Epoch 356 / 25\n",
      "----------\n",
      "train Loss: 0.025851\n",
      "val Loss: 0.044194\n",
      "\n",
      "Epoch 357 / 25\n",
      "----------\n",
      "train Loss: 0.025792\n",
      "val Loss: 0.044111\n",
      "\n",
      "Epoch 358 / 25\n",
      "----------\n",
      "train Loss: 0.025733\n",
      "val Loss: 0.044028\n",
      "\n",
      "Epoch 359 / 25\n",
      "----------\n",
      "train Loss: 0.025675\n",
      "val Loss: 0.043945\n",
      "\n",
      "Epoch 360 / 25\n",
      "----------\n",
      "train Loss: 0.025616\n",
      "val Loss: 0.043863\n",
      "\n",
      "Epoch 361 / 25\n",
      "----------\n",
      "train Loss: 0.025558\n",
      "val Loss: 0.043780\n",
      "\n",
      "Epoch 362 / 25\n",
      "----------\n",
      "train Loss: 0.025500\n",
      "val Loss: 0.043698\n",
      "\n",
      "Epoch 363 / 25\n",
      "----------\n",
      "train Loss: 0.025443\n",
      "val Loss: 0.043617\n",
      "\n",
      "Epoch 364 / 25\n",
      "----------\n",
      "train Loss: 0.025385\n",
      "val Loss: 0.043535\n",
      "\n",
      "Epoch 365 / 25\n",
      "----------\n",
      "train Loss: 0.025328\n",
      "val Loss: 0.043454\n",
      "\n",
      "Epoch 366 / 25\n",
      "----------\n",
      "train Loss: 0.025271\n",
      "val Loss: 0.043373\n",
      "\n",
      "Epoch 367 / 25\n",
      "----------\n",
      "train Loss: 0.025214\n",
      "val Loss: 0.043292\n",
      "\n",
      "Epoch 368 / 25\n",
      "----------\n",
      "train Loss: 0.025158\n",
      "val Loss: 0.043212\n",
      "\n",
      "Epoch 369 / 25\n",
      "----------\n",
      "train Loss: 0.025102\n",
      "val Loss: 0.043132\n",
      "\n",
      "Epoch 370 / 25\n",
      "----------\n",
      "train Loss: 0.025046\n",
      "val Loss: 0.043052\n",
      "\n",
      "Epoch 371 / 25\n",
      "----------\n",
      "train Loss: 0.024990\n",
      "val Loss: 0.042972\n",
      "\n",
      "Epoch 372 / 25\n",
      "----------\n",
      "train Loss: 0.024934\n",
      "val Loss: 0.042893\n",
      "\n",
      "Epoch 373 / 25\n",
      "----------\n",
      "train Loss: 0.024879\n",
      "val Loss: 0.042814\n",
      "\n",
      "Epoch 374 / 25\n",
      "----------\n",
      "train Loss: 0.024824\n",
      "val Loss: 0.042735\n",
      "\n",
      "Epoch 375 / 25\n",
      "----------\n",
      "train Loss: 0.024769\n",
      "val Loss: 0.042657\n",
      "\n",
      "Epoch 376 / 25\n",
      "----------\n",
      "train Loss: 0.024715\n",
      "val Loss: 0.042579\n",
      "\n",
      "Epoch 377 / 25\n",
      "----------\n",
      "train Loss: 0.024660\n",
      "val Loss: 0.042501\n",
      "\n",
      "Epoch 378 / 25\n",
      "----------\n",
      "train Loss: 0.024606\n",
      "val Loss: 0.042423\n",
      "\n",
      "Epoch 379 / 25\n",
      "----------\n",
      "train Loss: 0.024553\n",
      "val Loss: 0.042346\n",
      "\n",
      "Epoch 380 / 25\n",
      "----------\n",
      "train Loss: 0.024499\n",
      "val Loss: 0.042268\n",
      "\n",
      "Epoch 381 / 25\n",
      "----------\n",
      "train Loss: 0.024446\n",
      "val Loss: 0.042192\n",
      "\n",
      "Epoch 382 / 25\n",
      "----------\n",
      "train Loss: 0.024393\n",
      "val Loss: 0.042115\n",
      "\n",
      "Epoch 383 / 25\n",
      "----------\n",
      "train Loss: 0.024340\n",
      "val Loss: 0.042039\n",
      "\n",
      "Epoch 384 / 25\n",
      "----------\n",
      "train Loss: 0.024287\n",
      "val Loss: 0.041963\n",
      "\n",
      "Epoch 385 / 25\n",
      "----------\n",
      "train Loss: 0.024235\n",
      "val Loss: 0.041887\n",
      "\n",
      "Epoch 386 / 25\n",
      "----------\n",
      "train Loss: 0.024183\n",
      "val Loss: 0.041812\n",
      "\n",
      "Epoch 387 / 25\n",
      "----------\n",
      "train Loss: 0.024131\n",
      "val Loss: 0.041736\n",
      "\n",
      "Epoch 388 / 25\n",
      "----------\n",
      "train Loss: 0.024079\n",
      "val Loss: 0.041662\n",
      "\n",
      "Epoch 389 / 25\n",
      "----------\n",
      "train Loss: 0.024028\n",
      "val Loss: 0.041587\n",
      "\n",
      "Epoch 390 / 25\n",
      "----------\n",
      "train Loss: 0.023977\n",
      "val Loss: 0.041513\n",
      "\n",
      "Epoch 391 / 25\n",
      "----------\n",
      "train Loss: 0.023926\n",
      "val Loss: 0.041439\n",
      "\n",
      "Epoch 392 / 25\n",
      "----------\n",
      "train Loss: 0.023875\n",
      "val Loss: 0.041365\n",
      "\n",
      "Epoch 393 / 25\n",
      "----------\n",
      "train Loss: 0.023825\n",
      "val Loss: 0.041291\n",
      "\n",
      "Epoch 394 / 25\n",
      "----------\n",
      "train Loss: 0.023774\n",
      "val Loss: 0.041218\n",
      "\n",
      "Epoch 395 / 25\n",
      "----------\n",
      "train Loss: 0.023724\n",
      "val Loss: 0.041145\n",
      "\n",
      "Epoch 396 / 25\n",
      "----------\n",
      "train Loss: 0.023675\n",
      "val Loss: 0.041073\n",
      "\n",
      "Epoch 397 / 25\n",
      "----------\n",
      "train Loss: 0.023625\n",
      "val Loss: 0.041000\n",
      "\n",
      "Epoch 398 / 25\n",
      "----------\n",
      "train Loss: 0.023576\n",
      "val Loss: 0.040928\n",
      "\n",
      "Epoch 399 / 25\n",
      "----------\n",
      "train Loss: 0.023527\n",
      "val Loss: 0.040856\n",
      "\n",
      "Epoch 400 / 25\n",
      "----------\n",
      "train Loss: 0.023478\n",
      "val Loss: 0.040785\n",
      "\n",
      "Epoch 401 / 25\n",
      "----------\n",
      "train Loss: 0.023430\n",
      "val Loss: 0.040714\n",
      "\n",
      "Epoch 402 / 25\n",
      "----------\n",
      "train Loss: 0.023382\n",
      "val Loss: 0.040643\n",
      "\n",
      "Epoch 403 / 25\n",
      "----------\n",
      "train Loss: 0.023334\n",
      "val Loss: 0.040572\n",
      "\n",
      "Epoch 404 / 25\n",
      "----------\n",
      "train Loss: 0.023286\n",
      "val Loss: 0.040502\n",
      "\n",
      "Epoch 405 / 25\n",
      "----------\n",
      "train Loss: 0.023238\n",
      "val Loss: 0.040432\n",
      "\n",
      "Epoch 406 / 25\n",
      "----------\n",
      "train Loss: 0.023191\n",
      "val Loss: 0.040362\n",
      "\n",
      "Epoch 407 / 25\n",
      "----------\n",
      "train Loss: 0.023144\n",
      "val Loss: 0.040292\n",
      "\n",
      "Epoch 408 / 25\n",
      "----------\n",
      "train Loss: 0.023097\n",
      "val Loss: 0.040223\n",
      "\n",
      "Epoch 409 / 25\n",
      "----------\n",
      "train Loss: 0.023051\n",
      "val Loss: 0.040154\n",
      "\n",
      "Epoch 410 / 25\n",
      "----------\n",
      "train Loss: 0.023004\n",
      "val Loss: 0.040085\n",
      "\n",
      "Epoch 411 / 25\n",
      "----------\n",
      "train Loss: 0.022958\n",
      "val Loss: 0.040017\n",
      "\n",
      "Epoch 412 / 25\n",
      "----------\n",
      "train Loss: 0.022912\n",
      "val Loss: 0.039949\n",
      "\n",
      "Epoch 413 / 25\n",
      "----------\n",
      "train Loss: 0.022867\n",
      "val Loss: 0.039881\n",
      "\n",
      "Epoch 414 / 25\n",
      "----------\n",
      "train Loss: 0.022821\n",
      "val Loss: 0.039813\n",
      "\n",
      "Epoch 415 / 25\n",
      "----------\n",
      "train Loss: 0.022776\n",
      "val Loss: 0.039746\n",
      "\n",
      "Epoch 416 / 25\n",
      "----------\n",
      "train Loss: 0.022731\n",
      "val Loss: 0.039679\n",
      "\n",
      "Epoch 417 / 25\n",
      "----------\n",
      "train Loss: 0.022687\n",
      "val Loss: 0.039612\n",
      "\n",
      "Epoch 418 / 25\n",
      "----------\n",
      "train Loss: 0.022642\n",
      "val Loss: 0.039546\n",
      "\n",
      "Epoch 419 / 25\n",
      "----------\n",
      "train Loss: 0.022598\n",
      "val Loss: 0.039479\n",
      "\n",
      "Epoch 420 / 25\n",
      "----------\n",
      "train Loss: 0.022554\n",
      "val Loss: 0.039414\n",
      "\n",
      "Epoch 421 / 25\n",
      "----------\n",
      "train Loss: 0.022510\n",
      "val Loss: 0.039348\n",
      "\n",
      "Epoch 422 / 25\n",
      "----------\n",
      "train Loss: 0.022467\n",
      "val Loss: 0.039283\n",
      "\n",
      "Epoch 423 / 25\n",
      "----------\n",
      "train Loss: 0.022423\n",
      "val Loss: 0.039217\n",
      "\n",
      "Epoch 424 / 25\n",
      "----------\n",
      "train Loss: 0.022380\n",
      "val Loss: 0.039153\n",
      "\n",
      "Epoch 425 / 25\n",
      "----------\n",
      "train Loss: 0.022337\n",
      "val Loss: 0.039088\n",
      "\n",
      "Epoch 426 / 25\n",
      "----------\n",
      "train Loss: 0.022295\n",
      "val Loss: 0.039024\n",
      "\n",
      "Epoch 427 / 25\n",
      "----------\n",
      "train Loss: 0.022252\n",
      "val Loss: 0.038960\n",
      "\n",
      "Epoch 428 / 25\n",
      "----------\n",
      "train Loss: 0.022210\n",
      "val Loss: 0.038896\n",
      "\n",
      "Epoch 429 / 25\n",
      "----------\n",
      "train Loss: 0.022168\n",
      "val Loss: 0.038833\n",
      "\n",
      "Epoch 430 / 25\n",
      "----------\n",
      "train Loss: 0.022127\n",
      "val Loss: 0.038769\n",
      "\n",
      "Epoch 431 / 25\n",
      "----------\n",
      "train Loss: 0.022085\n",
      "val Loss: 0.038706\n",
      "\n",
      "Epoch 432 / 25\n",
      "----------\n",
      "train Loss: 0.022044\n",
      "val Loss: 0.038644\n",
      "\n",
      "Epoch 433 / 25\n",
      "----------\n",
      "train Loss: 0.022003\n",
      "val Loss: 0.038581\n",
      "\n",
      "Epoch 434 / 25\n",
      "----------\n",
      "train Loss: 0.021962\n",
      "val Loss: 0.038519\n",
      "\n",
      "Epoch 435 / 25\n",
      "----------\n",
      "train Loss: 0.021921\n",
      "val Loss: 0.038457\n",
      "\n",
      "Epoch 436 / 25\n",
      "----------\n",
      "train Loss: 0.021881\n",
      "val Loss: 0.038396\n",
      "\n",
      "Epoch 437 / 25\n",
      "----------\n",
      "train Loss: 0.021841\n",
      "val Loss: 0.038335\n",
      "\n",
      "Epoch 438 / 25\n",
      "----------\n",
      "train Loss: 0.021801\n",
      "val Loss: 0.038274\n",
      "\n",
      "Epoch 439 / 25\n",
      "----------\n",
      "train Loss: 0.021761\n",
      "val Loss: 0.038213\n",
      "\n",
      "Epoch 440 / 25\n",
      "----------\n",
      "train Loss: 0.021722\n",
      "val Loss: 0.038152\n",
      "\n",
      "Epoch 441 / 25\n",
      "----------\n",
      "train Loss: 0.021683\n",
      "val Loss: 0.038092\n",
      "\n",
      "Epoch 442 / 25\n",
      "----------\n",
      "train Loss: 0.021643\n",
      "val Loss: 0.038032\n",
      "\n",
      "Epoch 443 / 25\n",
      "----------\n",
      "train Loss: 0.021605\n",
      "val Loss: 0.037972\n",
      "\n",
      "Epoch 444 / 25\n",
      "----------\n",
      "train Loss: 0.021566\n",
      "val Loss: 0.037913\n",
      "\n",
      "Epoch 445 / 25\n",
      "----------\n",
      "train Loss: 0.021528\n",
      "val Loss: 0.037854\n",
      "\n",
      "Epoch 446 / 25\n",
      "----------\n",
      "train Loss: 0.021489\n",
      "val Loss: 0.037795\n",
      "\n",
      "Epoch 447 / 25\n",
      "----------\n",
      "train Loss: 0.021451\n",
      "val Loss: 0.037736\n",
      "\n",
      "Epoch 448 / 25\n",
      "----------\n",
      "train Loss: 0.021414\n",
      "val Loss: 0.037678\n",
      "\n",
      "Epoch 449 / 25\n",
      "----------\n",
      "train Loss: 0.021376\n",
      "val Loss: 0.037619\n",
      "\n",
      "Epoch 450 / 25\n",
      "----------\n",
      "train Loss: 0.021339\n",
      "val Loss: 0.037562\n",
      "\n",
      "Epoch 451 / 25\n",
      "----------\n",
      "train Loss: 0.021302\n",
      "val Loss: 0.037504\n",
      "\n",
      "Epoch 452 / 25\n",
      "----------\n",
      "train Loss: 0.021265\n",
      "val Loss: 0.037447\n",
      "\n",
      "Epoch 453 / 25\n",
      "----------\n",
      "train Loss: 0.021228\n",
      "val Loss: 0.037389\n",
      "\n",
      "Epoch 454 / 25\n",
      "----------\n",
      "train Loss: 0.021192\n",
      "val Loss: 0.037333\n",
      "\n",
      "Epoch 455 / 25\n",
      "----------\n",
      "train Loss: 0.021155\n",
      "val Loss: 0.037276\n",
      "\n",
      "Epoch 456 / 25\n",
      "----------\n",
      "train Loss: 0.021119\n",
      "val Loss: 0.037220\n",
      "\n",
      "Epoch 457 / 25\n",
      "----------\n",
      "train Loss: 0.021083\n",
      "val Loss: 0.037164\n",
      "\n",
      "Epoch 458 / 25\n",
      "----------\n",
      "train Loss: 0.021048\n",
      "val Loss: 0.037108\n",
      "\n",
      "Epoch 459 / 25\n",
      "----------\n",
      "train Loss: 0.021012\n",
      "val Loss: 0.037052\n",
      "\n",
      "Epoch 460 / 25\n",
      "----------\n",
      "train Loss: 0.020977\n",
      "val Loss: 0.036997\n",
      "\n",
      "Epoch 461 / 25\n",
      "----------\n",
      "train Loss: 0.020942\n",
      "val Loss: 0.036942\n",
      "\n",
      "Epoch 462 / 25\n",
      "----------\n",
      "train Loss: 0.020907\n",
      "val Loss: 0.036887\n",
      "\n",
      "Epoch 463 / 25\n",
      "----------\n",
      "train Loss: 0.020872\n",
      "val Loss: 0.036832\n",
      "\n",
      "Epoch 464 / 25\n",
      "----------\n",
      "train Loss: 0.020838\n",
      "val Loss: 0.036778\n",
      "\n",
      "Epoch 465 / 25\n",
      "----------\n",
      "train Loss: 0.020804\n",
      "val Loss: 0.036724\n",
      "\n",
      "Epoch 466 / 25\n",
      "----------\n",
      "train Loss: 0.020769\n",
      "val Loss: 0.036670\n",
      "\n",
      "Epoch 467 / 25\n",
      "----------\n",
      "train Loss: 0.020736\n",
      "val Loss: 0.036616\n",
      "\n",
      "Epoch 468 / 25\n",
      "----------\n",
      "train Loss: 0.020702\n",
      "val Loss: 0.036563\n",
      "\n",
      "Epoch 469 / 25\n",
      "----------\n",
      "train Loss: 0.020668\n",
      "val Loss: 0.036510\n",
      "\n",
      "Epoch 470 / 25\n",
      "----------\n",
      "train Loss: 0.020635\n",
      "val Loss: 0.036457\n",
      "\n",
      "Epoch 471 / 25\n",
      "----------\n",
      "train Loss: 0.020602\n",
      "val Loss: 0.036404\n",
      "\n",
      "Epoch 472 / 25\n",
      "----------\n",
      "train Loss: 0.020569\n",
      "val Loss: 0.036352\n",
      "\n",
      "Epoch 473 / 25\n",
      "----------\n",
      "train Loss: 0.020536\n",
      "val Loss: 0.036300\n",
      "\n",
      "Epoch 474 / 25\n",
      "----------\n",
      "train Loss: 0.020504\n",
      "val Loss: 0.036248\n",
      "\n",
      "Epoch 475 / 25\n",
      "----------\n",
      "train Loss: 0.020472\n",
      "val Loss: 0.036196\n",
      "\n",
      "Epoch 476 / 25\n",
      "----------\n",
      "train Loss: 0.020439\n",
      "val Loss: 0.036145\n",
      "\n",
      "Epoch 477 / 25\n",
      "----------\n",
      "train Loss: 0.020408\n",
      "val Loss: 0.036094\n",
      "\n",
      "Epoch 478 / 25\n",
      "----------\n",
      "train Loss: 0.020376\n",
      "val Loss: 0.036043\n",
      "\n",
      "Epoch 479 / 25\n",
      "----------\n",
      "train Loss: 0.020344\n",
      "val Loss: 0.035992\n",
      "\n",
      "Epoch 480 / 25\n",
      "----------\n",
      "train Loss: 0.020313\n",
      "val Loss: 0.035941\n",
      "\n",
      "Epoch 481 / 25\n",
      "----------\n",
      "train Loss: 0.020282\n",
      "val Loss: 0.035891\n",
      "\n",
      "Epoch 482 / 25\n",
      "----------\n",
      "train Loss: 0.020251\n",
      "val Loss: 0.035841\n",
      "\n",
      "Epoch 483 / 25\n",
      "----------\n",
      "train Loss: 0.020220\n",
      "val Loss: 0.035791\n",
      "\n",
      "Epoch 484 / 25\n",
      "----------\n",
      "train Loss: 0.020189\n",
      "val Loss: 0.035742\n",
      "\n",
      "Epoch 485 / 25\n",
      "----------\n",
      "train Loss: 0.020159\n",
      "val Loss: 0.035693\n",
      "\n",
      "Epoch 486 / 25\n",
      "----------\n",
      "train Loss: 0.020128\n",
      "val Loss: 0.035643\n",
      "\n",
      "Epoch 487 / 25\n",
      "----------\n",
      "train Loss: 0.020098\n",
      "val Loss: 0.035595\n",
      "\n",
      "Epoch 488 / 25\n",
      "----------\n",
      "train Loss: 0.020068\n",
      "val Loss: 0.035546\n",
      "\n",
      "Epoch 489 / 25\n",
      "----------\n",
      "train Loss: 0.020039\n",
      "val Loss: 0.035498\n",
      "\n",
      "Epoch 490 / 25\n",
      "----------\n",
      "train Loss: 0.020009\n",
      "val Loss: 0.035449\n",
      "\n",
      "Epoch 491 / 25\n",
      "----------\n",
      "train Loss: 0.019980\n",
      "val Loss: 0.035402\n",
      "\n",
      "Epoch 492 / 25\n",
      "----------\n",
      "train Loss: 0.019950\n",
      "val Loss: 0.035354\n",
      "\n",
      "Epoch 493 / 25\n",
      "----------\n",
      "train Loss: 0.019921\n",
      "val Loss: 0.035306\n",
      "\n",
      "Epoch 494 / 25\n",
      "----------\n",
      "train Loss: 0.019892\n",
      "val Loss: 0.035259\n",
      "\n",
      "Epoch 495 / 25\n",
      "----------\n",
      "train Loss: 0.019864\n",
      "val Loss: 0.035212\n",
      "\n",
      "Epoch 496 / 25\n",
      "----------\n",
      "train Loss: 0.019835\n",
      "val Loss: 0.035165\n",
      "\n",
      "Epoch 497 / 25\n",
      "----------\n",
      "train Loss: 0.019807\n",
      "val Loss: 0.035119\n",
      "\n",
      "Epoch 498 / 25\n",
      "----------\n",
      "train Loss: 0.019779\n",
      "val Loss: 0.035072\n",
      "\n",
      "Epoch 499 / 25\n",
      "----------\n",
      "train Loss: 0.019751\n",
      "val Loss: 0.035026\n",
      "\n",
      "Epoch 500 / 25\n",
      "----------\n",
      "train Loss: 0.019723\n",
      "val Loss: 0.034980\n",
      "\n",
      "Training complete in 41m 48.508514s\n",
      "Best val loss: 0.034980\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoderRNN(input_size, hidden_size, num_layers)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model, losses = train_model(model, criterion, optimizer)\n",
    "torch.save(model.state_dict(), './lstm_autoencoder_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training/val curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for phase in ['train', 'val']:\n",
    "    plt.plot(losses[phase], label='{} loss'.format(phase))\n",
    " \n",
    "plt.legend()\n",
    "\n",
    "plt.title('train/val losses')\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
